/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./build/src/Engine/Audio/audioLoader.js":
/*!***********************************************!*\
  !*** ./build/src/Engine/Audio/audioLoader.js ***!
  \***********************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SonantAudioLoader = exports.DefaultAudioLoader = void 0;\nconst sonant = __importStar(__webpack_require__(/*! sonantx */ \"./node_modules/sonantx/dist/sonantx.bundle.js\"));\nconst EngineLogger_1 = __webpack_require__(/*! ../EngineLogger */ \"./build/src/Engine/EngineLogger.js\");\n// RegularAudioLoader.ts\nclass DefaultAudioLoader {\n    constructor(audioFile) {\n        this.audioFile = audioFile;\n    }\n    async loadAudio(audioContext) {\n        const response = await fetch(this.audioFile);\n        const arrayBuffer = await response.arrayBuffer();\n        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);\n        EngineLogger_1.EngineLogger.log(`audioBuffer duration after decoding is ${audioBuffer.duration} seconds`);\n        return audioBuffer;\n    }\n}\nexports.DefaultAudioLoader = DefaultAudioLoader;\nclass SonantAudioLoader {\n    constructor(songData) {\n        this.songData = songData;\n    } // Replace 'any' with the actual type of your song data\n    async loadAudio(audioContext) {\n        console.log(`Generating audioBuffer - it may take a while`);\n        const audioBuffer = await sonant.generateSong(this.songData, audioContext.sampleRate);\n        EngineLogger_1.EngineLogger.log(`audioBuffer duration after decoding is ${audioBuffer.duration} seconds`);\n        return audioBuffer;\n    }\n}\nexports.SonantAudioLoader = SonantAudioLoader;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Audio/audioLoader.js?");

/***/ }),

/***/ "./build/src/Engine/EngineLogger.js":
/*!******************************************!*\
  !*** ./build/src/Engine/EngineLogger.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EngineLogger = void 0;\nclass EngineLogger {\n    /**\n     * Enables or disables logging.\n     * @param enabled - Whether logging should be enabled or disabled.\n     */\n    static setEnabled(enabled) {\n        this.enabled = enabled;\n    }\n    /**\n     * Logs messages to the console if logging is enabled.\n     * @param args - The messages to log.\n     */\n    static log(...args) {\n        if (this.enabled) {\n            console.log(...args);\n        }\n    }\n}\nexports.EngineLogger = EngineLogger;\nEngineLogger.enabled = true; // Add a flag to control logging\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/EngineLogger.js?");

/***/ }),

/***/ "./build/src/Engine/GLSLShaderEntity.js":
/*!**********************************************!*\
  !*** ./build/src/Engine/GLSLShaderEntity.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GLSLShaderEntity = void 0;\nconst glslShaderRenderer_1 = __webpack_require__(/*! ./ShaderRenderers/WebGL/glslShaderRenderer */ \"./build/src/Engine/ShaderRenderers/WebGL/glslShaderRenderer.js\");\nclass GLSLShaderEntity {\n    /**\n     * Creates a new ShaderEntity.\n     * @param name - The key or identifier for the entity.\n     * @param w - The width of the entity's canvas.\n     * @param h - The height of the entity's canvas.\n     * @param props - The properties for the entity, including shader code and render buffers.\n     * @param action - An optional action function to be called before rendering the shaders.\n     */\n    constructor(name, props, action, w, h, startTimeinMs, durationInMs) {\n        this.name = name;\n        this.props = props;\n        this.action = action;\n        this.w = w;\n        this.h = h;\n        this.startTimeinMs = startTimeinMs;\n        this.durationInMs = durationInMs;\n        this.beatListeners = [];\n        this.tickListeners = [];\n        this.barListeners = [];\n        this.postProcessors = [];\n        this.canvas = document.createElement(\"canvas\");\n        if (w && h) {\n            this.canvas.width = w;\n            this.canvas.height = h;\n        }\n        if ((props === null || props === void 0 ? void 0 : props.mainFragmentShader) && props.mainVertexShader) {\n            this.shaderRenderer = new glslShaderRenderer_1.GLSLShaderRenderer(this.canvas, props === null || props === void 0 ? void 0 : props.mainVertexShader, props === null || props === void 0 ? void 0 : props.mainFragmentShader);\n            props.renderBuffers.forEach(buffer => {\n                this.shaderRenderer.addBuffer(buffer.name, buffer.vertex, buffer.fragment, buffer.textures, buffer.customUniforms);\n            });\n        }\n        else {\n            throw new Error(\"Cannot create ShaderEntity: Missing main shader code.\");\n        }\n    }\n    bindToScene(scene) {\n        this.scene = scene;\n    }\n    /**\n * Adds an event listener for when a beat occurs.\n * @param listener - The function to call when a beat occurs.\n * @returns The Entity instance for chaining.\n */\n    onBeat(listener) {\n        this.beatListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds an event listener for when a tick occurs.\n     * @param listener - The function to call when a tick occurs.\n     * @returns The Entity instance for chaining.\n     */\n    onTick(listener) {\n        this.tickListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds an event listener for when a bar is complete.\n     * @param listener - The function to call when a bar is complete.\n     * @returns The Entity instance for chaining.\n     */\n    onBar(listener) {\n        this.barListeners.push(listener);\n        return this;\n    }\n    /**\n * Adds a post-processing function to the entity.\n * @param processor - The post-processing function to add.\n */\n    addPostProcessor(processor) {\n        this.postProcessors.push(processor);\n    }\n    /**\n     * Updates the ShaderEntity by calling the action function (if provided)\n     * and then updating the ShaderRenderer.\n     * @param timeStamp - The current timestamp in the animation.\n     */\n    update(timeStamp) {\n        if (this.action && this.shaderRenderer && this.props) {\n            // Calculate elapsed time relative to the scene's start time\n            const sceneStartTime = this.scene ? this.scene.startTimeinMs : 0;\n            const elapsed = timeStamp - sceneStartTime - (this.startTimeinMs || 0);\n            if (elapsed >= 0 && elapsed <= (this.durationInMs || Infinity)) {\n                this.action(timeStamp, this.shaderRenderer, this.props);\n                // Calculate shader time relative to the entity's start time (within the scene)\n                const shaderTime = Math.max(0, elapsed);\n                this.shaderRenderer.update(shaderTime / 1000);\n            }\n        }\n    }\n    /**\n     * Copies the entity's canvas to the target canvas.\n     * @param targetCanvas - The target canvas to copy to.\n     */\n    copyToCanvas(targetCanvas, sequence) {\n        const targetCtx = targetCanvas.getContext(\"2d\");\n        if (targetCtx) {\n            // Calculate the elapsed time for the entity\n            const elapsed = sequence.currentTime - (this.startTimeinMs || 0);\n            // Check if the entity should be rendered based on its lifetime\n            if (elapsed >= 0 && elapsed <= (this.durationInMs || Infinity)) {\n                targetCtx.drawImage(this.canvas, 0, 0);\n            }\n        }\n    }\n}\nexports.GLSLShaderEntity = GLSLShaderEntity;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/GLSLShaderEntity.js?");

/***/ }),

/***/ "./build/src/Engine/Helpers/assetsHelper.js":
/*!**************************************************!*\
  !*** ./build/src/Engine/Helpers/assetsHelper.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AssetsHelper = void 0;\nclass AssetsHelper {\n    static async loadImage(url) {\n        const filename = url.split(\"/\").pop();\n        if (this.textureCache.has(filename)) {\n            return this.textureCache.get(filename).src;\n        }\n        return new Promise((resolve, reject) => {\n            const img = new Image();\n            img.src = url;\n            img.onload = () => {\n                this.textureCache.set(filename, { src: img });\n                resolve(img);\n            };\n            img.onerror = (error) => {\n                reject(error);\n            };\n        });\n    }\n    static async loadImages(urls) {\n        const imagePromises = urls.map(url => this.loadImage(url));\n        return Promise.all(imagePromises);\n    }\n    static async loadAudio(audioFile, audioContext) {\n        const response = await fetch(audioFile);\n        const arrayBuffer = await response.arrayBuffer();\n        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);\n        return audioBuffer;\n    }\n}\nexports.AssetsHelper = AssetsHelper;\nAssetsHelper.textureCache = new Map();\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Helpers/assetsHelper.js?");

/***/ }),

/***/ "./build/src/Engine/Helpers/sceneBuilder.js":
/*!**************************************************!*\
  !*** ./build/src/Engine/Helpers/sceneBuilder.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SceneBuilder = void 0;\nconst scene_1 = __webpack_require__(/*! ../scene */ \"./build/src/Engine/scene.js\");\nclass SceneBuilder {\n    /**\n     * Creates a new SceneBuilder to help construct scenes with automatic timing.\n     * @param totalDuration - The total duration of the animation sequence in milliseconds.\n     */\n    constructor(totalDuration) {\n        this.scenes = [];\n        this.currentTime = 0;\n        this.totalDuration = totalDuration;\n    }\n    /**\n     * Adds a scene to the builder with a specified name and duration.\n     * @param name - The name of the scene.\n     * @param duration - The duration of the scene in milliseconds.\n     * @returns The SceneBuilder instance for chaining.\n     */\n    addScene(name, duration) {\n        const startTime = this.currentTime;\n        this.currentTime += duration;\n        // If the current time exceeds the total duration, adjust the last scene's duration\n        if (this.currentTime > this.totalDuration) {\n            const lastScene = this.scenes[this.scenes.length - 1];\n            if (lastScene) {\n                lastScene.durationInMs = this.totalDuration - lastScene.startTimeinMs;\n            }\n            duration = this.totalDuration - startTime; // Adjust the current scene's duration as well\n        }\n        const scene = new scene_1.Scene(name, startTime, duration);\n        this.scenes.push(scene);\n        return this; // For chaining\n    }\n    /**\n     * Gets the array of scenes with their timing configured.\n     * @returns The array of Scene objects.\n     */\n    getScenes() {\n        return this.scenes;\n    }\n    /**\n     * Gets the total duration of all scenes added to the builder.\n     * @returns The total duration in milliseconds.\n     */\n    get totalScenesDuration() {\n        return this.scenes.reduce((total, scene) => total + scene.durationInMs, 0);\n    }\n    /**\n     * Adds a scene to the builder with a specified name and a duration that extends to the end of the total duration.\n     * @param name - The name of the scene.\n     * @returns The SceneBuilder instance for chaining.\n     */\n    durationUntilEndInMs(name) {\n        const startTime = this.currentTime;\n        const duration = this.totalDuration - startTime;\n        const scene = new scene_1.Scene(name, startTime, duration);\n        this.scenes.push(scene);\n        return this;\n    }\n}\nexports.SceneBuilder = SceneBuilder;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Helpers/sceneBuilder.js?");

/***/ }),

/***/ "./build/src/Engine/Interfaces/IPass.js":
/*!**********************************************!*\
  !*** ./build/src/Engine/Interfaces/IPass.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RenderPass = void 0;\nclass RenderPass {\n    constructor(type, label, pipleline, uniforms, bindGroup, buffer, bufferView) {\n        this.type = type;\n        this.label = label;\n        this.pipleline = pipleline;\n        this.uniforms = uniforms;\n        this.bindGroup = bindGroup;\n        this.buffer = buffer;\n        this.bufferView = bufferView;\n    }\n}\nexports.RenderPass = RenderPass;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Interfaces/IPass.js?");

/***/ }),

/***/ "./build/src/Engine/Interfaces/IWgslTexture.js":
/*!*****************************************************!*\
  !*** ./build/src/Engine/Interfaces/IWgslTexture.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WgslTextureType = void 0;\nvar WgslTextureType;\n(function (WgslTextureType) {\n    WgslTextureType[WgslTextureType[\"IMAGE\"] = 0] = \"IMAGE\";\n    WgslTextureType[WgslTextureType[\"VIDEO\"] = 1] = \"VIDEO\";\n    WgslTextureType[WgslTextureType[\"CANVAS\"] = 2] = \"CANVAS\";\n    WgslTextureType[WgslTextureType[\"MEDIASTREAM\"] = 3] = \"MEDIASTREAM\";\n})(WgslTextureType || (exports.WgslTextureType = WgslTextureType = {}));\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Interfaces/IWgslTexture.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGL/glslShaderRenderer.js":
/*!**********************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGL/glslShaderRenderer.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GLSLShaderRenderer = exports.RenderTarget = void 0;\nclass RenderTarget {\n    constructor(gl, textures, customUniforms) {\n        this.textures = new Array();\n        this.locations = new Map();\n        this.framebuffer = gl.createFramebuffer();\n        this.renderbuffer = gl.createRenderbuffer();\n        this.texture = gl.createTexture();\n        this.textures = textures;\n        this.uniforms = customUniforms;\n    }\n}\nexports.RenderTarget = RenderTarget;\nclass GLSLShaderRenderer {\n    /**\n     * Create a Shader\n     *\n     * @param {WebGLProgram} program\n     * @param {number} type\n     * @param {string} source\n     * @memberof DR\n     */\n    createShader(program, type, source) {\n        let gl = this.gl;\n        let shader = gl.createShader(type);\n        gl.shaderSource(shader, source);\n        gl.compileShader(shader);\n        gl.attachShader(program, shader);\n        if (!gl.getShaderParameter(shader, 35713)) { // this.gl.COMPILE_STATUS\n            // gl.getShaderInfoLog(shader).trim().split(\"\\n\").forEach((l: string) =>\n            //         console.error(\"[shader] \" + l))\n            throw new Error(\"Error while compiling vertex/fragment\" + source);\n        }\n        ;\n    }\n    /**\n     * Create and a WebGLProgram\n     *\n     * @param {string} name\n     * @returns {WebGLProgram}\n     * @memberof DR\n     */\n    addProgram(name) {\n        let p = this.gl.createProgram();\n        this.programs.set(name, { program: p, state: true });\n        return p;\n    }\n    /**\n     *  Create a new WEBGLTexture\n     *\n     * @param {*} data  image or UInt8Array\n     * @returns WebGLTexture\n     * @memberof DR\n     */\n    createTexture(data, d) {\n        let gl = this.gl;\n        let texture = gl.createTexture();\n        gl.activeTexture(33985 + d);\n        gl.bindTexture(3553, texture);\n        if (data instanceof Image) {\n            gl.texImage2D(3553, 0, 6408, 6408, 5121, data);\n        }\n        else {\n            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, 1, 1, 0, gl.RGBA, gl.UNSIGNED_BYTE, data);\n        }\n        gl.generateMipmap(3553);\n        return texture;\n    }\n    /**\n     * Create a texture cube map\n     *\n     * @param {Array<any>} sources\n     * @param {number} d\n     * @returns {WebGLTexture}\n     * @memberof DR\n     */\n    createTextureCube(sources, d) {\n        let gl = this.gl;\n        let texture = gl.createTexture();\n        gl.activeTexture(33985 + d);\n        gl.bindTexture(gl.TEXTURE_CUBE_MAP, texture);\n        const fetchAll = (src, key) => {\n            return new Promise(async (resolve, reject) => {\n                const response = await fetch(src);\n                const blob = await response.blob();\n                let image = new Image();\n                image.dataset.key = key;\n                image.onerror = reject;\n                image.onload = () => {\n                    resolve(image);\n                };\n                image.src = src;\n            });\n        };\n        Promise.all(sources.map(i => {\n            return fetchAll(i.d, i.t);\n        })).then(data => {\n            data.forEach(image => {\n                const target = image.dataset.key;\n                const level = 0;\n                const internalFormat = gl.RGBA;\n                const width = 512;\n                const height = 512;\n                const format = gl.RGBA;\n                const type = gl.UNSIGNED_BYTE;\n                gl.texImage2D(target, level, internalFormat, width, height, 0, format, type, null);\n                gl.bindTexture(gl.TEXTURE_CUBE_MAP, texture);\n                gl.texImage2D(target, level, internalFormat, format, type, image);\n                gl.generateMipmap(gl.TEXTURE_CUBE_MAP);\n            });\n        });\n        gl.generateMipmap(gl.TEXTURE_CUBE_MAP);\n        gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MIN_FILTER, gl.LINEAR_MIPMAP_LINEAR);\n        return texture;\n    }\n    /**\n     * add assets ( textures )\n     *\n     * @param {*} assets\n     * @param {()=>void} cb\n     * @returns {this}\n     * @memberof DR\n     */\n    addAssets(assets, cb) {\n        const cache = (k, v, f) => {\n            this.textureCache.set(k, { src: v, fn: f });\n        };\n        const p = (key, texture, unit) => {\n            return new Promise((resolve) => {\n                if (!texture.src) {\n                    cache(key, this.createTexture(new Uint8Array(1024), unit), texture.fn);\n                    resolve(key);\n                }\n                else {\n                    if (!Array.isArray(texture.src)) {\n                        const i = new Image();\n                        i.onload = (e) => {\n                            cache(key, this.createTexture(i, unit), null);\n                            resolve(key);\n                        };\n                        i.src = texture.src;\n                    }\n                    else {\n                        cache(key, this.createTextureCube(texture.src, unit), texture.fn);\n                        resolve(key);\n                    }\n                }\n            });\n        };\n        Promise.all(Object.keys(assets).map((key, index) => {\n            return p(key, assets[key], index);\n        })).then((result) => {\n            cb(result);\n        }).catch((err) => {\n            console.error(err);\n        });\n        return this;\n    }\n    /**\n     * add a new buffer / shader program\n     *\n     * @param {string} name\n     * @param {string} vertex\n     * @param {string} fragment\n     * @param {Array<string>} [textures]\n     * @param {*} [customUniforms]\n     * @returns {this}\n     * @memberof DR\n     */\n    addBuffer(name, vertex, fragment, textures, customUniforms) {\n        let gl = this.gl;\n        let tA = this.createTarget(this.canvas.width, this.canvas.height, textures ? textures : [], customUniforms ? customUniforms : {});\n        let tB = this.createTarget(this.canvas.width, this.canvas.height, textures ? textures : [], customUniforms ? customUniforms : {});\n        this.targets.set(name, tA);\n        this.targets.set(`_${name}`, tB);\n        let program = this.addProgram(name);\n        this.createShader(program, 35633, this.header + vertex);\n        this.createShader(program, 35632, this.header + fragment);\n        gl.linkProgram(program);\n        gl.validateProgram(program);\n        if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {\n            var info = gl.getProgramInfoLog(program);\n            throw `Could not compile ${name} program. \\n\\n${info}`;\n        }\n        gl.useProgram(program);\n        if (textures) {\n            textures.forEach((tk) => {\n                gl.bindTexture(3553, this.textureCache.get(tk).src);\n            });\n        }\n        this.vertexPosition = gl.getAttribLocation(program, \"pos\");\n        gl.enableVertexAttribArray(this.vertexPosition);\n        for (let i = 0; i < gl.getProgramParameter(program, gl.ACTIVE_UNIFORMS); ++i) {\n            const u = gl.getActiveUniform(program, i);\n            tA.locations.set(u.name, gl.getUniformLocation(program, u.name));\n        }\n        return this;\n    }\n    /**\n     * Set program state ( enable / or disable)\n     *\n     * @param {string} key\n     * @param {boolean} state\n     * @memberof DR\n     */\n    setProgramState(key, state) {\n        this.programs.get(key).state = state;\n    }\n    /**\n     * Render\n     *\n     * @param {number} time\n     * @memberof DR\n     */\n    update(time) {\n        let gl = this.gl;\n        let main = this.mainProgram;\n        let tc = 0;\n        this.programs.forEach((l, key) => {\n            if (!l.state)\n                return; // do not render \n            const current = l.program;\n            let fT = this.targets.get(key);\n            let bT = this.targets.get(`_${key}`);\n            gl.useProgram(current);\n            // resolution, time\n            gl.uniform2f(fT.locations.get(\"resolution\"), this.canvas.width, this.canvas.height);\n            gl.uniform1f(fT.locations.get(\"time\"), time);\n            gl.uniform1f(fT.locations.get(\"deltaTime\"), this.frameCount);\n            gl.uniform1f(fT.locations.get(\"frame\"), this.frameCount);\n            let customUniforms = fT.uniforms;\n            customUniforms && Object.keys(customUniforms).forEach((v) => {\n                customUniforms[v](fT.locations.get(v), gl, current, time);\n            });\n            let bl = gl.getUniformLocation(current, key); // todo: get this from cache?\n            gl.uniform1i(bl, 0);\n            gl.activeTexture(gl.TEXTURE0);\n            gl.bindTexture(gl.TEXTURE_2D, bT.texture);\n            fT.textures.forEach((tk, index) => {\n                let ct = this.textureCache.get(tk);\n                gl.activeTexture(33985 + index);\n                gl.bindTexture(gl.TEXTURE_2D, ct.src);\n                if (ct.fn)\n                    ct.fn(!current, gl, ct.src);\n                let loc = gl.getUniformLocation(!current, tk); // todo: get this from cache?  \n                gl.uniform1i(loc, index + 1);\n                tc++;\n            });\n            gl.bindBuffer(34962, this.surfaceBuffer);\n            gl.vertexAttribPointer(0, 2, 5126, false, 0, 0);\n            gl.bindBuffer(34962, this.buffer);\n            gl.vertexAttribPointer(0, 2, 5126, false, 0, 0);\n            gl.bindFramebuffer(36160, fT.framebuffer);\n            gl.clear(16384 | 256);\n            gl.drawArrays(4, 0, 6);\n            bT = fT;\n            fT = bT;\n        });\n        gl.useProgram(main);\n        gl.uniform2f(this.mainUniforms.get(\"resolution\"), this.canvas.width, this.canvas.height);\n        gl.uniform1f(this.mainUniforms.get(\"time\"), time);\n        // todo:  set up a cache for custom uniforms\n        Object.keys(this.cU).forEach((v) => {\n            this.cU[v](gl.getUniformLocation(main, v), gl, main, time); // todo: use cached locations\n        });\n        gl.bindBuffer(34962, this.buffer);\n        gl.vertexAttribPointer(0, 2, 5126, false, 0, 0);\n        this.targets.forEach((target, key) => {\n            gl.uniform1i(gl.getUniformLocation(main, key), tc); // todo: use cached locations\n            gl.activeTexture(33984 + tc);\n            gl.bindTexture(3553, target.texture);\n            tc++;\n        });\n        gl.bindFramebuffer(36160, null);\n        gl.clear(16384 | 256);\n        gl.drawArrays(4, 0, 6);\n        this.frameCount++;\n        this.deltaTime = -(this.deltaTime - time);\n    }\n    /**\n     * Create render target\n     *\n     * @param {number} width\n     * @param {number} height\n     * @param {Array<string>} textures\n     * @returns {*}\n     * @memberof DR\n     */\n    createTarget(width, height, textures, customUniforms) {\n        let gl = this.gl;\n        let target = new RenderTarget(gl, textures, customUniforms);\n        gl.bindTexture(3553, target.texture);\n        gl.texImage2D(3553, 0, 6408, width, height, 0, 6408, 5121, null);\n        gl.texParameteri(3553, 10242, 33071);\n        gl.texParameteri(3553, 10243, 33071);\n        gl.texParameteri(3553, 10240, 9728);\n        gl.texParameteri(3553, 10241, 9728);\n        gl.bindFramebuffer(36160, target.framebuffer);\n        gl.framebufferTexture2D(36160, 36064, 3553, target.texture, 0);\n        gl.bindRenderbuffer(36161, target.renderbuffer);\n        gl.renderbufferStorage(36161, 33189, width, height);\n        gl.framebufferRenderbuffer(36160, 36096, 36161, target.renderbuffer);\n        gl.bindTexture(3553, null);\n        gl.bindRenderbuffer(36161, null);\n        gl.bindFramebuffer(36160, null);\n        return target;\n    }\n    /**\n     * Render loop\n     *\n     * @param {number} t\n     * @param {number} fps\n     * @returns {this}\n     * @memberof DR\n     */\n    run(t, fps) {\n        let pt = performance.now();\n        let interval = 1000 / fps;\n        let dt = 0;\n        const a = (t) => {\n            requestAnimationFrame(a);\n            dt = t - pt;\n            if (dt > interval) {\n                pt = t - (dt % interval);\n                this.update(pt / 1000);\n            }\n        };\n        a(t | 0);\n        return this;\n    }\n    constructor(canvas, v, f, cU = {}) {\n        this.canvas = canvas;\n        this.cU = cU;\n        this.vertexPosition = 0;\n        this.frameCount = 0;\n        this.deltaTime = 0;\n        this.header = `#version 300 es\r\n#ifdef GL_ES\r\nprecision highp float;\r\nprecision highp int;\r\nprecision mediump sampler3D;\r\n#endif\r\n`;\n        this.targets = new Map();\n        this.mainUniforms = new Map();\n        this.programs = new Map();\n        this.textureCache = new Map();\n        let gl = canvas.getContext(\"webgl2\", { preserveDrawingBuffer: true });\n        this.gl = gl;\n        let mp = gl.createProgram();\n        this.mainProgram = mp;\n        gl.viewport(0, 0, canvas.width, canvas.height);\n        this.buffer = gl.createBuffer();\n        this.surfaceBuffer = gl.createBuffer();\n        this.createShader(mp, 35633, this.header + v);\n        this.createShader(mp, 35632, this.header + f);\n        gl.linkProgram(mp);\n        gl.validateProgram(mp);\n        if (!gl.getProgramParameter(mp, gl.LINK_STATUS)) {\n            var info = gl.getProgramInfoLog(mp);\n            throw 'Could not compile main program. \\n\\n' + info;\n        }\n        gl.useProgram(mp);\n        for (let i = 0; i < gl.getProgramParameter(mp, gl.ACTIVE_UNIFORMS); ++i) {\n            const u = gl.getActiveUniform(mp, i);\n            const loc = gl.getUniformLocation(mp, u.name);\n            this.mainUniforms.set(u.name, loc);\n        }\n        this.screenVertexPosition = gl.getAttribLocation(mp, \"pos\");\n        gl.enableVertexAttribArray(this.screenVertexPosition);\n        gl.bindBuffer(34962, this.buffer);\n        gl.bufferData(34962, new Float32Array([-1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0]), 35044);\n    }\n    /**\n     *  Generate a texture and return a canvas element\n     *\n     * @static\n     * @param {string} mainVertex\n     * @param {string} mainFrag\n     * @param {string} textureVertex\n     * @param {*} textureFrag\n     * @param {number} w\n     * @param {number} h\n     * @returns {HTMLCanvasElement}\n     * @memberof DR\n     */\n    static generateTexture(mainVertex, mainFrag, textureVertex, textureFrag, w, h) {\n        let canvas = document.createElement(\"canvas\");\n        canvas.width = w;\n        canvas.height = h;\n        let dr = new GLSLShaderRenderer(canvas, mainVertex, mainFrag);\n        dr.addBuffer(\"A\", textureVertex, textureFrag);\n        // do a few frames due to back buffer.\n        for (var i = 0; i < 2; i++) {\n            dr.update(i);\n        }\n        return canvas;\n    }\n}\nexports.GLSLShaderRenderer = GLSLShaderRenderer;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGL/glslShaderRenderer.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGPU/defaultMainShader.js":
/*!**********************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGPU/defaultMainShader.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.defaultMainShader = void 0;\nexports.defaultMainShader = {\n    vertex: /* wgsl */ `\r\n    \r\n    struct VertexOutput {\r\n      @builtin(position) Position  : vec4<f32>,\r\n      @location(0) TexCoord  : vec2<f32>,\r\n  }\r\n  \r\n  @vertex\r\n  fn main_vertex(@builtin(vertex_index) VertexIndex : u32) -> VertexOutput {\r\n  \r\n      var positions = array<vec2<f32>, 6>(\r\n          vec2<f32>( 1.0,  1.0),\r\n          vec2<f32>( 1.0, -1.0),\r\n          vec2<f32>(-1.0, -1.0),\r\n          vec2<f32>( 1.0,  1.0),\r\n          vec2<f32>(-1.0, -1.0),\r\n          vec2<f32>(-1.0,  1.0)\r\n      );\r\n  \r\n      var texCoords = array<vec2<f32>, 6>(\r\n          vec2<f32>(1.0, 0.0),\r\n          vec2<f32>(1.0, 1.0),\r\n          vec2<f32>(0.0, 1.0),\r\n          vec2<f32>(1.0, 0.0),\r\n          vec2<f32>(0.0, 1.0),\r\n          vec2<f32>(0.0, 0.0)\r\n      );\r\n  \r\n      var output : VertexOutput;\r\n      output.Position = vec4<f32>(positions[VertexIndex], 0.0, 1.0);\r\n      output.TexCoord = texCoords[VertexIndex];\r\n      return output;\r\n  }\r\n    \r\n    `,\n    fragment: /* wgsl */ `\r\n    \r\n    struct Uniforms {\r\n      resolution: vec3<f32>,\r\n      time: f32\r\n    };  \r\n    @group(0) @binding(0) var screen_sampler : sampler;    \r\n    @group(0) @binding(1) var<uniform> uniforms: Uniforms;  \r\n    @group(0) @binding(2) var buffer1: texture_2d<f32>;   \r\n\r\n    struct VertexOutput {\r\n      @builtin(position) Position: vec4<f32>,\r\n      @location(0) TexCoord: vec2<f32>\r\n    };  \r\n  \r\n    @fragment\r\n    fn main_fragment(@location(0) TexCoord : vec2<f32>,@builtin(position) Position: vec4<f32> ) -> @location(0) vec4<f32> {\r\n      return  textureSample(buffer1, screen_sampler, -TexCoord);  \r\n  \r\n    }`,\n    // vertexEntryPoint:\"main_vertex\",\n    // fragmentEntryPoint:\"main_fragment\"\n};\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGPU/defaultMainShader.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGPU/geometry.js":
/*!*************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGPU/geometry.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.rectGeometry = exports.Geometry = exports.DefaultIndicies = exports.VERTEXType = void 0;\nvar VERTEXType;\n(function (VERTEXType) {\n    VERTEXType[VERTEXType[\"xyz\"] = 3] = \"xyz\";\n    VERTEXType[VERTEXType[\"xyzw\"] = 4] = \"xyzw\";\n    VERTEXType[VERTEXType[\"xyzrgba\"] = 7] = \"xyzrgba\";\n    VERTEXType[VERTEXType[\"xyzwrgba\"] = 8] = \"xyzwrgba\";\n})(VERTEXType || (exports.VERTEXType = VERTEXType = {}));\nexports.DefaultIndicies = new Uint16Array([0, 1, 2, 3, 4, 5]);\nclass Geometry {\n    /**\n     * Creates a new Geometry object.\n     * @param device - The GPUDevice to use for creating buffers.\n     * @param model - The geometry data, including vertices, indices, and vertex type.\n     */\n    constructor(device, model) {\n        this.device = device;\n        this.model = model;\n        this.vertexBuffer = this.createBuffer(model.vertices, GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST, model.verticesType);\n        this.indexBuffer = this.createBuffer(model.indicies, GPUBufferUsage.INDEX, 3);\n        this.numOfVerticles = model.vertices.length / model.verticesType;\n    }\n    /**\n     * Creates a GPUBuffer with the given data and usage flags.\n     * @param arr - The data to store in the buffer.\n     * @param usage - The usage flags for the buffer.\n     * @param vertexSize - The size of each vertex in bytes.\n     * @returns The created GPUBuffer.\n     */\n    createBuffer(arr, usage, vertexSize) {\n        const desc = {\n            size: (arr.byteLength + vertexSize) & ~vertexSize,\n            usage,\n            mappedAtCreation: true\n        };\n        const buffer = this.device.createBuffer(desc);\n        const writeArray = arr instanceof Uint16Array\n            ? new Uint16Array(buffer.getMappedRange())\n            : new Float32Array(buffer.getMappedRange());\n        writeArray.set(arr);\n        buffer.unmap();\n        return buffer;\n    }\n    /**\n     * Creates a vertex buffer layout for the geometry.\n     * @param shaderLocation - The location of the vertex attribute in the shader.\n     * @returns The GPUVertexBufferLayout object.\n     */\n    vertexBufferLayout(shaderLocation) {\n        return {\n            attributes: [{\n                    shaderLocation: shaderLocation,\n                    offset: 0,\n                    format: 'float32x2' // This might need to be adjusted based on your shader\n                }],\n            arrayStride: 4 * this.model.verticesType,\n            stepMode: 'vertex'\n        };\n    }\n}\nexports.Geometry = Geometry;\n// Default rectangle geometry\nexports.rectGeometry = {\n    verticesType: VERTEXType.xyz,\n    vertices: new Float32Array([\n        -1, 1, 0,\n        -1, -1, 0,\n        1, -1, 0,\n        1, 1, 0,\n        -1, 1, 0,\n        1, -1, 0,\n    ]),\n    indicies: exports.DefaultIndicies, // Use the DefaultIndicies constant\n};\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGPU/geometry.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGPU/material.js":
/*!*************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGPU/material.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Material = exports.defaultWglslVertex = void 0;\n/**\n * Default vertex shader code for rendering a rectangle.\n */\nexports.defaultWglslVertex = ` \r\n  struct VertexInput {\r\n    @location(0) pos: vec2<f32>,\r\n    @builtin(vertex_index) index : u32\r\n  };\r\n\r\n  struct VertexOutput {\r\n    @builtin(position) pos: vec4<f32>,\r\n    @location(0) uv: vec2<f32>,\r\n    @location(1) fragCoord: vec2<f32>\r\n  };\r\n\r\n  @vertex\r\n  fn main_vertex(input: VertexInput) -> VertexOutput {\r\n    var output: VertexOutput;\r\n    var pos: vec2<f32> = input.pos * 2.0 - 1.0;\r\n    output.pos = vec4<f32>(pos, 0.0, 1.0);\r\n    output.uv = pos;\r\n    output.fragCoord = vec2<f32>((pos.x + 1.0) / 2.0, (1.0 - pos.y) / 2.0); \r\n    return output;\r\n  }\r\n`;\n/**\n * Represents a material with vertex and fragment shaders.\n */\nclass Material {\n    /**\n     * Creates a new Material.\n     * @param device - The GPUDevice to use for creating shader modules.\n     * @param shader - The IMaterialShader object containing the shader code.\n     */\n    constructor(device, shader) {\n        this.device = device;\n        this.shader = shader;\n        this.vertexShaderModule = this.device.createShaderModule({\n            code: shader.vertex\n        });\n        this.fragmentShaderModule = this.device.createShaderModule({\n            code: shader.fragment\n        });\n    }\n    /**\n     * Creates an IMaterialShader object from the provided shader code and entry points.\n     * @param vertex - The vertex shader code as a Uint32Array.\n     * @param fragment - The fragment shader code as a Uint32Array.\n     * @param vertexEntryPoint - The entry point function name for the vertex shader.\n     * @param fragmentEntryPoint - The entry point function name for the fragment shader.\n     * @returns The created IMaterialShader object.\n     */\n    static createMaterialShader(vertex, fragment, vertexEntryPoint, fragmentEntryPoint) {\n        return {\n            fragment: fragment,\n            fragmentEntryPoint: fragmentEntryPoint,\n            vertex: vertex,\n            vertexEntryPoint: vertexEntryPoint\n        };\n    }\n}\nexports.Material = Material;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGPU/material.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGPU/renderPassBuilder.js":
/*!**********************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGPU/renderPassBuilder.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RenderPassBuilder = void 0;\n/**\n * A builder class for creating render passes in WebGPU.\n */\nclass RenderPassBuilder {\n    /**\n  * Creates a new RenderPassBuilder.\n  * @param device - The GPUDevice to use for creating resources.\n  * @param canvas - The HTMLCanvasElement to render to.\n  */\n    constructor(device, canvas) {\n        this.canvas = canvas;\n        this.device = device;\n    }\n    /**\n   * Creates a bind group layout and entries for a render pipeline.\n   * @param uniformBuffer - The uniform buffer for the pipeline.\n   * @param sampler - An optional GPUSampler to use. If not provided, a default sampler is created.\n   * @returns An array of GPUBindGroupEntry objects.\n   */\n    getRenderPiplelineBindingGroupLayout(uniformBuffer, sampler) {\n        const bindingGroupEntrys = [];\n        bindingGroupEntrys.push({\n            binding: 0,\n            resource: {\n                buffer: uniformBuffer\n            }\n        });\n        const defaultSampler = this.device.createSampler({\n            addressModeU: 'repeat',\n            addressModeV: 'repeat',\n            magFilter: 'linear',\n            minFilter: 'nearest'\n        });\n        bindingGroupEntrys.push({\n            binding: 1,\n            resource: sampler || defaultSampler\n        });\n        return bindingGroupEntrys;\n    }\n    /**\n  * Creates a render pipeline.\n  * @param material - The material to use for the pipeline.\n  * @param geometry - The geometry to use for the pipeline.\n  * @param textures - An array of textures to use in the pipeline.\n  * @param priorRenderPasses - An array of prior render passes to include as textures.\n  * @returns The created GPURenderPipeline.\n  */\n    createRenderPipeline(material, geometry, textures, priorRenderPasses) {\n        const bindGroupLayoutEntries = new Array();\n        // add uniforms\n        bindGroupLayoutEntries.push({\n            binding: 0,\n            visibility: GPUShaderStage.COMPUTE | GPUShaderStage.FRAGMENT,\n            buffer: {\n                type: \"uniform\"\n            }\n        });\n        // add sampler\n        bindGroupLayoutEntries.push({\n            binding: 1,\n            visibility: GPUShaderStage.COMPUTE | GPUShaderStage.FRAGMENT,\n            sampler: {\n                type: \"filtering\"\n            }\n        });\n        let offset = bindGroupLayoutEntries.length;\n        // add prior render passes\n        priorRenderPasses.forEach((p, index) => {\n            bindGroupLayoutEntries.push({\n                binding: offset + index,\n                visibility: GPUShaderStage.FRAGMENT,\n                texture: {}\n            });\n        });\n        offset = bindGroupLayoutEntries.length;\n        if (textures.length > 0) {\n            for (let i = 0; i < textures.length; i++) { //  1-n texture bindings\n                if (textures[i].type === 0) {\n                    bindGroupLayoutEntries.push({\n                        binding: 2 + i,\n                        visibility: GPUShaderStage.FRAGMENT,\n                        texture: {\n                            sampleType: \"float\"\n                        }\n                    });\n                }\n                else {\n                    bindGroupLayoutEntries.push({\n                        binding: 2 + i,\n                        visibility: GPUShaderStage.FRAGMENT,\n                        externalTexture: {}\n                    });\n                }\n            }\n        }\n        const bindGroupLayout = this.device.createBindGroupLayout({\n            entries: bindGroupLayoutEntries\n        });\n        const pipeline = this.device.createRenderPipeline({\n            layout: this.device.createPipelineLayout({\n                bindGroupLayouts: [bindGroupLayout],\n            }),\n            vertex: {\n                module: material.vertexShaderModule,\n                entryPoint: \"main_vertex\",\n                buffers: [geometry.vertexBufferLayout(0)]\n            },\n            fragment: {\n                module: material.fragmentShaderModule,\n                entryPoint: \"main_fragment\",\n                targets: [\n                    {\n                        format: 'bgra8unorm'\n                    }\n                ]\n            }\n        });\n        return pipeline;\n    }\n    /**\n     * Creates a compute pipeline.\n     * @param computeShader - The compute shader module.\n     * @param textures - An array of textures to use in the pipeline.\n     * @returns The created GPUComputePipeline.\n     */\n    createComputePipeline(computeShader, textures) {\n        const bindGroupLayoutEntries = new Array();\n        bindGroupLayoutEntries.push({\n            binding: 0,\n            visibility: GPUShaderStage.COMPUTE,\n            storageTexture: {\n                access: \"write-only\",\n                format: \"bgra8unorm\",\n                viewDimension: \"2d\"\n            },\n        }, {\n            binding: 1, visibility: GPUShaderStage.COMPUTE,\n            buffer: {\n                type: \"uniform\"\n            }\n        });\n        if (textures.length > 0) {\n            for (let i = 0; i < textures.length; i++) { //  1-n texture bindings\n                if (textures[i].type === 0) {\n                    bindGroupLayoutEntries.push({\n                        binding: 3 + i,\n                        visibility: window.GPUShaderStage.COMPUTE,\n                        texture: {\n                            sampleType: \"float\"\n                        }\n                    });\n                }\n                else {\n                    bindGroupLayoutEntries.push({\n                        binding: 3 + i,\n                        visibility: window.GPUShaderStage.COMPUTE,\n                        externalTexture: {}\n                    });\n                }\n            }\n        }\n        const bindGroupLayout = this.device.createBindGroupLayout({\n            entries: bindGroupLayoutEntries\n        });\n        const pipeline = this.device.createComputePipeline({\n            layout: this.device.createPipelineLayout({\n                bindGroupLayouts: [bindGroupLayout],\n            }),\n            compute: {\n                module: computeShader,\n                entryPoint: 'main',\n            },\n        });\n        return pipeline;\n    }\n}\nexports.RenderPassBuilder = RenderPassBuilder;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGPU/renderPassBuilder.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGPU/textureLoader.js":
/*!******************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGPU/textureLoader.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TextureLoader = void 0;\n/**\n * A helper class for loading and creating textures for WebGPU.\n */\nclass TextureLoader {\n    /**\n     * Loads an array of textures and returns an array of ITextureData.\n     * @param device - The GPUDevice to use for creating textures.\n     * @param textures - An array of ITexture objects.\n     * @returns A Promise that resolves to an array of ITextureData.\n     */\n    static async loadAll(device, ...textures) {\n        return Promise.all(textures.map(async (texture) => {\n            if (texture.type === 0) {\n                return { type: 0, data: await this.createImageTexture(device, texture) };\n            }\n            else {\n                return { type: 1, data: await this.createVideoTexture(device, texture) };\n            }\n        }));\n    }\n    /**\n     * Creates a GPUTexture from an image.\n     * @param device - The GPUDevice to use for creating the texture.\n     * @param texture - The ITexture object containing the image source.\n     * @returns A Promise that resolves to the created GPUTexture.\n     */\n    static async createImageTexture(device, texture) {\n        const image = new Image();\n        image.src = texture.source;\n        await image.decode();\n        const imageBitmap = await createImageBitmap(image);\n        const textureSize = { width: image.width, height: image.height };\n        const gpuTexture = device.createTexture({\n            label: texture.key,\n            size: textureSize,\n            dimension: '2d',\n            format: 'rgba8unorm',\n            usage: GPUTextureUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING\n        });\n        device.queue.copyExternalImageToTexture({ source: imageBitmap }, { texture: gpuTexture, mipLevel: 0 }, textureSize);\n        return gpuTexture;\n    }\n    /**\n     * Creates a HTMLVideoElement for video textures.\n     * @param device - The GPUDevice.\n     * @param texture - The ITexture object containing the video source.\n     * @returns A Promise that resolves to the HTMLVideoElement.\n     */\n    static async createVideoTexture(device, texture) {\n        const video = document.createElement(\"video\");\n        video.loop = true;\n        video.autoplay = true;\n        video.muted = true;\n        if (texture.source instanceof MediaStream) {\n            video.srcObject = texture.source;\n        }\n        else {\n            video.src = texture.source;\n        }\n        await video.play();\n        return video;\n    }\n}\nexports.TextureLoader = TextureLoader;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGPU/textureLoader.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGPU/uniforms.js":
/*!*************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGPU/uniforms.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Uniforms = void 0;\nclass Uniforms {\n    static initialize(w, h) {\n        return new Float32Array([w, h, 0, 1, 0, 0, 0, 0, 0, 0]);\n    }\n    constructor(device, canvas) {\n        this.device = device;\n        this.uniformBuffer = this.device.createBuffer({\n            size: 60,\n            usage: window.GPUBufferUsage.UNIFORM | window.GPUBufferUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT,\n        });\n        this.uniformBufferArray = new Float32Array([canvas.width, canvas.height, 0, 1, 0, 0, 0, 0, 0, 0]);\n    }\n    setUniforms(values, offset) {\n        this.uniformBufferArray.set(values, offset);\n    }\n    updateUniformBuffer() {\n        this.device.queue.writeBuffer(this.uniformBuffer, 0, this.uniformBufferArray.buffer, this.uniformBufferArray.byteOffset, this.uniformBufferArray.byteLength);\n    }\n}\nexports.Uniforms = Uniforms;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGPU/uniforms.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGPU/wgslShaderRenderer.js":
/*!***********************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGPU/wgslShaderRenderer.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WGLSLShaderRenderer = exports.initWebGPU = void 0;\nconst uniforms_1 = __webpack_require__(/*! ./uniforms */ \"./build/src/Engine/ShaderRenderers/WebGPU/uniforms.js\");\nconst material_1 = __webpack_require__(/*! ./material */ \"./build/src/Engine/ShaderRenderers/WebGPU/material.js\");\nconst textureLoader_1 = __webpack_require__(/*! ./textureLoader */ \"./build/src/Engine/ShaderRenderers/WebGPU/textureLoader.js\");\nconst IPass_1 = __webpack_require__(/*! ../../Interfaces/IPass */ \"./build/src/Engine/Interfaces/IPass.js\");\nconst renderPassBuilder_1 = __webpack_require__(/*! ./renderPassBuilder */ \"./build/src/Engine/ShaderRenderers/WebGPU/renderPassBuilder.js\");\nconst geometry_1 = __webpack_require__(/*! ./geometry */ \"./build/src/Engine/ShaderRenderers/WebGPU/geometry.js\");\nconst initWebGPU = async (canvas) => {\n    var _a;\n    const adapter = await ((_a = navigator.gpu) === null || _a === void 0 ? void 0 : _a.requestAdapter());\n    const hasBGRA8unormStorage = adapter.features.has('bgra8unorm-storage');\n    const device = await (adapter === null || adapter === void 0 ? void 0 : adapter.requestDevice({\n        requiredFeatures: hasBGRA8unormStorage\n            ? ['bgra8unorm-storage']\n            : [],\n    }));\n    if (!device)\n        throw \"need a browser that supports WebGPU\";\n    const context = canvas.getContext(\"webgpu\");\n    context === null || context === void 0 ? void 0 : context.configure({\n        device,\n        format: hasBGRA8unormStorage\n            ? navigator.gpu.getPreferredCanvasFormat()\n            : 'rgba8unorm',\n        usage: GPUTextureUsage.TEXTURE_BINDING |\n            GPUTextureUsage.STORAGE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT,\n    });\n    return { device, context };\n};\nexports.initWebGPU = initWebGPU;\n/**\n * The Renderer class is responsible for managing the WebGPU rendering context,\n * creating and executing render passes, and handling resources like buffers and textures.\n */\nclass WGLSLShaderRenderer {\n    constructor(canvas, device, context, geometry) {\n        this.canvas = canvas;\n        this.device = device;\n        this.context = context;\n        this.frameCount = 0;\n        this.frame = 0;\n        this.zoomLevel = 1.;\n        this.renderPassBacklog = new Map();\n        this.textures = new Array();\n        this.renderPassBuilder = new renderPassBuilder_1.RenderPassBuilder(device, this.canvas);\n        this.geometry = new geometry_1.Geometry(device, geometry || geometry_1.rectGeometry);\n        this.uniforms = new uniforms_1.Uniforms(this.device, this.canvas);\n    }\n    /**\n  * Gets the WebGPU device.\n  * @returns The GPUDevice.\n  * @throws Error if the device is not initialized.\n  */\n    getDevice() {\n        if (!this.device)\n            throw \"Cannot get the GPUDevice\";\n        return this.device;\n    }\n    /**\n   * Creates a render pipeline for a given material.\n   * @param uniformBuffer - The uniform buffer for the pipeline.\n   * @param material - The material to use for the pipeline.\n   * @returns The created GPURenderPipeline.\n   */\n    creatRenderPipeline(uniformBuffer, material) {\n        const bindingGroupEntrys = [];\n        const sampler = this.getDevice().createSampler({\n            addressModeU: 'repeat',\n            addressModeV: 'repeat',\n            magFilter: 'linear',\n            minFilter: 'nearest'\n        });\n        bindingGroupEntrys.push({\n            binding: 0,\n            resource: sampler\n        }, {\n            binding: 1,\n            resource: {\n                buffer: uniformBuffer\n            }\n        });\n        const layout = new Array();\n        layout.push({\n            binding: 0,\n            visibility: GPUShaderStage.FRAGMENT,\n            sampler: {}\n        }, {\n            binding: 1,\n            visibility: GPUShaderStage.FRAGMENT,\n            buffer: {\n                type: \"uniform\"\n            }\n        });\n        const pipleline_group_layout = this.getDevice().createBindGroupLayout({\n            entries: layout\n        });\n        const pipeline_layout = this.getDevice().createPipelineLayout({\n            bindGroupLayouts: [pipleline_group_layout]\n        });\n        const pipelineDescriptor = {\n            vertex: {\n                module: material.vertexShaderModule,\n                entryPoint: material.shader.vertexEntryPoint || 'main_vertex',\n                buffers: [this.geometry.vertexBufferLayout(0)]\n            },\n            fragment: {\n                module: material.fragmentShaderModule,\n                entryPoint: material.shader.fragmentEntryPoint || 'main_fragment',\n                targets: [{\n                        format: 'bgra8unorm'\n                    }]\n            },\n            primitive: {\n                topology: 'triangle-list',\n            },\n            layout: pipeline_layout\n        };\n        return this.getDevice().createRenderPipeline(pipelineDescriptor);\n    }\n    /**\n   * Creates a main render pipeline for a given material.\n   * @param uniformBuffer - The uniform buffer for the pipeline.\n   * @param material - The material to use for the pipeline.\n   * @returns The created GPURenderPipeline.\n   */\n    createMainRenderPipeline(uniformBuffer, material) {\n        const bindingGroupEntrys = [];\n        const sampler = this.getDevice().createSampler({\n            addressModeU: 'repeat',\n            addressModeV: 'repeat',\n            magFilter: 'linear',\n            minFilter: 'nearest'\n        });\n        bindingGroupEntrys.push({\n            binding: 0,\n            resource: sampler\n        }, {\n            binding: 1,\n            resource: {\n                buffer: uniformBuffer\n            }\n        });\n        const layout = new Array();\n        layout.push({\n            binding: 0,\n            visibility: GPUShaderStage.FRAGMENT,\n            sampler: {}\n        }, {\n            binding: 1,\n            visibility: GPUShaderStage.FRAGMENT,\n            buffer: {\n                type: \"uniform\"\n            }\n        });\n        const renderPasses = Array.from(this.renderPassBacklog.values());\n        renderPasses.forEach((pass, i) => {\n            bindingGroupEntrys.push({\n                binding: 2 + i,\n                resource: pass.bufferView\n            });\n            layout.push({\n                binding: 2 + i,\n                visibility: GPUShaderStage.FRAGMENT,\n                texture: {}\n            });\n        });\n        const screen_bind_group_layout = this.getDevice().createBindGroupLayout({\n            entries: layout\n        });\n        this.screen_bind_group = this.getDevice().createBindGroup({\n            layout: screen_bind_group_layout,\n            entries: bindingGroupEntrys\n        });\n        const screen_pipeline_layout = this.getDevice().createPipelineLayout({\n            bindGroupLayouts: [screen_bind_group_layout]\n        });\n        const pipelineDescriptor = {\n            vertex: {\n                module: material.vertexShaderModule,\n                entryPoint: material.shader.vertexEntryPoint || 'main_vertex',\n                buffers: [this.geometry.vertexBufferLayout(0)]\n            },\n            fragment: {\n                module: material.fragmentShaderModule,\n                entryPoint: material.shader.fragmentEntryPoint || 'main_fragment',\n                targets: [{\n                        format: 'bgra8unorm'\n                    }]\n            },\n            primitive: {\n                topology: 'triangle-list',\n            },\n            layout: screen_pipeline_layout\n        };\n        return this.getDevice().createRenderPipeline(pipelineDescriptor);\n    }\n    /**\n   * Creates render targets for the pipeline.\n   * @returns An object containing the texture and texture view for the render target.\n   */\n    createAssets() {\n        const buffer = this.getDevice().createTexture({\n            size: {\n                width: this.canvas.width,\n                height: this.canvas.height,\n            },\n            format: \"bgra8unorm\",\n            usage: GPUTextureUsage.COPY_DST | GPUTextureUsage.STORAGE_BINDING | GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT\n        });\n        return { buffer, bufferView: buffer.createView() };\n    }\n    /**\n     * Creates a buffer on the GPU.\n     * @param arr - The data to store in the buffer.\n     * @param usage - The usage flags for the buffer.\n     * @param vertexSize - The size of each vertex in bytes.\n     * @returns The created GPUBuffer.\n     */\n    createBuffer(arr, usage, vertexSize) {\n        let bufferDescriptor = {\n            size: (arr.byteLength + vertexSize) & ~vertexSize,\n            usage,\n            mappedAtCreation: true\n        };\n        let buffer = this.getDevice().createBuffer(bufferDescriptor);\n        const writeArray = arr instanceof Uint16Array\n            ? new Uint16Array(buffer.getMappedRange())\n            : new Float32Array(buffer.getMappedRange());\n        writeArray.set(arr);\n        buffer.unmap();\n        return buffer;\n    }\n    /**\n   * Adds a main render pass to the backlog.\n   * @param material - The material to use for the render pass.\n   */\n    addMainRenderPass(shader) {\n        const material = new material_1.Material(this.device, shader);\n        this.renderPipleline = this.createMainRenderPipeline(this.uniforms.uniformBuffer, material);\n    }\n    /**\n   * Adds a render pass to the backlog.\n   * @param label - The label for the render pass.\n   * @param material - The material to use for the render pass.\n   * @param geometry - The geometry to use for the render pass.\n   * @param textures - An optional array of textures to use in the render pass.\n   */\n    addRenderPass(label, material, geometry, textures) {\n        textures === null || textures === void 0 ? void 0 : textures.forEach(texture => {\n            this.textures.push(texture);\n        });\n        const priorRenderPasses = Array.from(this.renderPassBacklog.values());\n        const uniforms = this.uniforms;\n        const renderPipeline = this.renderPassBuilder.createRenderPipeline(material, geometry, this.textures, priorRenderPasses);\n        const assets = this.createAssets();\n        const bindingGroupEntrys = [];\n        const sampler = this.getDevice().createSampler({\n            addressModeU: 'repeat',\n            addressModeV: 'repeat',\n            magFilter: 'linear',\n            minFilter: 'nearest'\n        });\n        bindingGroupEntrys.push({\n            binding: 0,\n            resource: {\n                buffer: uniforms.uniformBuffer\n            }\n        }, {\n            binding: 1,\n            resource: sampler\n        });\n        let offset = bindingGroupEntrys.length;\n        // Pass the previos renderpasses to current\n        priorRenderPasses.forEach((pass, i) => {\n            bindingGroupEntrys.push({\n                binding: offset + i,\n                resource: pass.bufferView,\n            });\n        });\n        // Add the bindings for the textures  \n        offset = bindingGroupEntrys.length;\n        this.textures.forEach((t, i) => {\n            let entry;\n            if (t.type === 0) {\n                entry = {\n                    binding: i + offset,\n                    resource: t.data.createView()\n                };\n            }\n            else {\n                entry = {\n                    binding: i + 2,\n                    resource: this.getDevice().importExternalTexture({ source: t.data }),\n                };\n            }\n            bindingGroupEntrys.push(entry);\n        });\n        const bindGroup = this.getDevice().createBindGroup({\n            layout: renderPipeline.getBindGroupLayout(0),\n            entries: bindingGroupEntrys,\n            label: `${label} renderpass`\n        });\n        const renderPass = new IPass_1.RenderPass(1, label, renderPipeline, uniforms, bindGroup, assets.buffer, assets.bufferView);\n        this.renderPassBacklog.set(label, renderPass); // send it the the renderpass backlog\n        return renderPass;\n    }\n    /**\n   * Adds a compute render pass to the backlog.\n   * @param label - The label for the compute pass.\n   * @param computeShaderCode - The WGSL code for the compute shader.\n   * @param textures - An optional array of textures to use in the compute pass.\n   */\n    async addComputeRenderPass(label, computeShaderCode, textures, samplers) {\n        if (samplers)\n            throw \"Samplers not yet implememted, using default binding 2\";\n        const shaderModule = this.getDevice().createShaderModule({ code: computeShaderCode });\n        const uniforms = this.uniforms; //new Uniforms(this.device, this.canvas);\n        if (textures) {\n            for (let i = 0; i < textures.length; i++) {\n                const texture = textures[i];\n                if (texture.type == 0) {\n                    this.textures.push({ type: 0, data: await textureLoader_1.TextureLoader.createImageTexture(this.getDevice(), texture) });\n                }\n                else\n                    this.textures.push({ type: 1, data: await textureLoader_1.TextureLoader.createVideoTexture(this.getDevice(), texture) });\n            }\n        }\n        const computePipeline = this.renderPassBuilder.createComputePipeline(shaderModule, this.textures);\n        const assets = this.createAssets();\n        const bindingGroupEntrys = [];\n        const sampler = this.getDevice().createSampler({\n            addressModeU: 'repeat',\n            addressModeV: 'repeat',\n            magFilter: 'linear',\n            minFilter: 'nearest'\n        });\n        bindingGroupEntrys.push({\n            binding: 0,\n            resource: assets.bufferView\n        }, {\n            binding: 1,\n            resource: {\n                buffer: uniforms.uniformBuffer\n            }\n        });\n        const offset = bindingGroupEntrys.length;\n        this.textures.forEach((t, i) => {\n            let entry;\n            if (t.type === 0) {\n                entry = {\n                    binding: i + offset,\n                    resource: t.data.createView()\n                };\n            }\n            else {\n                entry = {\n                    binding: i + 2,\n                    resource: this.getDevice().importExternalTexture({ source: t.data }),\n                };\n            }\n            bindingGroupEntrys.push(entry);\n        });\n        const bindGroup = this.getDevice().createBindGroup({\n            layout: computePipeline.getBindGroupLayout(0),\n            entries: bindingGroupEntrys,\n            label: `${label} computepass`\n        });\n        const renderPass = new IPass_1.RenderPass(0, label, computePipeline, uniforms, bindGroup, assets.buffer, assets.bufferView);\n        this.renderPassBacklog.set(label, renderPass);\n    }\n    /**\n   * Updates the renderer and executes all render passes in the backlog.\n   * @param time - The current time in seconds.\n   */\n    update(ts) {\n        const encoder = this.getDevice().createCommandEncoder();\n        const arrRenderPasses = Array.from(this.renderPassBacklog.values());\n        // get the compute shaders from the back log\n        arrRenderPasses.filter((pre) => {\n            return pre.type == 0;\n        }).forEach(pass => {\n            const computePass = encoder.beginComputePass();\n            computePass.setPipeline(pass.pipleline);\n            computePass.setBindGroup(0, pass.bindGroup);\n            computePass.dispatchWorkgroups(Math.floor((this.canvas.width + 7) / 8), Math.floor((this.canvas.height + 7) / 8), 1);\n            computePass.end();\n        });\n        arrRenderPasses.filter(pre => {\n            return pre.type == 1;\n        }).forEach(pass => {\n            const renderPassDescriptor = {\n                colorAttachments: [{\n                        loadOp: 'clear',\n                        storeOp: 'store',\n                        view: pass.bufferView,\n                        clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },\n                    }]\n            };\n            const renderPass = encoder.beginRenderPass(renderPassDescriptor);\n            renderPass.setPipeline(pass.pipleline);\n            renderPass.setBindGroup(0, pass.bindGroup);\n            renderPass.setVertexBuffer(0, this.geometry.vertexBuffer);\n            renderPass.setIndexBuffer(this.geometry.indexBuffer, 'uint16');\n            renderPass.drawIndexed(this.geometry.numOfVerticles, 1);\n            renderPass.end();\n        });\n        const mainRenderer = encoder.beginRenderPass({\n            colorAttachments: [{\n                    view: this.context.getCurrentTexture().createView(),\n                    clearValue: { r: 0.0, g: 0, b: 0.0, a: 1 },\n                    loadOp: \"clear\",\n                    storeOp: \"store\"\n                }]\n        });\n        this.uniforms.setUniforms([this.frame], 8);\n        this.uniforms.setUniforms([ts], 3);\n        this.uniforms.updateUniformBuffer();\n        mainRenderer.setPipeline(this.renderPipleline);\n        mainRenderer.setVertexBuffer(0, this.geometry.vertexBuffer);\n        mainRenderer.setBindGroup(0, this.screen_bind_group);\n        mainRenderer.draw(6, 1, 0, 0);\n        mainRenderer.end();\n        this.getDevice().queue.submit([encoder.finish()]);\n    }\n    /**\n   * Starts the rendering loop.\n   * @param t - The initial time.\n   * @param maxFps - The maximum frames per second.\n   * @param onFrame - An optional callback function to be called on each frame.\n   */\n    start(t, maxFps = 200, onFrame) {\n        let startTime = null;\n        let frame = -1;\n        const renderLoop = (ts) => {\n            if (!startTime)\n                startTime = ts;\n            let segment = Math.floor((ts - startTime) / (1000 / maxFps));\n            if (segment > frame) {\n                frame = segment;\n                this.frame = segment;\n                this.frameCount = frame;\n                if (!this.isPaused) {\n                    this.update(ts / 1000);\n                    if (onFrame)\n                        onFrame(frame);\n                }\n            }\n            requestAnimationFrame(renderLoop);\n        };\n        renderLoop(t);\n    }\n    pause() {\n        this.isPaused = !this.isPaused;\n    }\n    clear() {\n        this.renderPassBacklog.clear();\n    }\n}\nexports.WGLSLShaderRenderer = WGLSLShaderRenderer;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGPU/wgslShaderRenderer.js?");

/***/ }),

/***/ "./build/src/Engine/WGLShaderEntity.js":
/*!*********************************************!*\
  !*** ./build/src/Engine/WGLShaderEntity.js ***!
  \*********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WGLSLShaderEntity = void 0;\nconst wgslShaderRenderer_1 = __webpack_require__(/*! ./ShaderRenderers/WebGPU/wgslShaderRenderer */ \"./build/src/Engine/ShaderRenderers/WebGPU/wgslShaderRenderer.js\");\nclass WGLSLShaderEntity {\n    constructor(name, props, action, w, h, startTimeinMs, durationInMs) {\n        var _a, _b;\n        this.name = name;\n        this.props = props;\n        this.action = action;\n        this.w = w;\n        this.h = h;\n        this.startTimeinMs = startTimeinMs;\n        this.durationInMs = durationInMs;\n        this.beatListeners = [];\n        this.tickListeners = [];\n        this.barListeners = [];\n        this.canvas = props === null || props === void 0 ? void 0 : props.canvas;\n        if (props === null || props === void 0 ? void 0 : props.shader) {\n            this.shaderRenderer = new wgslShaderRenderer_1.WGLSLShaderRenderer(this.canvas, (_a = this.props) === null || _a === void 0 ? void 0 : _a.device, (_b = this.props) === null || _b === void 0 ? void 0 : _b.context);\n            props.renderBuffers.forEach((buffer, index) => {\n                this.shaderRenderer.addRenderPass(buffer.name, buffer.shader, buffer.geometry, buffer.textures);\n            });\n            this.shaderRenderer.addMainRenderPass(props.shader);\n        }\n        else {\n            throw new Error(\"Cannot create WGSLShaderEntity: Missing main shader code.\");\n        }\n    }\n    bindToScene(scene) {\n        this.scene = scene;\n    }\n    /**\n * Adds an event listener for when a beat occurs.\n * @param listener - The function to call when a beat occurs.\n * @returns The Entity instance for chaining.\n */\n    onBeat(listener) {\n        this.beatListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds an event listener for when a tick occurs.\n     * @param listener - The function to call when a tick occurs.\n     * @returns The Entity instance for chaining.\n     */\n    onTick(listener) {\n        this.tickListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds an event listener for when a bar is complete.\n     * @param listener - The function to call when a bar is complete.\n     * @returns The Entity instance for chaining.\n     */\n    onBar(listener) {\n        this.barListeners.push(listener);\n        return this;\n    }\n    /**\n     * Updates the ShaderEntity by calling the action function (if provided)\n     * and then updating the ShaderRenderer.\n     * @param timeStamp - The current timestamp in the animation.\n     */\n    update(timeStamp) {\n        if (this.action && this.shaderRenderer && this.props) {\n            // Calculate elapsed time relative to the scene's start time\n            const sceneStartTime = this.scene ? this.scene.startTimeinMs : 0;\n            const elapsed = timeStamp - sceneStartTime - (this.startTimeinMs || 0);\n            if (elapsed >= 0 && elapsed <= (this.durationInMs || Infinity)) {\n                this.action(timeStamp, this.shaderRenderer, this.props);\n                // Calculate shader time relative to the entity's start time (within the scene)\n                const shaderTime = Math.max(0, elapsed);\n                this.shaderRenderer.update(shaderTime / 1000);\n            }\n        }\n    }\n    /**\n     * Copies the entity's canvas to the target canvas.\n     * @param targetCanvas - The target canvas to copy to.\n     */\n    copyToCanvas(targetCanvas, sequence) {\n        const targetCtx = targetCanvas.getContext(\"2d\");\n        if (targetCtx) {\n            // Calculate the elapsed time for the entity\n            const elapsed = sequence.currentTime - (this.startTimeinMs || 0);\n            // Check if the entity should be rendered based on its lifetime\n            if (elapsed >= 0 && elapsed <= (this.durationInMs || Infinity)) {\n                targetCtx.drawImage(this.canvas, 0, 0);\n            }\n        }\n    }\n}\nexports.WGLSLShaderEntity = WGLSLShaderEntity;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/WGLShaderEntity.js?");

/***/ }),

/***/ "./build/src/Engine/entity.js":
/*!************************************!*\
  !*** ./build/src/Engine/entity.js ***!
  \************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Entity = void 0;\nclass Entity {\n    /**\n     * Creates a new Entity.\n     * @param name - The key or identifier for the entity.\n     * @param w - The width of the entity's canvas.\n     * @param h - The height of the entity's canvas.\n     * @param props - The properties for the entity.\n     * @param action - The action function that defines the entity's behavior.\n     */\n    constructor(name, props, action, startTimeinMs, durationInMs, w, h) {\n        this.name = name;\n        this.props = props;\n        this.action = action;\n        this.startTimeinMs = startTimeinMs;\n        this.durationInMs = durationInMs;\n        this.w = w;\n        this.h = h;\n        this.postProcessors = [];\n        this.beatListeners = [];\n        this.tickListeners = [];\n        this.barListeners = [];\n        this.canvas = document.createElement(\"canvas\");\n        if (w !== undefined && h !== undefined) {\n            this.canvas.width = w;\n            this.canvas.height = h;\n        }\n        ;\n        this.ctx = this.canvas.getContext(\"2d\");\n    }\n    bindToScene(scene) {\n        this.scene = scene;\n    }\n    /**\n    * Adds an event listener for when a beat occurs.\n    * @param listener - The function to call when a beat occurs.\n    * @returns The Entity instance for chaining.\n    */\n    onBeat(listener) {\n        this.beatListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds an event listener for when a tick occurs.\n     * @param listener - The function to call when a tick occurs.\n     * @returns The Entity instance for chaining.\n     */\n    onTick(listener) {\n        this.tickListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds an event listener for when a bar is complete.\n     * @param listener - The function to call when a bar is complete.\n     * @returns The Entity instance for chaining.\n     */\n    onBar(listener) {\n        this.barListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds a post-processing function to the entity.\n     * @param processor - The post-processing function to add.\n     */\n    addPostProcessor(processor) {\n        this.postProcessors.push(processor);\n    }\n    /**\n     * Copies the entity's canvas to the target canvas and applies post-processors.\n     * @param targetCanvas - The target canvas to copy to.\n     * @param sequence - The Sequence instance.\n     */\n    copyToCanvas(targetCanvas, sequence) {\n        const targetCtx = targetCanvas.getContext(\"2d\");\n        if (targetCtx) {\n            // Calculate the elapsed time for the entity\n            const elapsed = sequence.currentTime - (this.startTimeinMs || 0);\n            // Check if the entity should be rendered based on its lifetime\n            if (elapsed >= 0 && elapsed <= (this.durationInMs || Infinity)) {\n                targetCtx.drawImage(this.canvas, 0, 0);\n                this.postProcessors.forEach(processor => processor(targetCtx, sequence));\n            }\n        }\n    }\n    /**\n    * Updates the entity's state, clears the canvas, and calls the action function.\n    * @param timeStamp - The current timestamp in the animation.\n    */\n    update(timeStamp) {\n        var _a;\n        (_a = this.ctx) === null || _a === void 0 ? void 0 : _a.clearRect(0, 0, this.canvas.width, this.canvas.height);\n        if (this.action && this.ctx && this.props) {\n            // Calculate elapsed time relative to the scene's start time    \n            const sceneStartTime = this.getScene().startTimeinMs || 0;\n            const elapsed = timeStamp - sceneStartTime - (this.startTimeinMs || 0);\n            if (elapsed >= 0 && elapsed <= (this.durationInMs || Infinity)) {\n                this.action(timeStamp, this.ctx, this.props);\n            }\n        }\n    }\n    /**\n   * Retrieves the Sequence instance associated with the entity.\n   * @returns The Sequence instance if available, otherwise null.\n   */\n    getScene() {\n        return this.scene;\n    }\n}\nexports.Entity = Entity;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/entity.js?");

/***/ }),

/***/ "./build/src/Engine/scene.js":
/*!***********************************!*\
  !*** ./build/src/Engine/scene.js ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Scene = void 0;\nconst entity_1 = __webpack_require__(/*! ./entity */ \"./build/src/Engine/entity.js\");\nclass Scene {\n    /**\n     * Creates a new Scene.\n     * @param name - The name or identifier for the scene.\n     * @param startTimeinMs - The start time of the scene in milliseconds.\n     * @param durationInMs - The duration of the scene in milliseconds.\n     */\n    constructor(name, startTimeinMs, durationInMs, width, height) {\n        this.name = name;\n        this.startTimeinMs = startTimeinMs;\n        this.durationInMs = durationInMs;\n        this.width = width;\n        this.height = height;\n        this.entities = [];\n        this.transitionOutListeners = [];\n        this.transitionInListeners = [];\n    }\n    /**\n     * Adds an entity to the scene.\n     * @param entity - The entity to add.\n     */\n    addEntity(entity) {\n        // If the entity's canvas dimensions are not set, use the scene's dimensions\n        if (!entity.w && !entity.h) {\n            entity.canvas.width = this.width || 800;\n            entity.canvas.height = this.height || 450;\n        }\n        entity.bindToScene(this);\n        this.entities.push(entity);\n    }\n    /**\n     * Adds multiple entities to the scene.\n     * @param entities - An array of entities to add.\n     * @returns The Scene instance for chaining.\n     */\n    addEntities(...entities) {\n        entities.forEach(entity => this.addEntity(entity));\n        return this;\n    }\n    /**\n     * Gets an entity from the scene by its key.\n     * @param key - The key of the entity to retrieve.\n     * @returns The entity if found, otherwise undefined.\n     */\n    getEntity(key) {\n        return this.entities.find(entity => entity.name === key);\n    }\n    /**\n     * Plays the scene by animating its entities.\n     * @param elapsedTime - The elapsed time in the animation sequence.\n     * @returns A promise that resolves when the scene has finished playing.\n     */\n    // play(elapsedTime: number): Promise<boolean> {\n    //   return new Promise((resolve) => {\n    //     const startTime = performance.now();\n    //     const animate = () => {\n    //       const currentTime = performance.now();\n    //       const sceneElapsedTime = currentTime - startTime + elapsedTime;\n    //       const adjustedSceneElapsedTime = sceneElapsedTime - this.startTimeinMs;\n    //       if (adjustedSceneElapsedTime >= 0) {\n    //         this.entities.forEach((entity) => {\n    //           entity.update(sceneElapsedTime);\n    //         });\n    //       }\n    //       if (sceneElapsedTime < this.durationInMs + this.startTimeinMs) {\n    //         // The requestAnimationFrame call was removed here. \n    //         // The animation loop is now handled in the Sequence class.\n    //       } else {\n    //         resolve(true);\n    //       }\n    //     };\n    //     animate(); // Call animate once to start the initial rendering\n    //   });\n    // }\n    addPostProcessorToEntities(processor) {\n        this.entities.forEach(entity => {\n            if (entity instanceof entity_1.Entity) { // Check if the entity is an instance of the Entity class\n                entity.addPostProcessor(processor);\n            }\n        });\n    }\n    /**\n      * Adds a transition-in effect to the scene.\n      * @param sequence - The Sequence instance associated with the scene.\n      * @param startTime - The time (in milliseconds) within the scene when the transition should start.\n      * @param duration - The duration of the transition in milliseconds.\n      * @param listener - The transition function to apply.\n      */\n    transitionIn(sequence, startTime, duration, listener) {\n        this.transitionInListeners.push(listener);\n        sequence.addSceneTransitionIn(this, startTime, duration, (ctx, scene, progress) => {\n            this.transitionInListeners.forEach(listener => listener(ctx, scene, progress));\n        });\n    }\n    /**\n    * Adds a transition-out effect to the scene.\n    * @param sequence - The Sequence instance associated with the scene.\n    * @param startTime - The time (in milliseconds) within the scene when the transition should start.\n    * @param duration - The duration of the transition in milliseconds.\n    * @param listener - The transition function to apply.\n    */\n    transitionOut(sequence, startTime, duration, listener) {\n        this.transitionOutListeners.push(listener);\n        sequence.addSceneTransitionOut(this, startTime, duration, (ctx, scene, progress) => {\n            this.transitionOutListeners.forEach(listener => listener(ctx, scene, progress));\n        });\n    }\n}\nexports.Scene = Scene;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/scene.js?");

/***/ }),

/***/ "./build/src/Engine/sequence.js":
/*!**************************************!*\
  !*** ./build/src/Engine/sequence.js ***!
  \**************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Sequence = void 0;\nclass Sequence {\n    /**\n* Sets the function to be used for resetting the rendering context when switching scenes.\n* @param resetFunction - The function to call to reset the context.\n*/\n    setContextResetFunction(resetFunction) {\n        this.resetContext = resetFunction;\n    }\n    /**\n     * Adds a transition-out listener for a specific scene.\n     * @param scene - The scene to add the listener to.\n     * @param startTime - The time (in milliseconds) relative to the end of the scene when the transition should start.\n     * @param listener - The transition function to apply.\n     */\n    addSceneTransitionOut(scene, startTime, duration, listener) {\n        this.sceneTransitionOutListeners.push({ scene, startTime, duration, listener });\n    }\n    /**\n     * Adds a transition-in listener for a specific scene.\n     * @param scene - The scene to add the listener to.\n     * @param startTime - The time (in milliseconds) within the scene when the transition should start.\n     * @param listener - The transition function to apply.\n     */\n    addSceneTransitionIn(scene, startTime, duration, listener) {\n        this.sceneTransitionInListeners.push({ scene, startTime, duration, listener });\n    }\n    /**\n     * Adds a post-processing function to the sequence.\n     * @param processor - The post-processing function to add.\n     */\n    addPostProcessor(processor) {\n        this.postProcessors.push(processor);\n    }\n    /**\n     * Gets the remaining time in the current scene.\n     * @param timeStamp - The current timestamp in the animation.\n     * @returns The remaining time in milliseconds.\n     */\n    getSceneRemainingTime(timeStamp) {\n        if (!this.currentScene) {\n            return 0;\n        }\n        const elapsedTime = timeStamp - this.currentScene.startTimeinMs;\n        return Math.max(0, this.currentScene.durationInMs - elapsedTime);\n    }\n    /**\n     * Creates a new Sequence.\n     * @param target - The canvas element to render the animation on.\n     * @param bpm - The beats per minute for the animation.\n     * @param ticksPerBeat - The number of ticks per beat.\n     * @param beatsPerBar - The number of beats per bar.\n     * @param beatsPerBar - The number of beats per bar.\n     * @param scenes - An array of scenes to include in the sequence.\n     * @param audioFile - An array of scenes to include in the sequence.\n     * @param audioLoader\n    \n     \n     */\n    constructor(target, bpm = 120, ticksPerBeat = 4, beatsPerBar = 4, scenes, audioLoader) {\n        this.target = target;\n        this.durationMs = 0;\n        this.scenes = [];\n        this.currentSceneIndex = 0;\n        this.isPlaying = false;\n        this.startTime = 0;\n        this.currentTime = 0;\n        this.bpm = 0;\n        this.ticksPerBeat = 0;\n        this.lastBeatTime = 0;\n        this.currentTick = 0;\n        this.currentBar = 0;\n        this.tickCounter = 0;\n        this.beatCounter = 0;\n        this.beatsPerBar = 0;\n        this.currentBeat = 0;\n        this.previousBeat = 0; // Store the previous beat value\n        this.previousTick = 0; // Store the previous tick value\n        this.previousBar = 0; // Store the previous bar value\n        this.beatListeners = [];\n        this.tickListeners = [];\n        this.barListeners = [];\n        this.frameListeners = [];\n        this.postProcessors = [];\n        this.sceneTransitionInListeners = [];\n        this.sceneTransitionOutListeners = [];\n        this.resetContext = (ctx) => {\n            ctx.globalAlpha = 1; // Default reset function\n        };\n        this.scenes = scenes || [];\n        this.targetCtx = target.getContext(\"2d\");\n        this.bpm = bpm;\n        this.ticksPerBeat = ticksPerBeat;\n        this.beatsPerBar = beatsPerBar;\n        this.audioContext = new AudioContext();\n        this.analyser = this.audioContext.createAnalyser();\n        audioLoader.loadAudio(this.audioContext)\n            .then(audioBuffer => {\n            this.audioBuffer = audioBuffer;\n            this.onReady();\n        })\n            .catch(error => console.error(\"Error loading audio:\", error));\n        this.recalculateDuration();\n    }\n    /**\n     * Called when the audio file is loaded or when no audio is used.\n     */\n    onReady() { }\n    /**\n     * Adds an event listener for each frame.\n     * @param listener - The function to call on each frame.\n     */\n    onFrame(listener) {\n        this.frameListeners.push(listener);\n    }\n    /**\n     * Adds an event listener for when a bar is complete.\n     * @param listener - The function to call when a bar is complete.\n     */\n    onBar(listener) {\n        this.barListeners.push(listener);\n    }\n    /**\n     * Adds an event listener for when a beat occurs.\n     * @param listener - The function to call when a beat occurs.\n     */\n    onBeat(listener) {\n        this.beatListeners.push(listener);\n    }\n    /**\n     * Adds an event listener for when a tick occurs.\n     * @param listener - The function to call when a tick occurs.\n     */\n    onTick(listener) {\n        this.tickListeners.push(listener);\n    }\n    /**\n     * Adds a scene to the sequence.\n     * @param scene - The scene to add.\n     */\n    addScene(scene) {\n        if (!scene.width && scene.height) {\n            scene.width = this.target.width;\n            scene.height = this.target.height;\n        }\n        this.scenes.push(scene);\n        this.recalculateDuration();\n    }\n    /**\n     * Adds multiple scenes to the sequence.\n     * @param scenes - The scenes to add.\n     * @returns The Sequence instance for chaining.\n     */\n    addScenes(...scenes) {\n        this.scenes.push(...scenes);\n        this.recalculateDuration();\n        return this;\n    }\n    /**\n    * Adds multiple scenes to the sequence.\n    * @param scenes - The scenes to add.\n    * @returns The Sequence instance for chaining.\n    */\n    addSceneArray(scenes) {\n        this.scenes.push(...scenes);\n        this.recalculateDuration();\n        return this;\n    }\n    /**\n     * Removes a scene from the sequence.\n     * @param scene - The scene to remove.\n     */\n    removeScene(scene) {\n        this.scenes = this.scenes.filter((s) => s !== scene);\n        this.recalculateDuration();\n    }\n    /**\n     * Recalculates the total duration of the sequence.\n     */\n    recalculateDuration() {\n        this.durationMs = 0;\n        if (this.scenes.length > 0) {\n            this.durationMs = Math.max(...this.scenes.map((scene) => {\n                return scene.startTimeinMs + scene.durationInMs;\n            }));\n        }\n    }\n    /**\n     * Render a specific time\n     *\n     * @param {number} time\n     * @memberof Sequence\n     */\n    renderAtTime(time) {\n        var _a;\n        this.currentTime = time; // Update the currentTime\n        // Find the active scene for the given time\n        const currentSceneIndex = this.scenes.findIndex(scene => time >= scene.startTimeinMs && time < scene.startTimeinMs + scene.durationInMs);\n        if (currentSceneIndex !== -1) {\n            this.currentSceneIndex = currentSceneIndex;\n            const elapsedTime = time - this.currentScene.startTimeinMs;\n            // Update and draw entities\n            (_a = this.targetCtx) === null || _a === void 0 ? void 0 : _a.clearRect(0, 0, this.target.width, this.target.height);\n            this.currentScene.entities.forEach(entity => {\n                entity.update(time);\n                if (this.target) {\n                    entity.copyToCanvas(this.target, this);\n                }\n            });\n            // Apply post-processing\n            if (this.targetCtx) {\n                this.postProcessors.forEach(processor => processor(this.targetCtx, this));\n            }\n            this.triggerEventsForTime(time);\n        }\n    }\n    /**\n * Triggers beat, tick, and bar listeners for a given time.\n * @param time - The time in milliseconds.\n */\n    triggerEventsForTime(time) {\n        const beatIntervalMs = 60000 / this.bpm;\n        const tickIntervalMs = beatIntervalMs / this.ticksPerBeat;\n        // Calculate beat, tick, and bar values for the given time\n        const beat = Math.floor(time / beatIntervalMs) + 1;\n        const tick = Math.floor((time % beatIntervalMs) / tickIntervalMs);\n        const bar = Math.floor(beat / this.beatsPerBar) + 1;\n        // Trigger listeners if the values have changed\n        if (beat !== this.currentBeat) {\n            this.currentBeat = beat;\n            this.beatListeners.forEach(listener => listener(this.currentSceneIndex, time, this.beatCounter));\n            this.beatCounter++;\n        }\n        if (tick !== this.currentTick) {\n            this.currentTick = tick;\n            this.tickListeners.forEach(listener => listener(this.currentSceneIndex, time, this.tickCounter));\n            this.tickCounter++;\n        }\n        if (bar !== this.currentBar) {\n            this.currentBar = bar;\n            this.barListeners.forEach(listener => listener(this.currentBar));\n        }\n        // Trigger frame listeners\n        this.frameListeners.forEach(listener => listener(this.currentSceneIndex, time));\n    }\n    /**\n     * Starts the animation sequence.\n     */\n    play() {\n        this.isPlaying = true;\n        this.currentSceneIndex = 0;\n        this.lastBeatTime = 0;\n        this.currentTick = 0;\n        this.currentBeat = 0; // Initialize currentBeat to 0\n        this.startTime = performance.now();\n        if (this.audioBuffer) {\n            this.audioSource = this.audioContext.createBufferSource();\n            this.audioSource.buffer = this.audioBuffer;\n            this.audioSource.connect(this.analyser);\n            this.analyser.connect(this.audioContext.destination);\n            this.fftData = new Uint8Array(this.analyser.frequencyBinCount);\n            this.audioSource.start();\n        }\n        const animate = (ts) => {\n            const adjustedTimeStamp = ts - this.startTime;\n            this.playCurrentScene(adjustedTimeStamp);\n            if (this.isPlaying) {\n                this.requestAnimationFrameID = requestAnimationFrame(animate);\n            }\n        };\n        this.requestAnimationFrameID = requestAnimationFrame(animate);\n    }\n    /**\n     * Pauses\n   the animation sequence.\n     */\n    pause() {\n        this.isPlaying = false;\n        cancelAnimationFrame(this.requestAnimationFrameID);\n    }\n    /**\n     * Stops the animation sequence.\n     */\n    stop() {\n        this.isPlaying = false;\n        this.currentSceneIndex = 0;\n        cancelAnimationFrame(this.requestAnimationFrameID);\n    }\n    /**\n     * Gets the current scene being played.\n     * @returns The current Scene or undefined if no scene is active.\n     */\n    get currentScene() {\n        return this.scenes[this.currentSceneIndex];\n    }\n    /**\n  * Animates the current scene and handles scene transitions,\n  * audio analysis, and beat/tick events.\n  * @param timeStamp - The adjusted timestamp for the current frame.\n  */\n    playCurrentScene(timeStamp) {\n        var _a;\n        if (!this.isPlaying) {\n            return;\n        }\n        this.currentTime = timeStamp; // Update currentTime\n        // Determine the current scene based on timeStamp\n        let currentSceneIndex = this.scenes.findIndex(scene => timeStamp >= scene.startTimeinMs && timeStamp < scene.startTimeinMs + scene.durationInMs);\n        // If no current scene is found, check for upcoming scenes\n        if (currentSceneIndex === -1) {\n            currentSceneIndex = this.scenes.findIndex(scene => timeStamp < scene.startTimeinMs);\n            if (currentSceneIndex === -1) { // No upcoming scene, end animation\n                this.isPlaying = false;\n                return;\n            }\n            else { // Wait for the upcoming scene\n                return;\n            }\n        }\n        // If the scene has changed, update currentSceneIndex and play the new scene\n        if (this.currentSceneIndex !== currentSceneIndex) {\n            this.currentSceneIndex = currentSceneIndex;\n            // Reset the rendering context\n            this.resetContext(this.targetCtx);\n            // Set scene dimensions if not already set\n            if (!this.currentScene.width) {\n                this.currentScene.width = this.target.width;\n            }\n            if (!this.currentScene.height) {\n                this.currentScene.height = this.target.height;\n            }\n        }\n        // FFT analysis (if analyser is available)\n        if (this.analyser) {\n            this.analyser.getByteFrequencyData(this.fftData);\n        }\n        // Clear the target canvas and update/draw entities\n        (_a = this.targetCtx) === null || _a === void 0 ? void 0 : _a.clearRect(0, 0, this.target.width, this.target.height);\n        this.currentScene.entities.forEach(entity => {\n            var _a, _b;\n            // Update the conductor's time and trigger events\n            (_a = this.conductor) === null || _a === void 0 ? void 0 : _a.updateTime(timeStamp);\n            (_b = this.conductor) === null || _b === void 0 ? void 0 : _b.triggerEvents(this);\n            entity.update(timeStamp);\n            if (this.target) {\n                entity.copyToCanvas(this.target, this);\n            }\n            // Trigger entity events only when the values change\n            if (this.currentBeat !== this.previousBeat) {\n                entity.beatListeners.forEach(listener => listener(timeStamp, this.beatCounter, entity.props));\n                this.previousBeat = this.currentBeat;\n            }\n            if (this.currentTick !== this.previousTick) {\n                entity.tickListeners.forEach(listener => listener(timeStamp, this.tickCounter, entity.props));\n                this.previousTick = this.currentTick;\n            }\n            if (this.currentBar !== this.previousBar) {\n                entity.barListeners.forEach(listener => listener(timeStamp, this.currentBar, entity.props));\n                this.previousBar = this.currentBar;\n            }\n        });\n        // Apply post-processing effects\n        if (this.targetCtx) {\n            this.postProcessors.forEach(processor => processor(this.targetCtx, this));\n        }\n        this.sceneTransitionInListeners.forEach(({ scene, startTime, duration, listener }) => {\n            if (scene === this.currentScene) {\n                const sceneElapsedTime = this.currentTime - scene.startTimeinMs;\n                if (sceneElapsedTime >= startTime && sceneElapsedTime <= startTime + duration) {\n                    const transitionProgress = (sceneElapsedTime - startTime) / duration; // Calculate progress based on duration\n                    listener(this.targetCtx, scene, transitionProgress);\n                }\n            }\n        });\n        this.sceneTransitionOutListeners.forEach(({ scene, startTime, duration, listener }) => {\n            if (scene === this.currentScene) {\n                const sceneElapsedTime = this.currentTime - scene.startTimeinMs;\n                if (sceneElapsedTime >= startTime && sceneElapsedTime <= startTime + duration) {\n                    const transitionProgress = (sceneElapsedTime - startTime) / duration; // Calculate progress based on duration\n                    listener(this.targetCtx, scene, transitionProgress);\n                }\n            }\n        });\n        this.handleBeatAndTickEvents(timeStamp); // Handle beat and tick events\n        // Trigger frame listeners\n        this.frameListeners.forEach(listener => listener(this.currentSceneIndex, timeStamp));\n    }\n    /**\n     * Handles beat and tick events based on the current timestamp.\n     * @param timeStamp - The adjusted timestamp for the current frame.\n     */\n    handleBeatAndTickEvents(timeStamp) {\n        const beatIntervalMs = 60000 / this.bpm;\n        const tickIntervalMs = beatIntervalMs / this.ticksPerBeat;\n        if (timeStamp - this.lastBeatTime >= beatIntervalMs) {\n            this.lastBeatTime = timeStamp;\n            this.beatListeners.forEach(listener => listener(this.currentSceneIndex, timeStamp, this.beatCounter));\n            this.currentTick = 0;\n            this.currentBeat++;\n            this.beatCounter++;\n            if (this.currentBeat > this.beatsPerBar) {\n                this.currentBar++;\n                this.currentBeat = 1;\n                this.barListeners.forEach(listener => listener(this.currentBar));\n            }\n        }\n        if (timeStamp - this.lastBeatTime >= this.currentTick * tickIntervalMs) {\n            this.tickListeners.forEach(listener => listener(this.currentSceneIndex, timeStamp, this.tickCounter));\n            this.currentTick++;\n            this.tickCounter++;\n        }\n    }\n}\nexports.Sequence = Sequence;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/sequence.js?");

/***/ }),

/***/ "./build/wwwroot/assets/shaders/mainFragment.js":
/*!******************************************************!*\
  !*** ./build/wwwroot/assets/shaders/mainFragment.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.mainFragment = void 0;\nexports.mainFragment = `\r\nuniform vec2 resolution;\r\nuniform float time;\r\n\r\nuniform float sI;\r\n\r\nuniform sampler2D iChannel0;\r\nuniform sampler2D iChannel1;\r\nuniform sampler2D iChannel2;\r\nuniform sampler2D iChannel3;\r\nuniform sampler2D iChannel4;\r\n\r\nout vec4 fragColor;\r\n\r\n#define iTime time\r\n#define res resolution \r\n\r\n\r\n//-------------------------------------------------------------------------------------------\r\nvoid mainImage(out vec4 fragColor,in vec2 fragCoord)\r\n{\r\n\r\n\tvec4 color = vec4(vec3(0.),1.);\r\n\tvec2 uv = gl_FragCoord.xy / res.xy;\r\n\r\n\tcolor = texture(iChannel0,uv);\r\n\t\r\n\tfragColor = color; //multi1*multi2*blend2;\r\n\t\r\n}\r\n\r\nvoid main(){\r\n\r\n    mainImage(fragColor,gl_FragCoord.xy);\r\n\r\n}`;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/assets/shaders/mainFragment.js?");

/***/ }),

/***/ "./build/wwwroot/assets/shaders/mainVertex.js":
/*!****************************************************!*\
  !*** ./build/wwwroot/assets/shaders/mainVertex.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.mainVertex = void 0;\nexports.mainVertex = `\r\nlayout(location = 0) in vec2 pos; \r\nout vec4 fragColor;\r\nvoid main(){\r\n    gl_Position = vec4(pos.xy,0.0,1.0);\r\n}`;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/assets/shaders/mainVertex.js?");

/***/ }),

/***/ "./build/wwwroot/assets/shaders/pseudoKnightyanFractal.js":
/*!****************************************************************!*\
  !*** ./build/wwwroot/assets/shaders/pseudoKnightyanFractal.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.pseudoKnightyanFractal = void 0;\nexports.pseudoKnightyanFractal = `uniform float time;\r\nuniform vec2 mouse;\r\nuniform vec2 resolution;\r\nuniform sampler2D iChannel0;\r\n\r\nvec3 mcol=vec3(0.);\r\n\r\nfloat randSeed;\r\nvoid randomize(vec2 c){randSeed=fract(sin(dot(c,vec2(113.421,17.329)))*3134.1234);}\r\nfloat rand(){return fract(sin(randSeed++)*3143.45345);}\r\n\r\n\r\nfloat DE(vec3 p){\r\n\tconst vec3 CSize=vec3(.63248,.78632,.875);\r\n\tfloat DEfactor=1.;\r\n\tfor(int i=0;i<5;i++){\r\n\t\tp=2.*clamp(p,-CSize,CSize)-p;\r\n\t\tfloat k=max(.70968/dot(p,p),1.);\r\n\t\tp*=k;DEfactor*=k;\r\n\t}\r\n\tif(mcol.r>=0.)mcol+=abs(p);\r\n\tfloat rxy=length(p.xy);\r\n\treturn max(rxy-.92784,abs(rxy*p.z)/length(p))/DEfactor;\r\n}\r\n\r\nfloat map(vec3 p){\r\n\treturn DE(p);\r\n}\r\n\r\nvec3 normal(in vec3 p){\r\n\t//    vec2 e = vec2(0.005, -0.005);\r\n\tvec2 e=vec2(1.,-1.)*.5773*.0005;\r\n\treturn normalize(e.xyy*map(p+e.xyy)+e.yyx*map(p+e.yyx)+e.yxy*map(p+e.yxy)+e.xxx*map(p+e.xxx));\r\n}\r\n\r\nvec3 calcNormal(in vec3 pos){\r\n\treturn normal(pos);\r\n}\r\n\r\nmat2 rot(float a){\r\n\treturn mat2(cos(a),sin(a),-sin(a),cos(a));\r\n}\r\n\r\n\r\n\r\nmat3 calcLookAtMatrix(in vec3 ro,in vec3 ta,in float roll)\r\n{\r\n\tvec3 ww=normalize(ta-ro);\r\n\tvec3 uu=normalize(cross(ww,vec3(sin(roll),cos(roll),0.)));\r\n\tvec3 vv=normalize(cross(uu,ww));\r\n\treturn mat3(uu,vv,ww);\r\n}\r\nvoid doCamera(out vec3 camPos,out vec3 camTar,in float time)\r\n{\r\n\tfloat an=.3*time+10.;\r\n\tcamPos=vec3(2.772*sin(an),.424,.820*cos(an));\r\n\tcamTar=vec3(1.,.000,-.03);\r\n}\r\nfloat calcIntersection(in vec3 ro,in vec3 rd)\r\n{\r\n\tconst float maxd=20.;\r\n\tconst float precis=.001;\r\n\tfloat h=precis*2.;\r\n\tfloat t=0.;\r\n\tfloat res=-1.;\r\n\tfor(int i=0;i<128;i++){\r\n\t\tif(h<precis||t>maxd)break;\r\n\t\th=map(ro+rd*t);\r\n\t\tt+=h;\r\n\t}\r\n\tif(t<maxd)res=t;\r\n\treturn res;\r\n}\r\n\r\nvec3 path(float t){\r\n\treturn vec3(cos(t),sin(t),-.65+abs(sin(t*.7))*.25)*(2.+sin(t*1.7)*.5)+vec3(0.,0.,1.);\r\n}\r\n\r\nvec3 post(vec3 rgb){\r\n\treturn rgb;\r\n}\r\n\r\nvec4 scene(vec3 ro,vec3 rd,float slider,float time,float pxl){\r\n\t\r\n\trandomize(gl_FragCoord.xy+time);\r\n\t\r\n\tvec3 LP=path(time+1.),p;\r\n\tLP.z+=slider;\r\n\tro.z-=slider;\r\n\t\r\n\tfloat d=map(ro)*.8,t=d*rand(),nt=d,od=1.,ft=0.;\r\n\t\r\n\tvec4 col=vec4(0.,0.,0.,1.);\r\n\t\r\n\tvec4 am,tm=vec4(-1.);\r\n\t\r\n\tfor(int i=0;i<99;i++){\r\n\t\t\r\n\t\tif(nt>t+ft){\r\n\t\t\tp=ro+rd*(t+ft);\r\n\t\t\tp+=(LP-p)*(-p.z)/(LP.z-p.z);\t\t\r\n\t\t}else{\r\n\t\t\tp=ro+rd*t;\r\n\t\t}\r\n\t\t\r\n\t\td=map(p);\r\n\t\t\r\n\t\tif(nt>t+ft){\r\n\t\t\tfloat dL=.05*length(ro+rd*(t+ft)-LP);\r\n\t\t\t\r\n\t\t\tcol.rgb+=col.a*vec3(1.,1.,.7)*exp(-dL*40.)*smoothstep(0.,.01,d);\r\n\t\t\t\r\n\t\t\tif(t+ft+dL>nt){\r\n\t\t\t\tft=0.;\r\n\t\t\t\tt=nt;\r\n\t\t\t\tif(t>20.)break;\r\n\t\t\t}else ft+=dL;\r\n\t\t}else{\r\n\t\t\tif(d<od&&tm.w<0.){\r\n\t\t\t\tfloat alpha=clamp(d/(pxl*t),0.,1.);\r\n\t\t\t\tif(alpha<.95){\r\n\t\t\t\t\tam=vec4(alpha,am.xyz);tm=vec4(t,tm.xyz);\r\n\t\t\t\t\tcol.a*=alpha;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tod=d;\r\n\t\t\tnt=t+d*(.6+.2*rand());\r\n\t\t}\r\n\t}\r\n\t\r\n\tvec3 tcol=vec3(0.);\r\n\t\r\n\tfor(int i=0;i<4;i++){\r\n\t\t\r\n\t\tif(tm.x<0.)continue;\r\n\r\n\t\tmcol=vec3(0.);\r\n\r\n\t\tp=ro+rd*tm.x;\r\n\t\t\r\n\t\tvec3 N=normal(p),L=LP-p;\r\n\t\t\r\n\t\tvec3 scol;\r\n\t\t\r\n\t\tmcol=sin(mcol)*.3+vec3(.8,.6,.4);\r\n\t\tfloat ls=exp(-dot(L,L)*.2);\r\n\t\tp+=L*(-p.z)/L.z;\r\n\t\t\r\n\t\tL=normalize(L);\r\n\t\t\r\n\t\tscol=ls*mcol*max(0.,dot(N,L));\r\n\t\t\r\n\t\tfloat v=max(0.,dot(N,-rd));\r\n\t\t\r\n\t\tscol+=exp(-t)*mcol*v;\r\n\t\td=smoothstep(0.,.005,map(p));\r\n\t\tscol+=ls*vec3(2.,2.,1.7)*max(0.,dot(N,L))*d;\r\n\t\t\r\n\t\tif(rd.z<0.&&d>0.)scol+=ls*vec3(4.,3.,1.4)*pow(max(0.,dot(reflect(rd,N),L)),5.)*(1.-.25*v)*d;\r\n\t\t\r\n\t\ttcol=mix(scol,tcol,am.x);\r\n\t\t\r\n\t\tam=am.yzwx;\r\n\t\ttm=tm.yzwx;\r\n\t}\r\n\t\r\n\tcol.rgb=clamp(col.rgb+tcol,0.,1.);\r\n\t\r\n\treturn vec4(post(col.rgb),t);\r\n\r\n}\r\n\r\nout vec4 fragColor;\r\n\r\nvoid main(void){\r\n\t\r\n\tfloat tm;\r\n\tfloat glow,eglow,totdist=glow=.3;\r\n\tvec2 p=(gl_FragCoord.xy/resolution.xy)+mouse/4.;\r\n\t\r\n\tvec3 ro,ta;\r\n\tdoCamera(ro,ta,time*.1);\r\n\t\r\n\ttm=mod(time,18.85);\r\n\t\r\n\tmat3 camMat=calcLookAtMatrix(ro,ta,0.);\r\n\t\r\n\tvec3 rd=normalize(camMat*vec3(p.xy,1.5+2.));\r\n\t\r\n\tvec4 final=scene(ro,rd,.3,tm*.12,3./resolution.y);\r\n\t\r\n\tfragColor=final;\r\n\t\r\n}\r\n\r\n`;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/assets/shaders/pseudoKnightyanFractal.js?");

/***/ }),

/***/ "./build/wwwroot/assets/shaders/someKindOfFractal.js":
/*!***********************************************************!*\
  !*** ./build/wwwroot/assets/shaders/someKindOfFractal.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.someKindOfFractal = void 0;\nexports.someKindOfFractal = `uniform float time;\r\nuniform vec2 mouse;\r\nuniform vec2 resolution;\r\n\r\nout vec4 fragColor;\r\n\r\n#define iTime  time\r\n#define iResolution  resolution\r\n\r\n#define R(p,a,r)mix(a*dot(p,a),p,cos(r))+sin(r)*cross(p,a)\r\n\r\nvoid mainImage(out vec4 O, vec2 C)\r\n{\r\n    O=vec4(0);\r\n    vec3 p;\r\n   vec3 r= vec3(iResolution.x,iResolution.y,0.);\r\n\t    \r\n    vec3 d =normalize(vec3((C-.5*r.xy)/r.y,1.)); \r\n for(float i=0.,g=0.,e,s;\r\n        ++i<99.;\r\n        O.xyz+=5e-5*abs(cos(vec3(3,2,1)+log(s*9.)))/dot(p,p)/e\r\n    )\r\n    {\r\n        p=g*d;\r\n        p.z+=iTime*.3;\r\n        p=R(p,normalize(vec3(1,2,3)),.5);   \r\n        s=2.5;\r\n        p=abs(mod(p-1.,2.)-1.)-1.;\r\n        for(int j=0;j++<10;)\r\n            p=1.-abs(p-1.),\r\n            s*=e=-1.8/dot(p,p),\r\n            p=p*e-.7;\r\n            g+=e=abs(p.z)/s+.001;           \r\n     }\r\n}\r\nvoid main(){\r\n    mainImage(fragColor,gl_FragCoord.xy);\r\n\r\n}\r\n\r\n`;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/assets/shaders/someKindOfFractal.js?");

/***/ }),

/***/ "./build/wwwroot/assets/shaders/wglsl/wgslFlamesShader.js":
/*!****************************************************************!*\
  !*** ./build/wwwroot/assets/shaders/wglsl/wgslFlamesShader.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.wgslFlamesShader = void 0;\nconst material_1 = __webpack_require__(/*! ../../../../src/Engine/ShaderRenderers/WebGPU/material */ \"./build/src/Engine/ShaderRenderers/WebGPU/material.js\");\n// This is a shader originally written by Inigo Quilez and published on:\n// https://www.shadertoy.com/view/MsXGRf\n//\n// It has been converted to WGSL by Magnus Thor.\n//\n// The original GLSL code is copyrighted by Inigo Quilez:\n// Copyright Inigo Quilez, 2013 - https://iquilezles.org/\n//\n// The converted WGSL code is shared here under the following conditions:\n//\n// This WGSL shader code is shared for educational purposes only. \n// You are free to use it for learning and experimentation.\n//\n// You are NOT allowed to:\n// - Host, display, distribute, or share this WGSL code as it is or altered.\n// - Use this WGSL code in any commercial or non-commercial product, website, or project.\n// - Sell this WGSL code.\n// - Mint NFTs of this WGSL code.\n// - Train a neural network with this WGSL code.\n//\n// If you wish to use this code outside of educational purposes, \n// please contact Inigo Quilez for permission.\n//\n// You can find the original GLSL shader and contact Inigo Quilez here:\n// https://www.shadertoy.com/view/MsXGRf\n// https://iquilezles.org/\nexports.wgslFlamesShader = {\n    vertex: material_1.defaultWglslVertex,\n    fragment: /* glsl */ `\r\n\r\n\tstruct VertexOutput {\r\n\t\t@builtin(position) pos: vec4<f32>,\r\n\t\t@location(0) uv: vec2<f32>\r\n\t  };    \r\n   \r\n\tstruct Uniforms {\r\n\t\tresolution: vec3<f32>,\r\n\t\ttime: f32,\r\n\t\tmouse: vec4<f32>,\r\n\t\tframe: f32\r\n\t  };\r\n\t\r\n    @group(0) @binding(0) var<uniform> uniforms: Uniforms;\r\n    @group(0) @binding(1) var linearSampler: sampler;\r\n    @group(0) @binding(2) var NOISE: texture_2d<f32>; \t\t\r\n\t\r\n\tfn sample_texture(tex:texture_2d<f32>,uv:vec2<f32>) -> vec4<f32>{\r\n\t\tlet result:vec4<f32> = textureSample(tex, linearSampler, -uv);\r\n\t\treturn result;\r\n\t}   \r\n\t\r\n\tfn noise(x: vec3<f32>) -> f32 {\r\n\t\tlet p: vec3<f32> = floor(x);\r\n\t\tvar f: vec3<f32> = fract(x);\r\n\t\tf = f * f * (3. - 2. * f);\r\n\t\tlet uv: vec2<f32> = p.xy + vec2<f32>(37., 17.) * p.z + f.xy;\r\n\t\tlet rg: vec2<f32> = textureSampleLevel(NOISE, linearSampler, (uv + 0.5) / 256., f32(0.)).yx;\r\n\t\treturn mix(rg.x, rg.y, f.z);\r\n\t} \r\n\r\n\tfn map(p: vec3<f32>) -> vec4<f32> {\r\n\r\n\t\tvar tm = uniforms.time;\r\n\r\n\t\tvar p_var = p;\r\n\t\tlet r: vec3<f32> = p_var;\r\n\t\tp_var.y = p_var.y + (0.6);\r\n\t\tp_var = -4. * p_var / dot(p_var, p_var);\r\n\t\tlet an: f32 = -1. * sin(0.1 * tm + length(p_var.xz) + p_var.y);\r\n\t\tlet co: f32 = cos(an);\r\n\t\tlet si: f32 = sin(an);\r\n\t\tvar pxz = p_var.xz;\r\n\t\tpxz = mat2x2<f32>(co, -si, si, co) * p_var.xz;\r\n\t\tp_var.x = pxz.x;\r\n\t\tp_var.z = pxz.y;\r\n\r\n\t\tpxz = p_var.xz + (-1. + 2. * noise(p_var * 1.1));\r\n\t\tp_var.x = pxz.x;\r\n\t\tp_var.z = pxz.y;\r\n\t\tvar f: f32;\r\n\t\tvar q: vec3<f32> = p_var * 0.85 - vec3<f32>(0., 1., 0.) * tm * 0.12;\r\n\t\tf = 0.5 * noise(q);\r\n\t\tq = q * 2.02 - vec3<f32>(0., 1., 0.) * tm * 0.12;\r\n\t\tf = f + (0.25 * noise(q));\r\n\t\tq = q * 2.03 - vec3<f32>(0., 1., 0.) * tm * 0.12;\r\n\t\tf = f + (0.125 * noise(q));\r\n\t\tq = q * 2.01 - vec3<f32>(0., 1., 0.) * tm * 0.12;\r\n\t\tf = f + (0.0625 * noise(q));\r\n\t\tq = q * 2.02 - vec3<f32>(0., 1., 0.) * tm * 0.12;\r\n\t\tf = f + (0.04 * noise(q));\r\n\t\tq = q * 2. - vec3<f32>(0., 1., 0.) * tm * 0.12;\r\n\t\tlet den: f32 = clamp((-r.y - 0.6 + 4. * f) * 1.2, 0., 1.);\r\n\r\n\t\tvar col: vec3<f32> = 1.2 * mix(vec3<f32>(1., 0.8, 0.6), 0.9 * vec3<f32>(0.3, 0.2, 0.35), den);\r\n\t\tcol = col + (0.05 * sin(0.05 * q));\r\n\t\tcol = col * (1. - 0.8 * smoothstep(0.6, 1., sin(0.7 * q.x) * sin(0.7 * q.y) * sin(0.7 * q.z)) * vec3<f32>(0.6, 1., 0.8));\r\n\t\tcol = col * (1. + 1. * smoothstep(0.5, 1., 1. - length((fract(q.xz * 0.12) - 0.5) / 0.5)) * vec3<f32>(1., 0.9, 0.8));\r\n\t\t\r\n\t\treturn vec4<f32>(col, den);\r\n\t} \r\n\t\r\n\tfn debugImage(invocation_id: vec2<f32>) -> vec4<f32> {\r\n\t\t\treturn vec4<f32>(1.0,0.,0.,0.5);\r\n\t}\r\n\r\n\tfn mainImage(invocation_id: vec2<f32>) -> vec4<f32> {\r\n\r\n\t\tlet mouse: vec4<f32> = uniforms.mouse;\r\n\t\r\n\t\tlet R: vec2<f32> = uniforms.resolution.xy;\r\n\t\tlet y_inverted_location = vec2<i32>(i32(invocation_id.x), i32(R.y) - i32(invocation_id.y));\r\n\t\tlet location = vec2<i32>(i32(invocation_id.x), i32(invocation_id.y));\r\n\t\t\r\n\t\tvar fragColor: vec4<f32>;\r\n\t\tvar fragCoord = vec2<f32>(f32(location.x), f32(location.y) );\r\n\t\r\n\t\tlet q: vec2<f32> = fragCoord.xy / uniforms.resolution.xy;\r\n\t\tlet p: vec2<f32> = (-1. + 2. * q) * vec2<f32>(uniforms.resolution.x / uniforms.resolution.y, 1.);\r\n\t\tvar mo: vec2<f32> = mouse.xy / uniforms.resolution.xy;\r\n\t\t\r\n\t\tlet an: f32 = -0.07 * uniforms.time + 3. * mo.x;\r\n\t\tvar ro: vec3<f32> = 4.5 * normalize(vec3<f32>(cos(an), 0.5, sin(an)));\r\n\t\tro.y = ro.y + (1.);\r\n\t\tlet ta: vec3<f32> = vec3<f32>(0., 0.5, 0.);\r\n\t\tlet cr: f32 = -0.4 * cos(0.02 * uniforms.time);\r\n\t\tlet ww: vec3<f32> = normalize(ta - ro);\r\n\t\tlet uu: vec3<f32> = normalize(cross(vec3<f32>(sin(cr), cos(cr), 0.), ww));\r\n\t\tlet vv: vec3<f32> = normalize(cross(ww, uu));\r\n\t\tlet rd: vec3<f32> = normalize(p.x * uu + p.y * vv + 2.5 * ww);\r\n\t\tvar sum: vec4<f32> = vec4<f32>(0.);\r\n\t\tlet bg: vec3<f32> = vec3<f32>(0.4, 0.5, 0.5) * 1.3;\r\n\t\tvar t: f32 = 0.05 * fract(10.5421 * dot(vec2<f32>(0.0149451, 0.038921), fragCoord));\r\n\t\r\n\t\tfor (var i: i32 = 0; i < 128; i = i + 1) {\r\n\t\t\tif (sum.a > 0.99) {\t\r\n\t\t\t\t\tbreak;\r\n\t\t \t}\r\n\r\n\t\t\tlet pos: vec3<f32> = ro + t * rd;\r\n\t\tvar col: vec4<f32> = map(pos);\r\n\t\tcol.a = col.a * (0.5);\r\n\t\tvar colrgb = col.rgb;\r\n\t\tcolrgb = mix(bg, col.rgb, exp(-0.002 * t * t * t)) * col.a;\r\n\t\tcol.r = colrgb.x;\r\n\t\tcol.g = colrgb.y;\r\n\t\tcol.b = colrgb.z;\r\n\t\t\tsum = sum + col * (1. - sum.a);\r\n\t\t\tt = t + (0.05);\r\n\t\t}\r\n\t\r\n\t\tvar mixedValue: vec3<f32> = mix(bg, sum.xyz / (0.001 + sum.w), sum.w);\r\n\r\n\t\tvar col: vec3<f32> = clamp(mixedValue, vec3<f32>(0.0), vec3<f32>(1.0));\r\n\r\n\t\tcol = col * col * (3. - 2. * col) * 1.4 - 0.4;\r\n\t\tcol = col * (0.25 + 0.75 * pow(16. * q.x * q.y * (1. - q.x) * (1. - q.y), 0.1));\r\n\t\treturn vec4<f32>(col, 1.);\r\n\t} \r\n\t\t\r\n\t@fragment\r\n\tfn main_fragment(vert: VertexOutput) -> @location(0) vec4<f32> {    \r\n\t\t\r\n\t\treturn mainImage(vert.pos.xy);\r\n\t}\r\n\r\n`\n};\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/assets/shaders/wglsl/wgslFlamesShader.js?");

/***/ }),

/***/ "./build/wwwroot/src/SetupDemo.js":
/*!****************************************!*\
  !*** ./build/wwwroot/src/SetupDemo.js ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SetupDemo = void 0;\nconst assetsHelper_1 = __webpack_require__(/*! ../../src/Engine/Helpers/assetsHelper */ \"./build/src/Engine/Helpers/assetsHelper.js\");\nconst sequence_1 = __webpack_require__(/*! ../../src/Engine/sequence */ \"./build/src/Engine/sequence.js\");\nclass SetupDemo {\n    constructor(audioLoader) {\n        this.scenes = [];\n        this.settings = {\n            width: 800,\n            height: 450,\n            audioProperties: {\n                bpm: 122,\n                ticks: 4,\n                beat: 0,\n                tick: 0,\n                bar: 0,\n                avgFreq: 0\n            },\n            font: \"Big Shoulders Stencil Text\"\n        };\n        this.sequence = new sequence_1.Sequence(document.querySelector(\"canvas\"), 122, 4, 4, [], audioLoader);\n    }\n    async addAssets(...urls) {\n        await assetsHelper_1.AssetsHelper.loadImages(urls);\n        return this;\n    }\n    addScene(scene) {\n        this.sequence.addScene(scene);\n    }\n    addEntity(key, entity) {\n        const scene = this.scenes.find(pre => {\n            return pre.name === key;\n        });\n        if (scene) {\n            scene.addEntity(entity);\n        }\n        else\n            throw Error(\"No such scene\");\n    }\n}\nexports.SetupDemo = SetupDemo;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/SetupDemo.js?");

/***/ }),

/***/ "./build/wwwroot/src/demo.js":
/*!***********************************!*\
  !*** ./build/wwwroot/src/demo.js ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst entity_1 = __webpack_require__(/*! ../../src/Engine/entity */ \"./build/src/Engine/entity.js\");\nconst GLSLShaderEntity_1 = __webpack_require__(/*! ../../src/Engine/GLSLShaderEntity */ \"./build/src/Engine/GLSLShaderEntity.js\");\nconst mainFragment_1 = __webpack_require__(/*! ../assets/shaders/mainFragment */ \"./build/wwwroot/assets/shaders/mainFragment.js\");\nconst mainVertex_1 = __webpack_require__(/*! ../assets/shaders/mainVertex */ \"./build/wwwroot/assets/shaders/mainVertex.js\");\nconst someKindOfFractal_1 = __webpack_require__(/*! ../assets/shaders/someKindOfFractal */ \"./build/wwwroot/assets/shaders/someKindOfFractal.js\");\nconst typeWriterEffet_1 = __webpack_require__(/*! ./effects/typeWriterEffet */ \"./build/wwwroot/src/effects/typeWriterEffet.js\");\nconst ranndomSquareByTickEffect_1 = __webpack_require__(/*! ./effects/ranndomSquareByTickEffect */ \"./build/wwwroot/src/effects/ranndomSquareByTickEffect.js\");\nconst expandingCircleEffect_1 = __webpack_require__(/*! ./effects/expandingCircleEffect */ \"./build/wwwroot/src/effects/expandingCircleEffect.js\");\nconst starBurstEffct_1 = __webpack_require__(/*! ./effects/starBurstEffct */ \"./build/wwwroot/src/effects/starBurstEffct.js\");\nconst textEffect_1 = __webpack_require__(/*! ./effects/textEffect */ \"./build/wwwroot/src/effects/textEffect.js\");\nconst imageOverlayEffect_1 = __webpack_require__(/*! ./effects/imageOverlayEffect */ \"./build/wwwroot/src/effects/imageOverlayEffect.js\");\nconst textArrayDisplayEffect_1 = __webpack_require__(/*! ./effects/textArrayDisplayEffect */ \"./build/wwwroot/src/effects/textArrayDisplayEffect.js\");\nconst assetsHelper_1 = __webpack_require__(/*! ../../src/Engine/Helpers/assetsHelper */ \"./build/src/Engine/Helpers/assetsHelper.js\");\nconst fftAnalyzerEffect_1 = __webpack_require__(/*! ./effects/fftAnalyzerEffect */ \"./build/wwwroot/src/effects/fftAnalyzerEffect.js\");\nconst strobeEffect_1 = __webpack_require__(/*! ./effects/strobeEffect */ \"./build/wwwroot/src/effects/strobeEffect.js\");\nconst createBeatShakePostProcessor_1 = __webpack_require__(/*! ./postprocessors/createBeatShakePostProcessor */ \"./build/wwwroot/src/postprocessors/createBeatShakePostProcessor.js\");\nconst pseudoKnightyanFractal_1 = __webpack_require__(/*! ../assets/shaders/pseudoKnightyanFractal */ \"./build/wwwroot/assets/shaders/pseudoKnightyanFractal.js\");\nconst sceneBuilder_1 = __webpack_require__(/*! ../../src/Engine/Helpers/sceneBuilder */ \"./build/src/Engine/Helpers/sceneBuilder.js\");\nconst gridOverlayEffect_1 = __webpack_require__(/*! ./effects/gridOverlayEffect */ \"./build/wwwroot/src/effects/gridOverlayEffect.js\");\nconst bubbleParticles_1 = __webpack_require__(/*! ./effects/bubbleParticles */ \"./build/wwwroot/src/effects/bubbleParticles.js\");\nconst streachingTextEffect_1 = __webpack_require__(/*! ./effects/streachingTextEffect */ \"./build/wwwroot/src/effects/streachingTextEffect.js\");\nconst creditsScroller_1 = __webpack_require__(/*! ./effects/creditsScroller */ \"./build/wwwroot/src/effects/creditsScroller.js\");\nconst createLensPostProcessor_1 = __webpack_require__(/*! ./postprocessors/createLensPostProcessor */ \"./build/wwwroot/src/postprocessors/createLensPostProcessor.js\");\nconst SetupDemo_1 = __webpack_require__(/*! ./SetupDemo */ \"./build/wwwroot/src/SetupDemo.js\");\nconst audioLoader_1 = __webpack_require__(/*! ../../src/Engine/Audio/audioLoader */ \"./build/src/Engine/Audio/audioLoader.js\");\nconst WGLShaderEntity_1 = __webpack_require__(/*! ../../src/Engine/WGLShaderEntity */ \"./build/src/Engine/WGLShaderEntity.js\");\nconst wgslShaderRenderer_1 = __webpack_require__(/*! ../../src/Engine/ShaderRenderers/WebGPU/wgslShaderRenderer */ \"./build/src/Engine/ShaderRenderers/WebGPU/wgslShaderRenderer.js\");\nconst defaultMainShader_1 = __webpack_require__(/*! ../../src/Engine/ShaderRenderers/WebGPU/defaultMainShader */ \"./build/src/Engine/ShaderRenderers/WebGPU/defaultMainShader.js\");\nconst material_1 = __webpack_require__(/*! ../../src/Engine/ShaderRenderers/WebGPU/material */ \"./build/src/Engine/ShaderRenderers/WebGPU/material.js\");\nconst geometry_1 = __webpack_require__(/*! ../../src/Engine/ShaderRenderers/WebGPU/geometry */ \"./build/src/Engine/ShaderRenderers/WebGPU/geometry.js\");\nconst textureLoader_1 = __webpack_require__(/*! ../../src/Engine/ShaderRenderers/WebGPU/textureLoader */ \"./build/src/Engine/ShaderRenderers/WebGPU/textureLoader.js\");\nconst IWgslTexture_1 = __webpack_require__(/*! ../../src/Engine/Interfaces/IWgslTexture */ \"./build/src/Engine/Interfaces/IWgslTexture.js\");\nconst wgslFlamesShader_1 = __webpack_require__(/*! ../assets/shaders/wglsl/wgslFlamesShader */ \"./build/wwwroot/assets/shaders/wglsl/wgslFlamesShader.js\");\n// get the music as baase\nconst demo = new SetupDemo_1.SetupDemo(new audioLoader_1.DefaultAudioLoader(\"/wwwroot/assets/music/music.mp3\"));\ndemo.addAssets(\"assets/images/silhouette.png\", \"assets/images/lens.png\").then(async (demo) => {\n    var _a, _b;\n    // Create the Scenes\n    // Music length = 139200 ms;\n    const sceneBuilder = new sceneBuilder_1.SceneBuilder(139200);\n    sceneBuilder\n        .addScene(\"Scene 0\", 10000).\n        addScene(\"Scene 1\", 20000).\n        addScene(\"Scene 2\", 8000).\n        addScene(\"Scene 3\", 15000).\n        addScene(\"Scene 4\", 15000).\n        addScene(\"Scene 5\", 25000).\n        durationUntilEndInMs(\"Scene 6\");\n    const scenes = sceneBuilder.getScenes();\n    // Set up a wgsl shader entity & renderer\n    const wgslCanvas = document.createElement(\"canvas\");\n    wgslCanvas.width = demo.settings.width;\n    wgslCanvas.height = demo.settings.height;\n    const webgpu = await (0, wgslShaderRenderer_1.initWebGPU)(wgslCanvas);\n    const wsglTextures = await textureLoader_1.TextureLoader.loadAll(webgpu.device, {\n        key: \"NOISE-TEXTURE\",\n        source: \"assets/images/noise.png\",\n        type: IWgslTexture_1.WgslTextureType.IMAGE,\n    });\n    const wgslShaderProps = {\n        canvas: wgslCanvas,\n        device: webgpu.device,\n        context: webgpu.context,\n        shader: defaultMainShader_1.defaultMainShader,\n        renderBuffers: [\n            {\n                name: \"iChannel0\",\n                shader: new material_1.Material(webgpu.device, wgslFlamesShader_1.wgslFlamesShader),\n                geometry: new geometry_1.Geometry(webgpu.device, geometry_1.rectGeometry),\n                textures: wsglTextures\n            }\n        ]\n    };\n    const wgslShaderEntity = new WGLShaderEntity_1.WGLSLShaderEntity(\"wgsl-shader\", wgslShaderProps, (ts, shaderRender) => {\n        // this is an action called for each, frame\n    });\n    const strobeEntity = new entity_1.Entity(\"Strobe\", {\n        color: \"white\", // You can change the color\n        isOn: false,\n        lastBeat: -1, // Initialize to -1 to trigger on the first beat\n    }, (ts, ctx, props, sequence) => (0, strobeEffect_1.strobeEffect)(ts, ctx, props, demo.sequence));\n    const imageOverlayEntity = new entity_1.Entity(\"ImageOverlay\", {\n        position: imageOverlayEffect_1.ImagePosition.FILL,\n        width: demo.settings.width,\n        height: demo.settings.height,\n        image: (_a = assetsHelper_1.AssetsHelper.textureCache.get(\"silhouette.png\")) === null || _a === void 0 ? void 0 : _a.src,\n        opacity: 0.7,\n        fadeIn: true,\n        fadeOut: true,\n        duration: 5,\n    }, (ts, ctx, props) => (0, imageOverlayEffect_1.imageOverlayEffect)(ts, ctx, props, demo.sequence));\n    const expandingCircleEntity = new entity_1.Entity(\"ExpandingCircle\", {\n        x: demo.settings.width / 2,\n        y: demo.settings.height / 2,\n        radius: 0,\n        maxRadius: 450,\n        growthRate: 15,\n        duration: 5 // Scene duration in seconds\n    }, (ts, ctx, props) => (0, expandingCircleEffect_1.expandingCircleEffect)(ts, ctx, props, demo.sequence) // Pass the sequence instance\n    );\n    const starburstEntity = new entity_1.Entity(\"Starburst\", {\n        x: demo.settings.width / 2, // Example x-coordinate\n        y: demo.settings.height / 2, // Example y-coordinate\n        numPoints: 8, // Example number of points\n        outerRadius: 50,\n        innerRadius: 25,\n        rotation: 0,\n        rotationSpeed: 2, // Example rotation speed\n        hue: 0,\n        saturation: 100,\n        lightness: 50\n    }, starBurstEffct_1.starburstEffect);\n    const typeWriterEntity = new entity_1.Entity(\"Typewriter\", {\n        x: 100,\n        y: 300,\n        text: \"EASY AUDIO SYNCRONIZATON\",\n        index: 0,\n        speed: 5, // 5 characters per second\n        lastCharacterTime: 0,\n        useBPM: true,\n        bpm: demo.settings.audioProperties.bpm,\n        ticksPerBeat: demo.settings.audioProperties.ticks\n    }, typeWriterEffet_1.typeWriterEffect);\n    const randomSquareEntity = new entity_1.Entity(\"RandomSquare\", {\n        x: 0,\n        y: 0,\n        size: 0,\n        color: \"red\",\n        lastTick: -1 // Initialize to -1 to add a square on the first bar\n    }, (ts, ctx, props) => (0, ranndomSquareByTickEffect_1.randomSquareEffect)(ts, ctx, props, demo.sequence.tickCounter) // Pass currentBar from Sequence\n    );\n    const gridOverlayEntity = new entity_1.Entity(\"GridOverlay\", {\n        rows: 5,\n        cols: 8,\n        cellColor: \"white\",\n        activeCells: new Set(),\n    }, (ts, ctx, props, sequence) => (0, gridOverlayEffect_1.gridOverlayEffect)(ts, ctx, props, demo.sequence));\n    const audioVisualizerEntity = new entity_1.Entity(\"AudioVisualizer\", {\n        x: 0,\n        y: 150,\n        width: demo.settings.width,\n        height: 300,\n        barWidth: 5,\n        barSpacing: 2,\n        numBars: 100,\n        color: \"red\"\n    }, (ts, ctx, props, sequence) => (0, fftAnalyzerEffect_1.audioVisualizerEffect)(ts, ctx, props, demo.sequence));\n    const pseudoKnightyanShaderEntity = new GLSLShaderEntity_1.GLSLShaderEntity(\"ShaderEnriry\", {\n        mainFragmentShader: mainFragment_1.mainFragment,\n        mainVertexShader: mainVertex_1.mainVertex,\n        renderBuffers: [\n            {\n                name: \"MyShader\",\n                fragment: pseudoKnightyanFractal_1.pseudoKnightyanFractal,\n                vertex: mainVertex_1.mainVertex,\n                textures: []\n            }\n        ]\n    }, (ts, render, propertybag) => {\n    }, demo.settings.width, demo.settings.height);\n    const someKindOfFractalShaderEntity = new GLSLShaderEntity_1.GLSLShaderEntity(\"ShaderEnriry\", {\n        mainFragmentShader: mainFragment_1.mainFragment,\n        mainVertexShader: mainVertex_1.mainVertex,\n        renderBuffers: [\n            {\n                name: \"MyShader\",\n                fragment: someKindOfFractal_1.someKindOfFractal,\n                vertex: mainVertex_1.mainVertex,\n                textures: []\n            }\n        ]\n    }, (ts, render, propertybag) => {\n    }, demo.settings.width, demo.settings.height);\n    const textOverlay = new entity_1.Entity(\"TextEffect\", {\n        x: 100,\n        y: 100,\n        text: \"FULL SHADER SUPPORT\".toUpperCase(),\n        font: \"Big Shoulders Stencil Text\",\n        size: 60,\n        duration: 15 // 5 seconds\n    }, (ts, ctx, props) => (0, textEffect_1.textEffect)(ts, ctx, props, demo.sequence) // Pass the sequence instance\n    );\n    const textArrayDisplayEntity = new entity_1.Entity(\"TextArrayDisplay\", {\n        x: 100,\n        y: 200,\n        texts: [\n            \"1-N RENDERPASSES\".toUpperCase(),\n            \"POSTPROCESSING\".toUpperCase(),\n            \"1-N TEXTURES\",\n            \"CUSTOM UNIFORMS\",\n        ],\n        font: demo.settings.font,\n        size: 60,\n        currentBeat: 0,\n    }, (ts, ctx, props) => {\n        (0, textArrayDisplayEffect_1.textArrayDisplayEffect)(ts, ctx, props, demo.sequence);\n    });\n    textArrayDisplayEntity.addPostProcessor((0, createBeatShakePostProcessor_1.createBeatShakePostProcessor)(3));\n    // Add Entities to the Scens\n    // setup a some more test Entities for § 0\n    const typeWriter1EntityForFirstScene = new entity_1.Entity(\"Typewriter\", {\n        x: 100,\n        y: 200,\n        text: \"DEMOLISHED-RAILS\",\n        index: 0,\n        speed: 5, // 5 characters per second\n        lastCharacterTime: 0,\n        useBPM: true,\n        bpm: demo.settings.audioProperties.bpm,\n        ticksPerBeat: demo.settings.audioProperties.ticks\n    }, typeWriterEffet_1.typeWriterEffect, 1000, 10000);\n    const typeWriter2EntityForFirstScene = new entity_1.Entity(\"Typewriter\", {\n        x: 0,\n        y: 350,\n        text: \"FRAMEWORK DEMO\",\n        index: 0,\n        speed: 5, // 5 characters per second\n        lastCharacterTime: 0,\n        useBPM: true,\n        bpm: demo.settings.audioProperties.bpm,\n        ticksPerBeat: demo.settings.audioProperties.ticks\n    }, typeWriterEffet_1.typeWriterEffect, 5000, 10000);\n    const gridOverlayEffectEntity = new entity_1.Entity(\"gridOverlayEffets\", {\n        activeCells: new Set(),\n        cellColor: \"rgba(255,255,0,0.2)\",\n        cols: 4,\n        rows: 4,\n    }, (ts, ctx, props) => (0, gridOverlayEffect_1.gridOverlayEffect)(ts, ctx, props, demo.sequence));\n    const ballEntityProps = {\n        numBalls: 20,\n        balls: [],\n    };\n    const ballEntity = new entity_1.Entity(\"BallEntity\", ballEntityProps, (ts, ctx, props, sequence) => (0, bubbleParticles_1.ballEffect)(ts, ctx, props, sequence));\n    const stretchingTextProps = {\n        texts: [\"BRING\", \"THE\", \"BEAT\", \"BACK\"],\n        currentIndex: 0,\n        font: \"Poppins\", // Or your custom font\n        color: \"rgba(255,255,255,0.2)\",\n        lastBeat: -1,\n    };\n    const stretchingTextEntity = new entity_1.Entity(\"StretchingText\", stretchingTextProps, (ts, ctx, props, sequence) => (0, streachingTextEffect_1.stretchingTextEffect)(ts, ctx, props, demo.sequence));\n    // set up an endScene ( credits )\n    const creditsText = [\n        \"FRAMWORK CODE\",\n        \"MAGNUS 'BAGZY'THOR\",\n        \"EXAMPLE FX'S\",\n        \"MAGNUS 'BAGZY'THOR\",\n        \"MUSIC BY\",\n        \"VIRGILL / MANIACS OF NOISE\",\n        \"GRAPHIS\",\n        \"COOKIEDOUGH\",\n        // ... more lines\n    ];\n    const creditsScrollerProps = {\n        lines: creditsText.map((text, index) => ({\n            text,\n            y: 100 + index * 30, // Initial y position\n            alpha: 0,\n        })),\n        lineHeight: 80,\n        scrollSpeed: 40,\n        fadeInDuration: 0.5,\n        fadeOutDuration: 0.5,\n        font: \"40px Poppins\",\n    };\n    const creditsEntity = new entity_1.Entity(\"CreditsScroller\", creditsScrollerProps, (ts, ctx, props, sequence) => (0, creditsScroller_1.creditsScrollerEffect)(ts, ctx, props, demo.sequence));\n    creditsEntity.addPostProcessor((0, createBeatShakePostProcessor_1.createBeatShakePostProcessor)(3));\n    // Okey, done setup , add the stuff to scens \n    typeWriter1EntityForFirstScene.onBar((ts, count, props) => {\n        console.log(`${ts} bar #${count}.`);\n        // modify props on bar in this case;\n    });\n    scenes[0].addEntities(wgslShaderEntity);\n    scenes[1].addEntities(typeWriter1EntityForFirstScene, typeWriter2EntityForFirstScene, gridOverlayEffectEntity, ballEntity, stretchingTextEntity)\n        .addPostProcessorToEntities((0, createLensPostProcessor_1.createLensPostProcessor)((_b = assetsHelper_1.AssetsHelper.textureCache.get(\"lens.png\")) === null || _b === void 0 ? void 0 : _b.src));\n    scenes[2].addEntities(expandingCircleEntity, starburstEntity, imageOverlayEntity);\n    scenes[3].addEntities(audioVisualizerEntity, randomSquareEntity, imageOverlayEntity, imageOverlayEntity, typeWriterEntity);\n    scenes[4].addEntities(strobeEntity, pseudoKnightyanShaderEntity, imageOverlayEntity);\n    scenes[5].addEntities(someKindOfFractalShaderEntity, imageOverlayEntity, textOverlay, textArrayDisplayEntity);\n    scenes[6].addEntities(creditsEntity, imageOverlayEntity, ballEntity);\n    demo.sequence.addSceneArray(scenes);\n});\ndemo.sequence.onReady = () => {\n    const btn = document.querySelector(\"BUTTON\");\n    btn.textContent = \"CLICK TO START!\";\n    btn.addEventListener(\"click\", () => {\n        var _a;\n        (_a = document.querySelector(\"#launch\")) === null || _a === void 0 ? void 0 : _a.remove();\n        demo.sequence.play();\n    });\n};\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/demo.js?");

/***/ }),

/***/ "./build/wwwroot/src/effects/bubbleParticles.js":
/*!******************************************************!*\
  !*** ./build/wwwroot/src/effects/bubbleParticles.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ballEffect = void 0;\nconst ballEffect = (ts, ctx, propertybag, sequence) => {\n    const { numBalls, balls } = propertybag;\n    /**\n   * Creates a new ball with random properties.\n   * @param ctx - The 2D rendering context of the canvas.\n   * @param balls - The array to add the new ball to.\n   */\n    function createBall(ctx, balls) {\n        const colors = [\n            \"85, 221, 224\",\n            \"51, 101, 138\",\n            \"47, 72, 88\",\n            \"246, 174, 45\",\n            \"242, 100, 25\"\n        ];\n        const randomColor = colors[Math.floor(Math.random() * colors.length)];\n        const ballProps = {\n            x: ctx.canvas.width / 2,\n            y: ctx.canvas.height / 2,\n            radius: Math.floor(Math.random() * 12) + 4,\n            color: `rgba(${randomColor}, ${Math.random()})`,\n            vx: Math.random() * 8 - 4,\n            vy: Math.random() * 8 - 4,\n        };\n        balls.push(ballProps);\n    }\n    // Create balls if there are not enough\n    while (balls.length < numBalls) {\n        createBall(ctx, balls);\n    }\n    // Update and draw each ball\n    balls.forEach(ball => {\n        ctx.fillStyle = ball.color;\n        // Update position based on velocity\n        ball.x += ball.vx;\n        ball.y += ball.vy;\n        // Reset position if ball goes off-screen\n        if (ball.x + ball.radius > ctx.canvas.width || ball.x - ball.radius < 0) {\n            ball.x = Math.max(ball.radius, Math.min(ball.x, ctx.canvas.width - ball.radius));\n            ball.vx = -ball.vx;\n        }\n        if (ball.y + ball.radius > ctx.canvas.height || ball.y - ball.radius < 0) {\n            ball.y = Math.max(ball.radius, Math.min(ball.y, ctx.canvas.height - ball.radius));\n            ball.vy = -ball.vy;\n        }\n        // Draw the ball\n        ctx.beginPath();\n        ctx.arc(ball.x, ball.y, ball.radius, 0, 2 * Math.PI);\n        ctx.fill();\n    });\n};\nexports.ballEffect = ballEffect;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/effects/bubbleParticles.js?");

/***/ }),

/***/ "./build/wwwroot/src/effects/creditsScroller.js":
/*!******************************************************!*\
  !*** ./build/wwwroot/src/effects/creditsScroller.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.creditsScrollerEffect = void 0;\nconst creditsScrollerEffect = (ts, ctx, propertybag, sequence) => {\n    const { lines, lineHeight, scrollSpeed, fadeInDuration, fadeOutDuration } = propertybag;\n    const { width, height } = ctx.canvas;\n    ctx.font = propertybag.font; // Set your desired font\n    ctx.textAlign = \"center\";\n    ctx.fillStyle = \"white\";\n    // Calculate the total duration of the animation\n    const totalDuration = sequence.durationMs / 1000;\n    // Update and draw each line\n    lines.forEach((line, index) => {\n        const sceneStartTime = sequence.currentScene.startTimeinMs / 1000; // Get the scene's start time in seconds\n        const elapsed = ts / 1000 - sceneStartTime - (index * lineHeight) / scrollSpeed;\n        // Fade in and fade out logic\n        if (elapsed < fadeInDuration) {\n            line.alpha = Math.min(1, elapsed / fadeInDuration);\n        }\n        else if (elapsed > totalDuration - fadeOutDuration) {\n            line.alpha = Math.max(0, (totalDuration - elapsed) / fadeOutDuration);\n        }\n        else {\n            line.alpha = 1;\n        }\n        // Update the y position to scroll upwards\n        line.y = height - elapsed * scrollSpeed;\n        // Draw the text\n        ctx.globalAlpha = line.alpha;\n        ctx.fillText(line.text, width / 2, line.y);\n    });\n};\nexports.creditsScrollerEffect = creditsScrollerEffect;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/effects/creditsScroller.js?");

/***/ }),

/***/ "./build/wwwroot/src/effects/expandingCircleEffect.js":
/*!************************************************************!*\
  !*** ./build/wwwroot/src/effects/expandingCircleEffect.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.expandingCircleEffect = void 0;\nconst expandingCircleEffect = (ts, ctx, propertybag, sequence) => {\n    ctx.fillStyle = \"white\";\n    // Calculate the current radius based on remaining time\n    const remainingTime = sequence.getSceneRemainingTime(ts);\n    const progress = Math.max(0, 1 - remainingTime / (propertybag.duration * 1000)); // Ensure progress is not negative\n    propertybag.radius = propertybag.maxRadius * progress;\n    // Draw the circle\n    ctx.beginPath();\n    ctx.arc(propertybag.x, propertybag.y, propertybag.radius, 0, 2 * Math.PI);\n    ctx.fill();\n};\nexports.expandingCircleEffect = expandingCircleEffect;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/effects/expandingCircleEffect.js?");

/***/ }),

/***/ "./build/wwwroot/src/effects/fftAnalyzerEffect.js":
/*!********************************************************!*\
  !*** ./build/wwwroot/src/effects/fftAnalyzerEffect.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.audioVisualizerEffect = void 0;\nconst audioVisualizerEffect = (ts, ctx, propertybag, sequence) => {\n    const { x, y, width, height, barWidth, barSpacing, numBars, color } = propertybag;\n    const frequencyData = sequence.fftData; // Access FFT data from the sequence\n    if (!frequencyData) {\n        return; // No data available\n    }\n    const barCount = Math.min(numBars, frequencyData.length);\n    const barMaxHeight = height;\n    ctx.fillStyle = color;\n    for (let i = 0; i < barCount; i++) {\n        const barHeight = (frequencyData[i] / 255) * barMaxHeight; // Scale bar height\n        const barX = x + i * (barWidth + barSpacing);\n        const barY = y + height - barHeight;\n        ctx.fillRect(barX, barY, barWidth, barHeight);\n    }\n};\nexports.audioVisualizerEffect = audioVisualizerEffect;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/effects/fftAnalyzerEffect.js?");

/***/ }),

/***/ "./build/wwwroot/src/effects/gridOverlayEffect.js":
/*!********************************************************!*\
  !*** ./build/wwwroot/src/effects/gridOverlayEffect.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.gridOverlayEffect = void 0;\nconst gridOverlayEffect = (ts, ctx, propertybag, sequence) => {\n    const { rows, cols, cellColor, activeCells } = propertybag;\n    const cellWidth = ctx.canvas.width / cols;\n    const cellHeight = ctx.canvas.height / rows;\n    // Toggle cell activity based on beat\n    if (sequence.currentBeat > activeCells.size) {\n        let randomCellIndex;\n        do {\n            randomCellIndex = Math.floor(Math.random() * (rows * cols));\n        } while (activeCells.has(randomCellIndex));\n        activeCells.add(randomCellIndex);\n    }\n    ctx.fillStyle = cellColor;\n    for (let row = 0; row < rows; row++) {\n        for (let col = 0; col < cols; col++) {\n            const cellIndex = row * cols + col;\n            if (activeCells.has(cellIndex)) {\n                const x = col * cellWidth;\n                const y = row * cellHeight;\n                ctx.fillRect(x, y, cellWidth, cellHeight);\n            }\n        }\n    }\n};\nexports.gridOverlayEffect = gridOverlayEffect;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/effects/gridOverlayEffect.js?");

/***/ }),

/***/ "./build/wwwroot/src/effects/imageOverlayEffect.js":
/*!*********************************************************!*\
  !*** ./build/wwwroot/src/effects/imageOverlayEffect.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.imageOverlayEffect = exports.ImagePosition = void 0;\nvar ImagePosition;\n(function (ImagePosition) {\n    ImagePosition[ImagePosition[\"FILL\"] = 0] = \"FILL\";\n    ImagePosition[ImagePosition[\"LEFT\"] = 1] = \"LEFT\";\n    ImagePosition[ImagePosition[\"RIGHT\"] = 2] = \"RIGHT\";\n    ImagePosition[ImagePosition[\"TOP\"] = 3] = \"TOP\";\n    ImagePosition[ImagePosition[\"BOTTOM\"] = 4] = \"BOTTOM\";\n    ImagePosition[ImagePosition[\"BOTTOM_LEFT\"] = 5] = \"BOTTOM_LEFT\";\n    ImagePosition[ImagePosition[\"BOTTOM_RIGHT\"] = 6] = \"BOTTOM_RIGHT\";\n    ImagePosition[ImagePosition[\"TOP_LEFT\"] = 7] = \"TOP_LEFT\";\n    ImagePosition[ImagePosition[\"TOP_RIGHT\"] = 8] = \"TOP_RIGHT\";\n})(ImagePosition || (exports.ImagePosition = ImagePosition = {}));\nconst imageOverlayEffect = (ts, ctx, propertybag, sequence) => {\n    let { width, height, image, opacity, fadeIn, fadeOut, duration, position } = propertybag;\n    let x = 0;\n    let y = 0;\n    // Calculate x and y coordinates based on the specified position\n    switch (position) {\n        case ImagePosition.FILL:\n            x = 0;\n            y = 0;\n            width = ctx.canvas.width;\n            height = ctx.canvas.height;\n            break;\n        case ImagePosition.LEFT:\n            x = 0;\n            y = (ctx.canvas.height - height) / 2;\n            break;\n        case ImagePosition.RIGHT:\n            x = ctx.canvas.width - width;\n            y = (ctx.canvas.height - height) / 2;\n            break;\n        case ImagePosition.TOP:\n            x = (ctx.canvas.width - width) / 2;\n            y = 0;\n            break;\n        case ImagePosition.BOTTOM:\n            x = (ctx.canvas.width - width) / 2;\n            y = ctx.canvas.height - height;\n            break;\n        case ImagePosition.BOTTOM_LEFT:\n            x = 0;\n            y = ctx.canvas.height - height;\n            break;\n        case ImagePosition.BOTTOM_RIGHT:\n            x = ctx.canvas.width - width;\n            y = ctx.canvas.height - height;\n            break;\n        case ImagePosition.TOP_LEFT:\n            x = 0;\n            y = 0;\n            break;\n        case ImagePosition.TOP_RIGHT:\n            x = ctx.canvas.width - width;\n            y = 0;\n            break;\n    }\n    // Calculate the remaining time in the scene\n    const sceneRemainingTime = sequence.getSceneRemainingTime(ts);\n    const elapsed = duration - sceneRemainingTime / 1000;\n    // Calculate opacity based on fade-in/fade-out properties\n    let alpha = opacity;\n    if (fadeIn && elapsed < 1) {\n        alpha = opacity * elapsed;\n    }\n    if (fadeOut && sceneRemainingTime / 1000 < 1) {\n        alpha = opacity * (sceneRemainingTime / 1000);\n    }\n    // Draw the image with the calculated opacity\n    ctx.globalAlpha = alpha;\n    ctx.drawImage(image, x, y, width, height);\n    ctx.globalAlpha = 1; // Reset global alpha\n};\nexports.imageOverlayEffect = imageOverlayEffect;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/effects/imageOverlayEffect.js?");

/***/ }),

/***/ "./build/wwwroot/src/effects/ranndomSquareByTickEffect.js":
/*!****************************************************************!*\
  !*** ./build/wwwroot/src/effects/ranndomSquareByTickEffect.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.randomSquareEffect = void 0;\nconst randomSquareEffect = (ts, ctx, propertybag, tick) => {\n    if (tick !== propertybag.lastTick) {\n        propertybag.lastTick = tick;\n        ctx.globalAlpha = 0.5;\n        // Generate random properties for the square\n        propertybag.x = Math.random() * ctx.canvas.width;\n        propertybag.y = Math.random() * ctx.canvas.height;\n        propertybag.size = 20 + Math.random() * 50; // Random size between 20 and 70\n        propertybag.color = `hsl(${Math.random() * 360}, 100%, 50%)`; // Random color\n    }\n    // Draw the square\n    ctx.fillStyle = propertybag.color;\n    ctx.fillRect(propertybag.x, propertybag.y, propertybag.size, propertybag.size);\n};\nexports.randomSquareEffect = randomSquareEffect;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/effects/ranndomSquareByTickEffect.js?");

/***/ }),

/***/ "./build/wwwroot/src/effects/starBurstEffct.js":
/*!*****************************************************!*\
  !*** ./build/wwwroot/src/effects/starBurstEffct.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.starburstEffect = void 0;\nconst starburstEffect = (ts, ctx, propertybag) => {\n    const { x, y, numPoints, outerRadius, innerRadius, rotation, rotationSpeed, hue, saturation, lightness } = propertybag;\n    ctx.fillStyle = `hsl(${hue}, ${saturation}%, ${lightness}%)`;\n    ctx.beginPath();\n    for (let i = 0; i < numPoints * 2; i++) {\n        const radius = i % 2 === 0 ? outerRadius : innerRadius;\n        const angle = (Math.PI * i) / numPoints + rotation;\n        const px = x + radius * Math.cos(angle);\n        const py = y + radius * Math.sin(angle);\n        if (i === 0) {\n            ctx.moveTo(px, py);\n        }\n        else {\n            ctx.lineTo(px, py);\n        }\n    }\n    ctx.closePath();\n    ctx.fill();\n    propertybag.rotation += rotationSpeed * (Math.PI / 180); // Update rotation\n};\nexports.starburstEffect = starburstEffect;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/effects/starBurstEffct.js?");

/***/ }),

/***/ "./build/wwwroot/src/effects/streachingTextEffect.js":
/*!***********************************************************!*\
  !*** ./build/wwwroot/src/effects/streachingTextEffect.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.stretchingTextEffect = void 0;\nconst stretchingTextEffect = (ts, ctx, propertybag, sequence) => {\n    const { texts, currentIndex, font, color, lastBeat } = propertybag;\n    if (sequence.currentBeat !== lastBeat) {\n        propertybag.currentIndex = (propertybag.currentIndex + 1) % texts.length; // Cycle through texts\n        propertybag.lastBeat = sequence.currentBeat;\n    }\n    const text = texts[currentIndex];\n    // Calculate the text size to fit the canvas\n    let fontSize = 10;\n    ctx.font = `${fontSize}px ${font}`;\n    let textMetrics = ctx.measureText(text);\n    let textWidth = textMetrics.width;\n    let textHeight = textMetrics.actualBoundingBoxAscent + textMetrics.actualBoundingBoxDescent;\n    // Adjust font size to fit the canvas\n    const scaleX = ctx.canvas.width / textWidth;\n    const scaleY = ctx.canvas.height / textHeight;\n    const scale = Math.min(scaleX, scaleY);\n    fontSize *= scale;\n    ctx.font = `${fontSize}px ${font}`;\n    // Recalculate text metrics with the new font size\n    textMetrics = ctx.measureText(text);\n    textWidth = textMetrics.width;\n    textHeight = textMetrics.actualBoundingBoxAscent + textMetrics.actualBoundingBoxDescent;\n    // Calculate the x and y coordinates to center the text\n    const x = (ctx.canvas.width - textWidth) / 2;\n    const y = (ctx.canvas.height + textHeight) / 2;\n    ctx.fillStyle = color;\n    ctx.fillText(text, x, y);\n};\nexports.stretchingTextEffect = stretchingTextEffect;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/effects/streachingTextEffect.js?");

/***/ }),

/***/ "./build/wwwroot/src/effects/strobeEffect.js":
/*!***************************************************!*\
  !*** ./build/wwwroot/src/effects/strobeEffect.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.strobeEffect = void 0;\nconst strobeEffect = (ts, ctx, propertybag, sequence) => {\n    const { color, isOn, lastBeat } = propertybag;\n    if (sequence.currentBeat !== lastBeat) {\n        propertybag.isOn = !isOn; // Toggle the strobe on/off on each beat\n        propertybag.lastBeat = sequence.currentBeat;\n    }\n    if (isOn) {\n        ctx.fillStyle = color;\n        ctx.fillRect(0, 0, ctx.canvas.width, ctx.canvas.height); // Fill the canvas\n    }\n};\nexports.strobeEffect = strobeEffect;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/effects/strobeEffect.js?");

/***/ }),

/***/ "./build/wwwroot/src/effects/textArrayDisplayEffect.js":
/*!*************************************************************!*\
  !*** ./build/wwwroot/src/effects/textArrayDisplayEffect.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.textArrayDisplayEffect = void 0;\nconst textArrayDisplayEffect = (ts, ctx, propertybag, sequence // Pass the Sequence instance\n) => {\n    const { x, y, texts, font, size } = propertybag;\n    ctx.font = `${size}px ${font}`;\n    ctx.fillStyle = \"white\";\n    // Se till att currentBeat är inom gränserna för texts-arrayen\n    const index = Math.min(sequence.currentBeat - 1, texts.length - 1);\n    // Visa texten vid aktuellt index\n    if (index >= 0) {\n        ctx.fillText(texts[index], x, y);\n    }\n};\nexports.textArrayDisplayEffect = textArrayDisplayEffect;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/effects/textArrayDisplayEffect.js?");

/***/ }),

/***/ "./build/wwwroot/src/effects/textEffect.js":
/*!*************************************************!*\
  !*** ./build/wwwroot/src/effects/textEffect.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.textEffect = void 0;\nconst textEffect = (ts, ctx, propertybag, sequence // Pass the Sequence instance\n) => {\n    const { x, y, text, font, size, duration } = propertybag;\n    ctx.font = `${size}px ${font}`;\n    ctx.fillStyle = \"white\";\n    const sceneRemainingTime = sequence.getSceneRemainingTime(ts);\n    const elapsed = duration - sceneRemainingTime / 1000; // Time elapsed in seconds\n    let alpha = 1;\n    if (elapsed < 1) {\n        alpha = elapsed; // Fade in over 1 second\n    }\n    if (sceneRemainingTime / 1000 < 1) {\n        alpha = sceneRemainingTime / 1000; // Fade out over 1 second\n    }\n    ctx.globalAlpha = alpha;\n    ctx.fillText(text, x, y);\n    ctx.globalAlpha = 1;\n};\nexports.textEffect = textEffect;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/effects/textEffect.js?");

/***/ }),

/***/ "./build/wwwroot/src/effects/typeWriterEffet.js":
/*!******************************************************!*\
  !*** ./build/wwwroot/src/effects/typeWriterEffet.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.typeWriterEffect = void 0;\nconst typeWriterEffect = (ts, ctx, propertybag) => {\n    ctx.font = \"68px Big Shoulders Stencil Text\";\n    ctx.fillStyle = \"white\";\n    let elapsedTime = 0;\n    if (propertybag.useBPM) {\n        // Calculate characters per beat\n        const charactersPerBeat = propertybag.speed / (propertybag.bpm / 60);\n        // Elapsed time in beats\n        elapsedTime = (ts - propertybag.lastCharacterTime) / (60000 / propertybag.bpm);\n    }\n    else {\n        // Calculate characters per tick\n        const charactersPerTick = propertybag.speed / ((propertybag.bpm * 4) / 60);\n        // Elapsed time in ticks\n        elapsedTime = (ts - propertybag.lastCharacterTime) / (60000 / (propertybag.bpm * propertybag.ticksPerBeat));\n    }\n    if (elapsedTime >= 1 / propertybag.speed) {\n        propertybag.index++;\n        propertybag.lastCharacterTime = ts;\n    }\n    // Draw the substring\n    const displayText = propertybag.text.substring(0, propertybag.index);\n    // Measure the full text width\n    const fullTextMetrics = ctx.measureText(propertybag.text);\n    const fullTextWidth = fullTextMetrics.width;\n    // Calculate the centered x-coordinate\n    const centeredX = (ctx.canvas.width - fullTextWidth) / 2;\n    ctx.fillText(displayText, centeredX, propertybag.y / 2);\n};\nexports.typeWriterEffect = typeWriterEffect;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/effects/typeWriterEffet.js?");

/***/ }),

/***/ "./build/wwwroot/src/postprocessors/createBeatShakePostProcessor.js":
/*!**************************************************************************!*\
  !*** ./build/wwwroot/src/postprocessors/createBeatShakePostProcessor.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.createBeatShakePostProcessor = void 0;\nconst createBeatShakePostProcessor = (intensity = 10) => {\n    return (ctx, sequence) => {\n        const offsetX = (Math.random() - 0.5) * intensity * sequence.currentBeat;\n        const offsetY = (Math.random() - 0.5) * intensity * sequence.currentBeat;\n        ctx.drawImage(ctx.canvas, offsetX, offsetY);\n    };\n};\nexports.createBeatShakePostProcessor = createBeatShakePostProcessor;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/postprocessors/createBeatShakePostProcessor.js?");

/***/ }),

/***/ "./build/wwwroot/src/postprocessors/createLensPostProcessor.js":
/*!*********************************************************************!*\
  !*** ./build/wwwroot/src/postprocessors/createLensPostProcessor.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.createLensPostProcessor = void 0;\n/**\n * Creates a post-processing function that applies a lens effect using a provided image.\n * @returns A post-processing function that can be added to a Sequence or Entity.\n */\nconst createLensPostProcessor = (lensImage) => {\n    return (ctx) => {\n        const { width, height } = ctx.canvas;\n        // Create a temporary canvas to draw the blended image\n        const tempCanvas = document.createElement('canvas');\n        tempCanvas.width = width;\n        tempCanvas.height = height;\n        const tempCtx = tempCanvas.getContext('2d');\n        // Draw the original image onto the temporary canvas\n        tempCtx.drawImage(ctx.canvas, 0, 0);\n        // Draw the lens image on top with \"multiply\" blend mode\n        tempCtx.globalCompositeOperation = \"multiply\";\n        tempCtx.drawImage(lensImage, 0, 0, width, height);\n        // Draw the blended image back onto the original canvas\n        ctx.drawImage(tempCanvas, 0, 0);\n    };\n};\nexports.createLensPostProcessor = createLensPostProcessor;\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/postprocessors/createLensPostProcessor.js?");

/***/ }),

/***/ "./node_modules/sonantx/dist/sonantx.bundle.js":
/*!*****************************************************!*\
  !*** ./node_modules/sonantx/dist/sonantx.bundle.js ***!
  \*****************************************************/
/***/ ((module) => {

eval("(function webpackUniversalModuleDefinition(root, factory) {\n\tif(true)\n\t\tmodule.exports = factory();\n\telse {}\n})(window, function() {\nreturn /******/ (function(modules) { // webpackBootstrap\n/******/ \t// The module cache\n/******/ \tvar installedModules = {};\n/******/\n/******/ \t// The require function\n/******/ \tfunction __nested_webpack_require_539__(moduleId) {\n/******/\n/******/ \t\t// Check if module is in cache\n/******/ \t\tif(installedModules[moduleId]) {\n/******/ \t\t\treturn installedModules[moduleId].exports;\n/******/ \t\t}\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = installedModules[moduleId] = {\n/******/ \t\t\ti: moduleId,\n/******/ \t\t\tl: false,\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/\n/******/ \t\t// Execute the module function\n/******/ \t\tmodules[moduleId].call(module.exports, module, module.exports, __nested_webpack_require_539__);\n/******/\n/******/ \t\t// Flag the module as loaded\n/******/ \t\tmodule.l = true;\n/******/\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/\n/******/\n/******/ \t// expose the modules object (__webpack_modules__)\n/******/ \t__nested_webpack_require_539__.m = modules;\n/******/\n/******/ \t// expose the module cache\n/******/ \t__nested_webpack_require_539__.c = installedModules;\n/******/\n/******/ \t// define getter function for harmony exports\n/******/ \t__nested_webpack_require_539__.d = function(exports, name, getter) {\n/******/ \t\tif(!__nested_webpack_require_539__.o(exports, name)) {\n/******/ \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n/******/ \t\t}\n/******/ \t};\n/******/\n/******/ \t// define __esModule on exports\n/******/ \t__nested_webpack_require_539__.r = function(exports) {\n/******/ \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n/******/ \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n/******/ \t\t}\n/******/ \t\tObject.defineProperty(exports, '__esModule', { value: true });\n/******/ \t};\n/******/\n/******/ \t// create a fake namespace object\n/******/ \t// mode & 1: value is a module id, require it\n/******/ \t// mode & 2: merge all properties of value into the ns\n/******/ \t// mode & 4: return value when already ns object\n/******/ \t// mode & 8|1: behave like require\n/******/ \t__nested_webpack_require_539__.t = function(value, mode) {\n/******/ \t\tif(mode & 1) value = __nested_webpack_require_539__(value);\n/******/ \t\tif(mode & 8) return value;\n/******/ \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n/******/ \t\tvar ns = Object.create(null);\n/******/ \t\t__nested_webpack_require_539__.r(ns);\n/******/ \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n/******/ \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __nested_webpack_require_539__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n/******/ \t\treturn ns;\n/******/ \t};\n/******/\n/******/ \t// getDefaultExport function for compatibility with non-harmony modules\n/******/ \t__nested_webpack_require_539__.n = function(module) {\n/******/ \t\tvar getter = module && module.__esModule ?\n/******/ \t\t\tfunction getDefault() { return module['default']; } :\n/******/ \t\t\tfunction getModuleExports() { return module; };\n/******/ \t\t__nested_webpack_require_539__.d(getter, 'a', getter);\n/******/ \t\treturn getter;\n/******/ \t};\n/******/\n/******/ \t// Object.prototype.hasOwnProperty.call\n/******/ \t__nested_webpack_require_539__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n/******/\n/******/ \t// __webpack_public_path__\n/******/ \t__nested_webpack_require_539__.p = \"\";\n/******/\n/******/\n/******/ \t// Load entry module and return exports\n/******/ \treturn __nested_webpack_require_539__(__nested_webpack_require_539__.s = \"./sonantx.js\");\n/******/ })\n/************************************************************************/\n/******/ ({\n\n/***/ \"./sonantx.js\":\n/*!********************!*\\\n  !*** ./sonantx.js ***!\n  \\********************/\n/*! exports provided: generateSound, generateSong */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\neval(\"__webpack_require__.r(__webpack_exports__);\\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \\\"generateSound\\\", function() { return generateSound; });\\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \\\"generateSong\\\", function() { return generateSong; });\\n// Oscillators\\nfunction osc_sin(value) {\\n  return Math.sin(value * Math.PI * 2);\\n}\\n\\nfunction osc_square(value) {\\n  if (osc_sin(value) < 0) {\\n    return -1;\\n  }\\n\\n  return 1;\\n}\\n\\nfunction osc_saw(value) {\\n  return value % 1 - 0.5;\\n}\\n\\nfunction osc_tri(value) {\\n  const v2 = value % 1 * 4;\\n\\n  if (v2 < 2) {\\n    return v2 - 1;\\n  }\\n\\n  return 3 - v2;\\n} // Array of oscillator functions\\n\\n\\nconst oscillators = [osc_sin, osc_square, osc_saw, osc_tri];\\n\\nfunction getnotefreq44100(n) {\\n  const val = 0.00390625 * Math.pow(1.059463094, n - 128);\\n  return val;\\n}\\n\\nfunction getnotefreq(audioCtx, n) {\\n  const x = getnotefreq44100(n);\\n  const val = x / audioCtx.sampleRate * 44100;\\n  return val;\\n}\\n\\nfunction effectiveRowLen(audioCtx, bpm) {\\n  return Math.round(60 * audioCtx.sampleRate / 4 / bpm);\\n}\\n\\nclass SoundWriter {\\n  constructor(audioCtx, instr, n, bpm) {\\n    this.audioCtx = audioCtx;\\n    this.instr = instr;\\n    this.n = n;\\n    this.bpm = bpm;\\n    this.c1 = 0;\\n    this.c2 = 0;\\n    this.low = 0;\\n    this.band = 0;\\n    this.j = 0;\\n  }\\n\\n  write(lchan, rchan, from) {\\n    const instr = this.instr;\\n    const n = this.n;\\n    let c = from;\\n    const osc_lfo = oscillators[instr.lfo_waveform];\\n    const osc1 = oscillators[instr.osc1_waveform];\\n    const osc2 = oscillators[instr.osc2_waveform];\\n    const panFreq = Math.pow(2, instr.fx_pan_freq - 8) / effectiveRowLen(this.audioCtx, this.bpm);\\n    const lfoFreq = Math.pow(2, instr.lfo_freq - 8) / effectiveRowLen(this.audioCtx, this.bpm);\\n    const attackTime = instr.env_attack / 44100;\\n    const releaseTime = instr.env_release / 44100;\\n    const sustainTime = instr.env_sustain / 44100;\\n    const env_attack = attackTime * this.audioCtx.sampleRate;\\n    const env_release = releaseTime * this.audioCtx.sampleRate;\\n    const env_sustain = sustainTime * this.audioCtx.sampleRate; // Precalculate frequencues\\n\\n    const o1t = getnotefreq(this.audioCtx, n + (instr.osc1_oct - 8) * 12 + instr.osc1_det) * (1 + 0.0008 * instr.osc1_detune);\\n    const o2t = getnotefreq(this.audioCtx, n + (instr.osc2_oct - 8) * 12 + instr.osc2_det) * (1 + 0.0008 * instr.osc2_detune); // State variable init\\n\\n    const q = instr.fx_resonance / 255;\\n\\n    while (this.j < env_attack + env_sustain + env_release && c < lchan.length) {\\n      // LFO\\n      const lfor = osc_lfo(this.j * lfoFreq) * instr.lfo_amt / 512 + 0.5; // Envelope\\n\\n      let e = 1;\\n\\n      if (this.j < env_attack) {\\n        e = this.j / env_attack;\\n      } else if (this.j >= env_attack + env_sustain) {\\n        e -= (this.j - env_attack - env_sustain) / env_release;\\n      } // Oscillator 1\\n\\n\\n      let t = o1t;\\n\\n      if (instr.lfo_osc1_freq) {\\n        t += lfor;\\n      }\\n\\n      if (instr.osc1_xenv) {\\n        t *= e * e;\\n      }\\n\\n      this.c1 += t;\\n      let rsample = osc1(this.c1) * instr.osc1_vol; // Oscillator 2\\n\\n      t = o2t;\\n\\n      if (instr.osc2_xenv) {\\n        t *= e * e;\\n      }\\n\\n      this.c2 += t;\\n      rsample += osc2(this.c2) * instr.osc2_vol; // Noise oscillator\\n\\n      if (instr.noise_fader) {\\n        rsample += (2 * Math.random() - 1) * instr.noise_fader * e;\\n      }\\n\\n      rsample *= e / 255; // State variable filter\\n\\n      let f = instr.fx_freq;\\n\\n      if (instr.lfo_fx_freq) {\\n        f *= lfor;\\n      }\\n\\n      f = 1.5 * Math.sin(f * Math.PI / this.audioCtx.sampleRate);\\n      this.low += f * this.band;\\n      const high = q * (rsample - this.band) - this.low;\\n      this.band += f * high;\\n\\n      switch (instr.fx_filter) {\\n        case 1:\\n          // Hipass\\n          rsample = high;\\n          break;\\n\\n        case 2:\\n          // Lopass\\n          rsample = this.low;\\n          break;\\n\\n        case 3:\\n          // Bandpass\\n          rsample = this.band;\\n          break;\\n\\n        case 4:\\n          // Notch\\n          rsample = this.low + high;\\n          break;\\n\\n        default:\\n      } // Panning & master volume\\n\\n\\n      t = osc_sin(this.j * panFreq) * instr.fx_pan_amt / 512 + 0.5;\\n      rsample *= 39 * instr.env_master;\\n      let x = 32768 + rsample * (1 - t);\\n      let x1 = x & 255;\\n      let x2 = x >> 8 & 255;\\n      let y = 4 * (x1 + (x2 << 8) - 32768);\\n      y = y < -32768 ? -32768 : y > 32767 ? 32767 : y;\\n      lchan[c] = lchan[c] + y / 32768;\\n      x = 32768 + rsample * t;\\n      x1 = x & 255;\\n      x2 = x >> 8 & 255;\\n      y = 4 * (x1 + (x2 << 8) - 32768);\\n      y = y < -32768 ? -32768 : y > 32767 ? 32767 : y;\\n      rchan[c] = rchan[c] + y / 32768;\\n      this.j++;\\n      c++;\\n    } // returns true if the sound finished\\n\\n\\n    if (c < lchan.length) {\\n      return true;\\n    }\\n\\n    return false;\\n  }\\n\\n}\\n\\nclass TrackGenerator {\\n  constructor(audioCtx, instr, bpm, endPattern) {\\n    bpm = bpm || 118;\\n    endPattern = endPattern || instr.p.length - 1;\\n    this.audioCtx = audioCtx;\\n    this.instr = instr;\\n    this.bpm = bpm;\\n    this.endPattern = endPattern;\\n    const source = this.audioCtx.createOscillator();\\n    const nullGain = this.audioCtx.createGain();\\n    nullGain.gain.value = 0;\\n    source.connect(nullGain);\\n    const scriptNode = this.audioCtx.createScriptProcessor(512, 2, 2);\\n    nullGain.connect(scriptNode);\\n    let currentSample = 0;\\n    let nextNote = 0;\\n    let sounds = [];\\n\\n    scriptNode.onaudioprocess = audioProcessingEvent => {\\n      const inputData = audioProcessingEvent.inputBuffer;\\n      const outputData = audioProcessingEvent.outputBuffer;\\n      const lchan = outputData.getChannelData(0);\\n      const rchan = outputData.getChannelData(1);\\n      lchan.set(inputData.getChannelData(0));\\n      rchan.set(inputData.getChannelData(1));\\n      sounds.slice().forEach(el => {\\n        const finished = el.write(lchan, rchan, 0);\\n\\n        if (finished) {\\n          sounds = sounds.filter(el2 => {\\n            return el2 !== el;\\n          });\\n        }\\n      });\\n      let nextNoteSample = nextNote * effectiveRowLen(this.audioCtx, this.bpm);\\n\\n      while (nextNoteSample >= currentSample && nextNoteSample < currentSample + inputData.length) {\\n        const pattern = instr.p[Math.floor(nextNote / 32) % (this.endPattern + 1)] || 0;\\n        const note = pattern === 0 ? 0 : (instr.c[pattern - 1] || {\\n          n: []\\n        }).n[nextNote % 32] || 0;\\n\\n        if (note !== 0) {\\n          const sw = new SoundWriter(this.audioCtx, instr, note, this.bpm);\\n          sw.write(lchan, rchan, nextNoteSample - currentSample);\\n          sounds.push(sw);\\n        }\\n\\n        nextNote += 1;\\n        nextNoteSample = nextNote * effectiveRowLen(this.audioCtx, this.bpm);\\n      }\\n\\n      currentSample += inputData.length;\\n    };\\n\\n    const delayTime = instr.fx_delay_time * (1 / (this.bpm / 60) / 8);\\n    const delayAmount = instr.fx_delay_amt / 255;\\n    const delayGain = this.audioCtx.createGain();\\n    delayGain.gain.value = delayAmount;\\n    scriptNode.connect(delayGain);\\n    const delay = this.audioCtx.createDelay();\\n    delay.delayTime.value = delayTime;\\n    delayGain.connect(delay);\\n    delay.connect(delayGain);\\n    const mixer = this.audioCtx.createGain();\\n    mixer.gain.value = 1;\\n    scriptNode.connect(mixer);\\n    delay.connect(mixer);\\n    this.chain = [source, nullGain, scriptNode, delayGain, delay, mixer];\\n  }\\n\\n  start(when) {\\n    this.chain[0].start(when);\\n  }\\n\\n  stop(when) {\\n    this.chain[0].stop(when);\\n    this.chain[this.chain.length - 1].disconnect();\\n  }\\n\\n  connect(target) {\\n    this.chain[this.chain.length - 1].connect(target);\\n  }\\n\\n}\\n\\nclass MusicGenerator {\\n  constructor(audioCtx, song) {\\n    this.audioCtx = audioCtx;\\n    this.song = song;\\n    const mixer = this.audioCtx.createGain();\\n    mixer.gain.value = 1;\\n    this.tracks = [];\\n    this.song.songData.forEach(el => {\\n      const track = new TrackGenerator(this.audioCtx, el, this.bpm, this.song.endPattern);\\n      track.connect(mixer);\\n      this.tracks.push(track);\\n    });\\n    this.chain = [this.tracks, mixer];\\n  }\\n\\n  get bpm() {\\n    // rowLen is a number of samples when using 44100hz\\n    return Math.round(60 * 44100 / 4 / this.song.rowLen);\\n  }\\n\\n  start(when) {\\n    when = when || this.audioCtx.currentTime;\\n    this.tracks.forEach(t => t.start(when));\\n  }\\n\\n  stop(when) {\\n    when = when || this.audioCtx.currentTime;\\n    this.tracks.forEach(t => t.stop(when));\\n    this.chain[this.chain.length - 1].disconnect();\\n  }\\n\\n  connect(target) {\\n    this.chain[this.chain.length - 1].connect(target);\\n  }\\n\\n}\\n/**\\n * Generates a single note from an instrument.\\n *\\n * @param {*} instr The instrument descriptor\\n * @param {*} n The note as a midi note\\n * @param {*} sampleRate The sample rate\\n * @param {*} bpm The bpm of the song\\n * @returns {AudioBuffer} The generated audio buffer\\n */\\n\\n\\nasync function generateSound(instr, n, sampleRate, bpm = 120) {\\n  const attackTime = instr.env_attack / 44100;\\n  const releaseTime = instr.env_release / 44100;\\n  const sustainTime = instr.env_sustain / 44100;\\n  const soundLenSeconds = attackTime + releaseTime + sustainTime + 8 * (1 / (bpm / 60));\\n  const nInstr = Object.assign({}, instr);\\n  nInstr.p = [1, 0, 0, 0];\\n  nInstr.c = [{\\n    n: new Array(32).map(() => 0)\\n  }];\\n  nInstr.c[0].n[0] = n + 75;\\n  const audioCtx = new OfflineAudioContext(2, soundLenSeconds * sampleRate, sampleRate);\\n  const soundGen = new TrackGenerator(audioCtx, nInstr, bpm, 0);\\n  soundGen.connect(audioCtx.destination);\\n  soundGen.start();\\n  const buf = await audioCtx.startRendering();\\n  return buf;\\n}\\n/**\\n * Generates a complete song from a song description.\\n *\\n * @param {*} song The song description\\n * @param {*} options `sampleRate`: the sample rate\\n * @returns {AudioBuffer} The generated audio buffer\\n */\\n\\nasync function generateSong(song, sampleRate) {\\n  const songLenSeconds = song.songLen;\\n  const audioCtx = new OfflineAudioContext(2, songLenSeconds * sampleRate, sampleRate);\\n  const soundGen = new MusicGenerator(audioCtx, song);\\n  soundGen.connect(audioCtx.destination);\\n  soundGen.start();\\n  const buf = await audioCtx.startRendering();\\n  return buf;\\n}\\n\\n//# sourceURL=webpack://sonantx/./sonantx.js?\");\n\n/***/ })\n\n/******/ });\n});\n\n//# sourceURL=webpack://demolished-rail/./node_modules/sonantx/dist/sonantx.bundle.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./build/wwwroot/src/demo.js");
/******/ 	
/******/ })()
;