/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./build/src/Engine/Audio/AudioLoader.js":
/*!***********************************************!*\
  !*** ./build/src/Engine/Audio/AudioLoader.js ***!
  \***********************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SonantAudioLoader = exports.DefaultAudioLoader = void 0;\nconst sonant = __importStar(__webpack_require__(/*! sonantx */ \"./node_modules/sonantx/dist/sonantx.bundle.js\"));\nconst EngineLogger_1 = __webpack_require__(/*! ../EngineLogger */ \"./build/src/Engine/EngineLogger.js\");\n// RegularAudioLoader.ts\nclass DefaultAudioLoader {\n    constructor(audioFile) {\n        this.audioFile = audioFile;\n    }\n    async loadAudio(audioContext) {\n        const response = await fetch(this.audioFile);\n        const arrayBuffer = await response.arrayBuffer();\n        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);\n        EngineLogger_1.EngineLogger.log(`audioBuffer duration after decoding is ${audioBuffer.duration} seconds`);\n        return audioBuffer;\n    }\n}\nexports.DefaultAudioLoader = DefaultAudioLoader;\nclass SonantAudioLoader {\n    constructor(songData) {\n        this.songData = songData;\n    } // Replace 'any' with the actual type of your song data\n    async loadAudio(audioContext) {\n        console.log(`Generating audioBuffer - it may take a while`);\n        const audioBuffer = await sonant.generateSong(this.songData, audioContext.sampleRate);\n        EngineLogger_1.EngineLogger.log(`audioBuffer duration after decoding is ${audioBuffer.duration} seconds`);\n        return audioBuffer;\n    }\n}\nexports.SonantAudioLoader = SonantAudioLoader;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Audio/AudioLoader.js?");

/***/ }),

/***/ "./build/src/Engine/Conductor.js":
/*!***************************************!*\
  !*** ./build/src/Engine/Conductor.js ***!
  \***************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Conductor = void 0;\nclass Conductor {\n    constructor() {\n        this.events = [];\n        this.currentTime = 0;\n    }\n    /**\n     * Adds an event to the timeline.\n     * @param event - The event to add.\n     */\n    addEvent(event) {\n        this.events.push(event);\n    }\n    /**\n     * Updates the current time of the timeline.\n     * @param time - The current time in milliseconds.\n     */\n    updateTime(time) {\n        this.currentTime = time;\n    }\n    triggerEvents(sequence) {\n        this.events.forEach(event => {\n            var _a;\n            const { time, beatCount, barCount, action, targetEntity, criteria, props } = event;\n            // Check if the event should be triggered\n            const timeCondition = time !== undefined ? this.currentTime >= time : true; // True if time is not specified\n            const beatCondition = beatCount !== undefined ? sequence.beatCounter >= beatCount : true; // True if beatCount is not specified\n            const barCondition = barCount !== undefined ? sequence.currentBar >= barCount : true; // True if barCount is not specified\n            const criteriaResult = criteria ? criteria() : true;\n            // Combine all conditions\n            if ((timeCondition && beatCondition && barCondition) && // All specified conditions must be true\n                criteriaResult // Criteria must also be true (if provided)\n            ) {\n                const entity = (_a = sequence.currentScene) === null || _a === void 0 ? void 0 : _a.entities.find(e => e.name === targetEntity);\n                if (entity) {\n                    action(entity, props, criteriaResult);\n                }\n            }\n        });\n    }\n}\nexports.Conductor = Conductor;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Conductor.js?");

/***/ }),

/***/ "./build/src/Engine/EngineLogger.js":
/*!******************************************!*\
  !*** ./build/src/Engine/EngineLogger.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EngineLogger = void 0;\nclass EngineLogger {\n    /**\n     * Enables or disables logging.\n     * @param enabled - Whether logging should be enabled or disabled.\n     */\n    static setEnabled(enabled) {\n        this.enabled = enabled;\n    }\n    /**\n     * Logs messages to the console if logging is enabled.\n     * @param args - The messages to log.\n     */\n    static log(...args) {\n        if (this.enabled) {\n            console.log(...args);\n        }\n    }\n}\nexports.EngineLogger = EngineLogger;\nEngineLogger.enabled = true; // Add a flag to control logging\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/EngineLogger.js?");

/***/ }),

/***/ "./build/src/Engine/Entity.js":
/*!************************************!*\
  !*** ./build/src/Engine/Entity.js ***!
  \************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Entity = void 0;\nclass Entity {\n    /**\n     * Creates a new Entity.\n     * @param name - The key or identifier for the entity.\n     * @param w - The width of the entity's canvas.\n     * @param h - The height of the entity's canvas.\n     * @param props - The properties for the entity.\n     * @param action - The action function that defines the entity's behavior.\n     */\n    constructor(name, props, action, startTimeinMs, durationInMs, w, h) {\n        this.name = name;\n        this.props = props;\n        this.action = action;\n        this.startTimeinMs = startTimeinMs;\n        this.durationInMs = durationInMs;\n        this.w = w;\n        this.h = h;\n        this.postProcessors = [];\n        this.beatListeners = [];\n        this.tickListeners = [];\n        this.barListeners = [];\n        this.canvas = document.createElement(\"canvas\");\n        if (w !== undefined && h !== undefined) {\n            this.canvas.width = w;\n            this.canvas.height = h;\n        }\n        ;\n        this.ctx = this.canvas.getContext(\"2d\");\n    }\n    bindToScene(scene) {\n        this.scene = scene;\n    }\n    /**\n    * Adds an event listener for when a beat occurs.\n    * @param listener - The function to call when a beat occurs.\n    * @returns The Entity instance for chaining.\n    */\n    onBeat(listener) {\n        this.beatListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds an event listener for when a tick occurs.\n     * @param listener - The function to call when a tick occurs.\n     * @returns The Entity instance for chaining.\n     */\n    onTick(listener) {\n        this.tickListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds an event listener for when a bar is complete.\n     * @param listener - The function to call when a bar is complete.\n     * @returns The Entity instance for chaining.\n     */\n    onBar(listener) {\n        this.barListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds a post-processing function to the entity.\n     * @param processor - The post-processing function to add.\n     */\n    addPostProcessor(processor) {\n        this.postProcessors.push(processor);\n    }\n    /**\n     * Copies the entity's canvas to the target canvas and applies post-processors.\n     * @param targetCanvas - The target canvas to copy to.\n     * @param sequence - The Sequence instance.\n     */\n    copyToCanvas(targetCanvas, sequence) {\n        const targetCtx = targetCanvas.getContext(\"2d\");\n        if (targetCtx) {\n            // Calculate the elapsed time for the entity\n            const elapsed = sequence.currentTime - (this.startTimeinMs || 0);\n            // Check if the entity should be rendered based on its lifetime\n            if (elapsed >= 0 && elapsed <= (this.durationInMs || Infinity)) {\n                targetCtx.drawImage(this.canvas, 0, 0);\n                this.postProcessors.forEach(processor => processor(targetCtx, sequence));\n            }\n        }\n    }\n    /**\n    * Updates the entity's state, clears the canvas, and calls the action function.\n    * @param timeStamp - The current timestamp in the animation.\n    */\n    update(timeStamp) {\n        var _a;\n        (_a = this.ctx) === null || _a === void 0 ? void 0 : _a.clearRect(0, 0, this.canvas.width, this.canvas.height);\n        if (this.action && this.ctx && this.props) {\n            // Calculate elapsed time relative to the scene's start time    \n            const sceneStartTime = this.getScene().startTimeinMs || 0;\n            const elapsed = timeStamp - sceneStartTime - (this.startTimeinMs || 0);\n            if (elapsed >= 0 && elapsed <= (this.durationInMs || Infinity)) {\n                this.action(timeStamp, this.ctx, this.props);\n            }\n        }\n    }\n    /**\n   * Retrieves the Sequence instance associated with the entity.\n   * @returns The Sequence instance if available, otherwise null.\n   */\n    getScene() {\n        return this.scene;\n    }\n}\nexports.Entity = Entity;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Entity.js?");

/***/ }),

/***/ "./build/src/Engine/GLSLShaderEntity.js":
/*!**********************************************!*\
  !*** ./build/src/Engine/GLSLShaderEntity.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GLSLShaderEntity = void 0;\nconst GLSLShaderRenderer_1 = __webpack_require__(/*! ./ShaderRenderers/WebGL/GLSLShaderRenderer */ \"./build/src/Engine/ShaderRenderers/WebGL/GLSLShaderRenderer.js\");\nclass GLSLShaderEntity {\n    /**\n     * Creates a new ShaderEntity.\n     * @param name - The key or identifier for the entity.\n     * @param w - The width of the entity's canvas.\n     * @param h - The height of the entity's canvas.\n     * @param props - The properties for the entity, including shader code and render buffers.\n     * @param action - An optional action function to be called before rendering the shaders.\n     */\n    constructor(name, props, action, w, h, startTimeinMs, durationInMs) {\n        this.name = name;\n        this.props = props;\n        this.action = action;\n        this.w = w;\n        this.h = h;\n        this.startTimeinMs = startTimeinMs;\n        this.durationInMs = durationInMs;\n        this.beatListeners = [];\n        this.tickListeners = [];\n        this.barListeners = [];\n        this.postProcessors = [];\n        this.canvas = document.createElement(\"canvas\");\n        if (w && h) {\n            this.canvas.width = w;\n            this.canvas.height = h;\n        }\n        if ((props === null || props === void 0 ? void 0 : props.mainFragmentShader) && props.mainVertexShader) {\n            this.shaderRenderer = new GLSLShaderRenderer_1.GLSLShaderRenderer(this.canvas, props === null || props === void 0 ? void 0 : props.mainVertexShader, props === null || props === void 0 ? void 0 : props.mainFragmentShader);\n            props.renderBuffers.forEach(buffer => {\n                this.shaderRenderer.addBuffer(buffer.name, buffer.vertex, buffer.fragment, buffer.textures, buffer.customUniforms);\n            });\n        }\n        else {\n            throw new Error(\"Cannot create ShaderEntity: Missing main shader code.\");\n        }\n    }\n    bindToScene(scene) {\n        this.scene = scene;\n    }\n    /**\n * Adds an event listener for when a beat occurs.\n * @param listener - The function to call when a beat occurs.\n * @returns The Entity instance for chaining.\n */\n    onBeat(listener) {\n        this.beatListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds an event listener for when a tick occurs.\n     * @param listener - The function to call when a tick occurs.\n     * @returns The Entity instance for chaining.\n     */\n    onTick(listener) {\n        this.tickListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds an event listener for when a bar is complete.\n     * @param listener - The function to call when a bar is complete.\n     * @returns The Entity instance for chaining.\n     */\n    onBar(listener) {\n        this.barListeners.push(listener);\n        return this;\n    }\n    /**\n * Adds a post-processing function to the entity.\n * @param processor - The post-processing function to add.\n */\n    addPostProcessor(processor) {\n        this.postProcessors.push(processor);\n    }\n    /**\n     * Updates the ShaderEntity by calling the action function (if provided)\n     * and then updating the ShaderRenderer.\n     * @param timeStamp - The current timestamp in the animation.\n     */\n    update(timeStamp) {\n        if (this.action && this.shaderRenderer && this.props) {\n            // Calculate elapsed time relative to the scene's start time\n            const sceneStartTime = this.scene ? this.scene.startTimeinMs : 0;\n            const elapsed = timeStamp - sceneStartTime - (this.startTimeinMs || 0);\n            if (elapsed >= 0 && elapsed <= (this.durationInMs || Infinity)) {\n                this.action(timeStamp, this.shaderRenderer, this.props);\n                // Calculate shader time relative to the entity's start time (within the scene)\n                const shaderTime = Math.max(0, elapsed);\n                this.shaderRenderer.update(shaderTime / 1000);\n            }\n        }\n    }\n    /**\n     * Copies the entity's canvas to the target canvas.\n     * @param targetCanvas - The target canvas to copy to.\n     */\n    copyToCanvas(targetCanvas, sequence) {\n        const targetCtx = targetCanvas.getContext(\"2d\");\n        if (targetCtx) {\n            // Calculate the elapsed time for the entity\n            const elapsed = sequence.currentTime - (this.startTimeinMs || 0);\n            // Check if the entity should be rendered based on its lifetime\n            if (elapsed >= 0 && elapsed <= (this.durationInMs || Infinity)) {\n                targetCtx.drawImage(this.canvas, 0, 0);\n            }\n        }\n    }\n}\nexports.GLSLShaderEntity = GLSLShaderEntity;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/GLSLShaderEntity.js?");

/***/ }),

/***/ "./build/src/Engine/Helpers/AssetsHelper.js":
/*!**************************************************!*\
  !*** ./build/src/Engine/Helpers/AssetsHelper.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AssetsHelper = void 0;\nclass AssetsHelper {\n    static async loadImage(url) {\n        const filename = url.split(\"/\").pop();\n        if (this.textureCache.has(filename)) {\n            return this.textureCache.get(filename).src;\n        }\n        return new Promise((resolve, reject) => {\n            const img = new Image();\n            img.src = url;\n            img.onload = () => {\n                this.textureCache.set(filename, { src: img });\n                resolve(img);\n            };\n            img.onerror = (error) => {\n                reject(error);\n            };\n        });\n    }\n    static async loadImages(urls) {\n        const imagePromises = urls.map(url => this.loadImage(url));\n        return Promise.all(imagePromises);\n    }\n    static async loadAudio(audioFile, audioContext) {\n        const response = await fetch(audioFile);\n        const arrayBuffer = await response.arrayBuffer();\n        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);\n        return audioBuffer;\n    }\n}\nexports.AssetsHelper = AssetsHelper;\nAssetsHelper.textureCache = new Map();\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Helpers/AssetsHelper.js?");

/***/ }),

/***/ "./build/src/Engine/Helpers/DebugHelper.js":
/*!*************************************************!*\
  !*** ./build/src/Engine/Helpers/DebugHelper.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DebugHelper = void 0;\nclass DebugHelper {\n    /**\n     * Creates a new DebugHelper to display debug information on the screen.\n     * @param sequence - The Sequence instance to get timing and beat information from.\n     * @param startScene - The optional scene number to start the debug display from.\n     */\n    constructor(sequence, startScene = 0) {\n        this.sequence = sequence;\n        this.startScene = startScene;\n        this.divElement = document.createElement(\"div\");\n        this.divElement.style.position = \"fixed\";\n        this.divElement.style.top = \"10px\";\n        this.divElement.style.left = \"10px\";\n        this.divElement.style.backgroundColor = \"rgba(0, 0, 0, 0.8)\";\n        this.divElement.style.color = \"white\";\n        this.divElement.style.padding = \"5px\";\n        this.divElement.style.fontFamily = \"monospace\";\n        this.divElement.style.zIndex = \"1000\";\n        document.body.appendChild(this.divElement);\n        this.startTime = performance.now(); // Initialize startTime\n    }\n    /**\n     * Updates the debug display with the current time, scene, beat, and bar information.\n     */\n    update() {\n        var _a;\n        const elapsedTimeMs = performance.now() - this.startTime; // Calculate elapsed time\n        const elapsedTimeSec = (elapsedTimeMs / 1000).toFixed(2);\n        const currentSceneName = ((_a = this.sequence.currentScene) === null || _a === void 0 ? void 0 : _a.name) || \"None\";\n        const currentBeat = this.sequence.currentBeat;\n        const currentBar = this.sequence.currentBar;\n        const beatCounter = this.sequence.beatCounter;\n        if (this.sequence.currentSceneIndex >= this.startScene) {\n            this.divElement.textContent = `\r\n        Elapsed Time: ${elapsedTimeMs.toFixed(0)}ms (${elapsedTimeSec}s)\r\n        Scene: ${currentSceneName}\r\n        Beat: ${currentBeat} (${beatCounter})\r\n        Bar: ${currentBar}\r\n      `;\n        }\n        else {\n            this.divElement.textContent = \"\";\n        }\n    }\n    addControls() {\n        const container = document.createElement(\"div\");\n        container.style.position = \"fixed\";\n        container.style.bottom = \"10px\";\n        container.style.left = \"10px\";\n        container.style.zIndex\n            = \"1000\";\n        document.body.appendChild(container);\n        // Create the slider\n        const slider = document.createElement(\"input\");\n        slider.type = \"range\";\n        slider.min = \"0\";\n        slider.max = this.sequence.durationMs.toString();\n        slider.value = \"0\";\n        slider.style.width = \"400px\";\n        container.appendChild(slider);\n        // Create the play/pause button\n        const playPauseButton = document.createElement(\"button\");\n        playPauseButton.textContent = \"Pause\";\n        container.appendChild(playPauseButton);\n        // Event listeners for slider and button\n        slider.addEventListener(\"input\", () => {\n            const time = parseInt(slider.value, 10);\n            this.sequence.pause(); // Pause the regular animation loop\n            this.sequence.renderAtTime(time); // Render the scene at the specified time\n        });\n        playPauseButton.addEventListener(\"click\", () => {\n            if (this.sequence.isPlaying) {\n                this.sequence.pause();\n                playPauseButton.textContent = \"Play\";\n            }\n            else {\n                this.sequence.play();\n                playPauseButton.textContent = \"Pause\";\n            }\n        });\n    }\n}\nexports.DebugHelper = DebugHelper;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Helpers/DebugHelper.js?");

/***/ }),

/***/ "./build/src/Engine/Helpers/EntityBuilder.js":
/*!***************************************************!*\
  !*** ./build/src/Engine/Helpers/EntityBuilder.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EntityRenderer = exports.EntityBuilder = void 0;\nclass EntityBuilder {\n    constructor() {\n        this.entities = [];\n        this.currentTime = 0;\n    }\n    /**\n     * Adds an entity to the builder with a specified start time and duration.\n     * @param entity - The entity to add.\n     * @param startTime - The start time of the entity within the scene (in milliseconds).\n     * @param duration - The duration of the entity within the scene (in milliseconds).\n     * @returns The EntityBuilder instance for chaining.\n     */\n    addEntity(entity, startTime, duration) {\n        entity.startTimeinMs = startTime !== undefined ? startTime + this.currentTime : undefined;\n        entity.durationInMs = duration;\n        this.currentTime += duration || 0; // Increment currentTime only if duration is provided\n        this.entities.push(entity);\n        return this;\n    }\n    /**\n     * Sets the graph object to be used for adding entities by name.\n     * @param graph - An object containing entities accessible by name.\n     * @returns The EntityBuilder instance for chaining.\n     */\n    setGraph(graph) {\n        this.graph = graph;\n        return this;\n    }\n    /**\n     * Adds an entity from the graph by its name.\n     * @param entityName - The name of the entity in the graph.\n     * @param startTime - The start time of the entity within the scene (in milliseconds).\n     * @param duration - The duration of the entity within the scene (in milliseconds).\n     * @returns The EntityBuilder instance for chaining.\n     */\n    addEntityByName(entityName, startTime, duration) {\n        if (!this.graph) {\n            throw new Error(\"Cannot add entity by name: graph is not set.\");\n        }\n        const entity = this.graph[entityName];\n        if (!entity) {\n            throw new Error(`Entity with name \"${entityName}\" not found in the graph.`);\n        }\n        return this.addEntity(entity, startTime, duration);\n    }\n    /**\n     * Gets the array of entities with their timing configured.\n     * @returns The array of IEntity objects.\n     */\n    getEntities() {\n        return this.entities;\n    }\n}\nexports.EntityBuilder = EntityBuilder;\nclass EntityRenderer {\n    /**\n     * Creates a new EntityRenderer to render entities without a Sequence.\n     * @param canvas - The canvas element to render to.\n     */\n    constructor(canvas) {\n        this.entities = [];\n        this.canvas = canvas;\n        this.ctx = canvas.getContext(\"2d\");\n    }\n    /**\n     * Adds an entity to the renderer.\n     * @param entity - The entity to add.\n     */\n    addEntity(entity) {\n        this.entities.push(entity);\n        entity.canvas.width = this.canvas.width;\n        entity.canvas.height = this.canvas.height;\n    }\n    /**\n     * Starts the rendering loop.\n     */\n    start() {\n        const animate = (ts) => {\n            this.render(ts);\n            requestAnimationFrame(animate);\n        };\n        requestAnimationFrame(animate);\n    }\n    /**\n     * Renders the entities on the canvas.\n     * @param timeStamp - The current timestamp in the animation.\n     */\n    render(timeStamp) {\n        this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height); // Clear the canvas\n        this.entities.forEach(entity => {\n            entity.update(timeStamp);\n            this.copyToCanvas(entity.canvas);\n        });\n    }\n    copyToCanvas(result) {\n        this.ctx.drawImage(result, 0, 0);\n    }\n}\nexports.EntityRenderer = EntityRenderer;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Helpers/EntityBuilder.js?");

/***/ }),

/***/ "./build/src/Engine/Helpers/EntityTransitions.js":
/*!*******************************************************!*\
  !*** ./build/src/Engine/Helpers/EntityTransitions.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.createFadeOutTransition = exports.createFadeInTransition = void 0;\nconst createFadeInTransition = (duration = 1000) => (ctx, progress) => {\n    ctx.globalAlpha = Math.min(1, progress * duration / 1000);\n};\nexports.createFadeInTransition = createFadeInTransition;\nconst createFadeOutTransition = (duration = 1000) => (ctx, progress) => {\n    ctx.globalAlpha = Math.max(0, 1 - (progress * duration / 1000));\n};\nexports.createFadeOutTransition = createFadeOutTransition;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Helpers/EntityTransitions.js?");

/***/ }),

/***/ "./build/src/Engine/Helpers/PostProcessors.js":
/*!****************************************************!*\
  !*** ./build/src/Engine/Helpers/PostProcessors.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.createInvertPostProcessor = exports.createGrayscalePostProcessor = exports.createBlurPostProcessor = void 0;\nconst createBlurPostProcessor = (blurAmount = 5) => {\n    return (ctx) => {\n        ctx.filter = `blur(${blurAmount}px)`; // Apply blur filter\n        ctx.drawImage(ctx.canvas, 0, 0); // Redraw the canvas with the filter\n        ctx.filter = \"none\"; // Reset the filter\n    };\n};\nexports.createBlurPostProcessor = createBlurPostProcessor;\nconst createGrayscalePostProcessor = () => {\n    return (ctx) => {\n        const imageData = ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height);\n        const data = imageData.data;\n        for (let i = 0; i < data.length; i += 4) {\n            const avg = (data[i] + data[i + 1] + data[i + 2]) / 3;\n            data[i] = avg; // Red\n            data[i + 1] = avg; // Green\n            data[i + 2] = avg; // Blue\n        }\n        ctx.putImageData(imageData, 0, 0);\n    };\n};\nexports.createGrayscalePostProcessor = createGrayscalePostProcessor;\nconst createInvertPostProcessor = () => {\n    return (ctx) => {\n        const imageData = ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height);\n        const data = imageData.data;\n        for (let i = 0; i < data.length; i += 4) {\n            data[i] = 255 - data[i]; // Red\n            data[i + 1] = 255 - data[i + 1]; // Green\n            data[i + 2] = 255 - data[i + 2]; // Blue\n        }\n        ctx.putImageData(imageData, 0, 0);\n    };\n};\nexports.createInvertPostProcessor = createInvertPostProcessor;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Helpers/PostProcessors.js?");

/***/ }),

/***/ "./build/src/Engine/Helpers/SceneBuilder.js":
/*!**************************************************!*\
  !*** ./build/src/Engine/Helpers/SceneBuilder.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SceneBuilder = void 0;\nconst Scene_1 = __webpack_require__(/*! ../Scene */ \"./build/src/Engine/Scene.js\");\nclass SceneBuilder {\n    /**\n     * Creates a new SceneBuilder to help construct scenes with automatic timing.\n     * @param totalDuration - The total duration of the animation sequence in milliseconds.\n     */\n    constructor(totalDuration) {\n        this.scenes = [];\n        this.currentTime = 0;\n        this.totalDuration = totalDuration;\n    }\n    /**\n     * Adds a scene to the builder with a specified name and duration.\n     * @param name - The name of the scene.\n     * @param duration - The duration of the scene in milliseconds.\n     * @returns The SceneBuilder instance for chaining.\n     */\n    addScene(name, duration) {\n        const startTime = this.currentTime;\n        this.currentTime += duration;\n        // If the current time exceeds the total duration, adjust the last scene's duration\n        if (this.currentTime > this.totalDuration) {\n            const lastScene = this.scenes[this.scenes.length - 1];\n            if (lastScene) {\n                lastScene.durationInMs = this.totalDuration - lastScene.startTimeinMs;\n            }\n            duration = this.totalDuration - startTime; // Adjust the current scene's duration as well\n        }\n        const scene = new Scene_1.Scene(name, startTime, duration);\n        this.scenes.push(scene);\n        return this; // For chaining\n    }\n    /**\n     * Gets the array of scenes with their timing configured.\n     * @returns The array of Scene objects.\n     */\n    getScenes() {\n        return this.scenes;\n    }\n    /**\n     * Gets the total duration of all scenes added to the builder.\n     * @returns The total duration in milliseconds.\n     */\n    get totalScenesDuration() {\n        return this.scenes.reduce((total, scene) => total + scene.durationInMs, 0);\n    }\n    /**\n     * Adds a scene to the builder with a specified name and a duration that extends to the end of the total duration.\n     * @param name - The name of the scene.\n     * @returns The SceneBuilder instance for chaining.\n     */\n    durationUntilEndInMs(name) {\n        const startTime = this.currentTime;\n        const duration = this.totalDuration - startTime;\n        const scene = new Scene_1.Scene(name, startTime, duration);\n        this.scenes.push(scene);\n        return this;\n    }\n}\nexports.SceneBuilder = SceneBuilder;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Helpers/SceneBuilder.js?");

/***/ }),

/***/ "./build/src/Engine/Helpers/SequenceHelper.js":
/*!****************************************************!*\
  !*** ./build/src/Engine/Helpers/SequenceHelper.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SequenceHelper = void 0;\nclass SequenceHelper {\n    /**\n     * Calculates the duration in milliseconds for a given number of beats.\n     * @param bpm - The beats per minute.\n     * @param numBeats - The number of beats.\n     * @returns The duration in milliseconds.\n     */\n    static getDurationForBeats(bpm, numBeats) {\n        const millisecondsPerBeat = 60000 / bpm;\n        return numBeats * millisecondsPerBeat;\n    }\n    /**\n     * Calculates the duration in milliseconds for a given number of bars.\n     * @param bpm - The beats per minute.\n     * @param beatsPerBar - The number of beats per bar.\n     * @param numBars - The number of bars.\n     * @returns The duration in milliseconds.\n     */\n    static getDurationForBars(bpm, beatsPerBar, numBars) {\n        const millisecondsPerBar = (60000 / bpm) * beatsPerBar;\n        return numBars * millisecondsPerBar;\n    }\n    /**\n     * Calculates the duration in milliseconds for a given number of ticks.\n     * @param bpm - The beats per minute.\n     * @param ticksPerBeat - The number of ticks per beat.\n     * @param numTicks - The number of ticks.\n     * @returns The duration in milliseconds.\n     */\n    static getDurationForTicks(bpm, ticksPerBeat, numTicks) {\n        const millisecondsPerTick = 60000 / (bpm * ticksPerBeat);\n        return numTicks * millisecondsPerTick;\n    }\n}\nexports.SequenceHelper = SequenceHelper;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Helpers/SequenceHelper.js?");

/***/ }),

/***/ "./build/src/Engine/Scene.js":
/*!***********************************!*\
  !*** ./build/src/Engine/Scene.js ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Scene = void 0;\nconst Entity_1 = __webpack_require__(/*! ./Entity */ \"./build/src/Engine/Entity.js\");\nclass Scene {\n    /**\n     * Creates a new Scene.\n     * @param name - The name or identifier for the scene.\n     * @param startTimeinMs - The start time of the scene in milliseconds.\n     * @param durationInMs - The duration of the scene in milliseconds.\n     */\n    constructor(name, startTimeinMs, durationInMs, width, height) {\n        this.name = name;\n        this.startTimeinMs = startTimeinMs;\n        this.durationInMs = durationInMs;\n        this.width = width;\n        this.height = height;\n        this.entities = [];\n        this.transitionOutListeners = [];\n        this.transitionInListeners = [];\n    }\n    /**\n     * Adds an entity to the scene.\n     * @param entity - The entity to add.\n     */\n    addEntity(entity) {\n        // If the entity's canvas dimensions are not set, use the scene's dimensions\n        if (!entity.w && !entity.h) {\n            entity.canvas.width = this.width || 800;\n            entity.canvas.height = this.height || 450;\n        }\n        entity.bindToScene(this);\n        this.entities.push(entity);\n    }\n    /**\n     * Adds multiple entities to the scene.\n     * @param entities - An array of entities to add.\n     * @returns The Scene instance for chaining.\n     */\n    addEntities(...entities) {\n        entities.forEach(entity => this.addEntity(entity));\n        return this;\n    }\n    /**\n     * Gets an entity from the scene by its key.\n     * @param key - The key of the entity to retrieve.\n     * @returns The entity if found, otherwise undefined.\n     */\n    getEntity(key) {\n        return this.entities.find(entity => entity.name === key);\n    }\n    addPostProcessorToEntities(processor) {\n        this.entities.forEach(entity => {\n            if (entity instanceof Entity_1.Entity) { // Check if the entity is an instance of the Entity class\n                entity.addPostProcessor(processor);\n            }\n        });\n    }\n    /**\n      * Adds a transition-in effect to the scene.\n      * @param sequence - The Sequence instance associated with the scene.\n      * @param startTime - The time (in milliseconds) within the scene when the transition should start.\n      * @param duration - The duration of the transition in milliseconds.\n      * @param listener - The transition function to apply.\n      */\n    transitionIn(sequence, startTime, duration, listener) {\n        this.transitionInListeners.push(listener);\n        sequence.addSceneTransitionIn(this, startTime, duration, (ctx, scene, progress) => {\n            this.transitionInListeners.forEach(listener => listener(ctx, scene, progress));\n        });\n    }\n    /**\n    * Adds a transition-out effect to the scene.\n    * @param sequence - The Sequence instance associated with the scene.\n    * @param startTime - The time (in milliseconds) within the scene when the transition should start.\n    * @param duration - The duration of the transition in milliseconds.\n    * @param listener - The transition function to apply.\n    */\n    transitionOut(sequence, startTime, duration, listener) {\n        this.transitionOutListeners.push(listener);\n        sequence.addSceneTransitionOut(this, startTime, duration, (ctx, scene, progress) => {\n            this.transitionOutListeners.forEach(listener => listener(ctx, scene, progress));\n        });\n    }\n}\nexports.Scene = Scene;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Scene.js?");

/***/ }),

/***/ "./build/src/Engine/Sequence.js":
/*!**************************************!*\
  !*** ./build/src/Engine/Sequence.js ***!
  \**************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Sequence = void 0;\nclass Sequence {\n    /**\n  * Adds an event listener for when the frame rate drops below a threshold.\n  * @param listener - The function to call when the frame rate is low.\n  */\n    onLowFrameRate(listener) {\n        this.lowFrameRateListeners.push(listener);\n    }\n    /**\n* Sets the function to be used for resetting the rendering context when switching scenes.\n* @param resetFunction - The function to call to reset the context.\n*/\n    setContextResetFunction(resetFunction) {\n        this.resetContext = resetFunction;\n    }\n    /**\n     * Adds a transition-out listener for a specific scene.\n     * @param scene - The scene to add the listener to.\n     * @param startTime - The time (in milliseconds) relative to the end of the scene when the transition should start.\n     * @param listener - The transition function to apply.\n     */\n    addSceneTransitionOut(scene, startTime, duration, listener) {\n        this.sceneTransitionOutListeners.push({ scene, startTime, duration, listener });\n    }\n    /**\n     * Adds a transition-in listener for a specific scene.\n     * @param scene - The scene to add the listener to.\n     * @param startTime - The time (in milliseconds) within the scene when the transition should start.\n     * @param listener - The transition function to apply.\n     */\n    addSceneTransitionIn(scene, startTime, duration, listener) {\n        this.sceneTransitionInListeners.push({ scene, startTime, duration, listener });\n    }\n    /**\n     * Adds a post-processing function to the sequence.\n     * @param processor - The post-processing function to add.\n     */\n    addPostProcessor(processor) {\n        this.postProcessors.push(processor);\n    }\n    /**\n     * Gets the remaining time in the current scene.\n     * @param timeStamp - The current timestamp in the animation.\n     * @returns The remaining time in milliseconds.\n     */\n    getSceneRemainingTime(timeStamp) {\n        if (!this.currentScene) {\n            return 0;\n        }\n        const elapsedTime = timeStamp - this.currentScene.startTimeinMs;\n        return Math.max(0, this.currentScene.durationInMs - elapsedTime);\n    }\n    /**\n   * Creates a new Sequence.\n   * @param target - The canvas element to render the animation on.\n   * @param bpm - The beats per minute for the animation.\n   * @param ticksPerBeat - The number of ticks per beat.\n   * @param beatsPerBar - The number of beats per bar.\n   * @param audioLoader - The IAudioLoader instance to load the audio.\n   * @param scenes - An optional array of scenes to include in the sequence.\n   * @param maxFps - The maximum frames per second (not yet implemented).\n   */\n    constructor(target, bpm = 120, ticksPerBeat = 4, beatsPerBar = 4, audioLoader, scenes, maxFps = 60 // not implemened at the moment\n    ) {\n        this.target = target;\n        this.maxFps = maxFps;\n        this.durationMs = 0;\n        this.scenes = [];\n        this.currentSceneIndex = 0;\n        this.isPlaying = false;\n        this.startTime = 0;\n        this.currentTime = 0;\n        this.bpm = 0;\n        this.ticksPerBeat = 0;\n        this.lastBeatTime = 0;\n        this.currentTick = 0;\n        this.currentBar = 0;\n        this.tickCounter = 0;\n        this.beatCounter = 0;\n        this.beatsPerBar = 0;\n        this.currentBeat = 0;\n        this.previousBeat = 0; // Store the previous beat value\n        this.previousTick = 0; // Store the previous tick value\n        this.previousBar = 0; // Store the previous bar value\n        this.beatListeners = [];\n        this.tickListeners = [];\n        this.barListeners = [];\n        this.frameListeners = [];\n        this.postProcessors = [];\n        this.lowFrameRateListeners = [];\n        this.sceneTransitionInListeners = [];\n        this.sceneTransitionOutListeners = [];\n        this.resetContext = (ctx) => {\n            ctx.globalAlpha = 1; // Default reset function\n        };\n        this.targetCtx = target.getContext(\"2d\");\n        this.bpm = bpm;\n        this.ticksPerBeat = ticksPerBeat;\n        this.beatsPerBar = beatsPerBar;\n        this.audioContext = new AudioContext();\n        this.analyser = this.audioContext.createAnalyser();\n        this.audioLoader = audioLoader;\n    }\n    /**\n  * Asynchronously initializes the Sequence by loading the audio.\n  * @returns A Promise that resolves to the Sequence instance.\n  */\n    async initialize() {\n        await this.audioLoader.loadAudio(this.audioContext)\n            .then(audioBuffer => {\n            this.audioBuffer = audioBuffer;\n        })\n            .catch(error => console.error(\"Error loading audio:\", error));\n        return this;\n    }\n    /**\n     * Adds an event listener for each frame.\n     * @param listener - The function to call on each frame.\n     */\n    onFrame(listener) {\n        this.frameListeners.push(listener);\n    }\n    /**\n     * Adds an event listener for when a bar is complete.\n     * @param listener - The function to call when a bar is complete.\n     */\n    onBar(listener) {\n        this.barListeners.push(listener);\n    }\n    /**\n     * Adds an event listener for when a beat occurs.\n     * @param listener - The function to call when a beat occurs.\n     */\n    onBeat(listener) {\n        this.beatListeners.push(listener);\n    }\n    /**\n     * Adds an event listener for when a tick occurs.\n     * @param listener - The function to call when a tick occurs.\n     */\n    onTick(listener) {\n        this.tickListeners.push(listener);\n    }\n    /**\n     * Adds a scene to the sequence.\n     * @param scene - The scene to add.\n     */\n    addScene(scene) {\n        if (!scene.width && scene.height) {\n            scene.width = this.target.width;\n            scene.height = this.target.height;\n        }\n        this.scenes.push(scene);\n        this.recalculateDuration();\n    }\n    /**\n     * Adds multiple scenes to the sequence.\n     * @param scenes - The scenes to add.\n     * @returns The Sequence instance for chaining.\n     */\n    addScenes(...scenes) {\n        this.scenes.push(...scenes);\n        this.recalculateDuration();\n        return this;\n    }\n    /**\n    * Adds multiple scenes to the sequence.\n    * @param scenes - The scenes to add.\n    * @returns The Sequence instance for chaining.\n    */\n    addSceneArray(scenes) {\n        this.scenes.push(...scenes);\n        this.recalculateDuration();\n        return this;\n    }\n    /**\n     * Removes a scene from the sequence.\n     * @param scene - The scene to remove.\n     */\n    removeScene(scene) {\n        this.scenes = this.scenes.filter((s) => s !== scene);\n        this.recalculateDuration();\n    }\n    /**\n     * Recalculates the total duration of the sequence.\n     */\n    recalculateDuration() {\n        this.durationMs = 0;\n        if (this.scenes.length > 0) {\n            this.durationMs = Math.max(...this.scenes.map((scene) => {\n                return scene.startTimeinMs + scene.durationInMs;\n            }));\n        }\n    }\n    /**\n     * Render a specific time\n     *\n     * @param {number} time\n     * @memberof Sequence\n     */\n    renderAtTime(time) {\n        var _a;\n        this.currentTime = time; // Update the currentTime\n        // Find the active scene for the given time\n        const currentSceneIndex = this.scenes.findIndex(scene => time >= scene.startTimeinMs && time < scene.startTimeinMs + scene.durationInMs);\n        if (currentSceneIndex !== -1) {\n            this.currentSceneIndex = currentSceneIndex;\n            const elapsedTime = time - this.currentScene.startTimeinMs;\n            // Update and draw entities\n            (_a = this.targetCtx) === null || _a === void 0 ? void 0 : _a.clearRect(0, 0, this.target.width, this.target.height);\n            this.currentScene.entities.forEach(entity => {\n                entity.update(time);\n                if (this.target) {\n                    entity.copyToCanvas(this.target, this);\n                }\n            });\n            // Apply post-processing\n            if (this.targetCtx) {\n                this.postProcessors.forEach(processor => processor(this.targetCtx, this));\n            }\n            this.triggerEventsForTime(time);\n        }\n    }\n    /**\n * Triggers beat, tick, and bar listeners for a given time.\n * @param time - The time in milliseconds.\n */\n    triggerEventsForTime(time) {\n        const beatIntervalMs = 60000 / this.bpm;\n        const tickIntervalMs = beatIntervalMs / this.ticksPerBeat;\n        // Calculate beat, tick, and bar values for the given time\n        const beat = Math.floor(time / beatIntervalMs) + 1;\n        const tick = Math.floor((time % beatIntervalMs) / tickIntervalMs);\n        const bar = Math.floor(beat / this.beatsPerBar) + 1;\n        // Trigger listeners if the values have changed\n        if (beat !== this.currentBeat) {\n            this.currentBeat = beat;\n            this.beatListeners.forEach(listener => listener(this.currentSceneIndex, time, this.beatCounter));\n            this.beatCounter++;\n        }\n        if (tick !== this.currentTick) {\n            this.currentTick = tick;\n            this.tickListeners.forEach(listener => listener(this.currentSceneIndex, time, this.tickCounter));\n            this.tickCounter++;\n        }\n        if (bar !== this.currentBar) {\n            this.currentBar = bar;\n            this.barListeners.forEach(listener => listener(this.currentBar));\n        }\n        // Trigger frame listeners\n        this.frameListeners.forEach(listener => listener(this.currentSceneIndex, time));\n    }\n    /**\n       * Starts the animation sequence.\n       * @param maxFps - The maximum frames per second.\n       */\n    play(maxFps) {\n        this.isPlaying = true;\n        this.currentSceneIndex = 0;\n        this.lastBeatTime = 0;\n        this.currentTick = 0;\n        this.currentBeat = 0;\n        this.startTime = performance.now();\n        if (maxFps) {\n            this.maxFps = maxFps;\n        }\n        console.log(`Rendering at ${this.maxFps}`);\n        let then = performance.now();\n        const interval = 1000 / this.maxFps;\n        let frameCount = 0;\n        let lastFpsUpdateTime = 0;\n        const animate = (ts) => {\n            const now = performance.now();\n            const delta = now - then;\n            if (delta > interval) {\n                then = now - (delta % interval);\n                const adjustedTimeStamp = ts - this.startTime;\n                this.playCurrentScene(adjustedTimeStamp);\n                frameCount++;\n                if (now - lastFpsUpdateTime >= 1000) {\n                    const fps = frameCount / ((now - lastFpsUpdateTime) / 1000);\n                    frameCount = 0;\n                    lastFpsUpdateTime = now;\n                    if (fps < this.maxFps * 0.8) {\n                        this.lowFrameRateListeners.forEach(listener => listener(fps));\n                    }\n                }\n            }\n            if (this.isPlaying) {\n                this.requestAnimationFrameID = requestAnimationFrame(animate);\n            }\n        };\n        // Start audio playback\n        if (this.audioBuffer) {\n            this.audioSource = this.audioContext.createBufferSource();\n            this.audioSource.buffer = this.audioBuffer;\n            this.audioSource.connect(this.analyser);\n            this.analyser.connect(this.audioContext.destination);\n            this.fftData = new Uint8Array(this.analyser.frequencyBinCount);\n            this.audioSource.start();\n        }\n        this.requestAnimationFrameID = requestAnimationFrame(animate);\n    }\n    /**\n     * Pauses\n   the animation sequence.\n     */\n    pause() {\n        this.isPlaying = false;\n        cancelAnimationFrame(this.requestAnimationFrameID);\n    }\n    /**\n     * Stops the animation sequence.\n     */\n    stop() {\n        this.isPlaying = false;\n        this.currentSceneIndex = 0;\n        cancelAnimationFrame(this.requestAnimationFrameID);\n    }\n    /**\n     * Gets the current scene being played.\n     * @returns The current Scene or undefined if no scene is active.\n     */\n    get currentScene() {\n        return this.scenes[this.currentSceneIndex];\n    }\n    /**\n  * Animates the current scene and handles scene transitions,\n  * audio analysis, and beat/tick events.\n  * @param timeStamp - The adjusted timestamp for the current frame.\n  */\n    playCurrentScene(timeStamp) {\n        var _a;\n        if (!this.isPlaying) {\n            return;\n        }\n        this.currentTime = timeStamp; // Update currentTime\n        // Determine the current scene based on timeStamp\n        let currentSceneIndex = this.scenes.findIndex(scene => timeStamp >= scene.startTimeinMs && timeStamp < scene.startTimeinMs + scene.durationInMs);\n        // If no current scene is found, check for upcoming scenes\n        if (currentSceneIndex === -1) {\n            currentSceneIndex = this.scenes.findIndex(scene => timeStamp < scene.startTimeinMs);\n            if (currentSceneIndex === -1) { // No upcoming scene, end animation\n                this.isPlaying = false;\n                return;\n            }\n            else { // Wait for the upcoming scene\n                return;\n            }\n        }\n        // If the scene has changed, update currentSceneIndex and play the new scene\n        if (this.currentSceneIndex !== currentSceneIndex) {\n            this.currentSceneIndex = currentSceneIndex;\n            // Reset the rendering context\n            this.resetContext(this.targetCtx);\n            // Set scene dimensions if not already set\n            if (!this.currentScene.width) {\n                this.currentScene.width = this.target.width;\n            }\n            if (!this.currentScene.height) {\n                this.currentScene.height = this.target.height;\n            }\n        }\n        // FFT analysis (if analyser is available)\n        if (this.analyser) {\n            this.analyser.getByteFrequencyData(this.fftData);\n        }\n        // Clear the target canvas and update/draw entities\n        (_a = this.targetCtx) === null || _a === void 0 ? void 0 : _a.clearRect(0, 0, this.target.width, this.target.height);\n        this.currentScene.entities.forEach(entity => {\n            var _a, _b;\n            // Update the conductor's time and trigger events\n            (_a = this.conductor) === null || _a === void 0 ? void 0 : _a.updateTime(timeStamp);\n            (_b = this.conductor) === null || _b === void 0 ? void 0 : _b.triggerEvents(this);\n            entity.update(timeStamp);\n            if (this.target) {\n                entity.copyToCanvas(this.target, this);\n            }\n            // Trigger entity events only when the values change\n            if (this.currentBeat !== this.previousBeat) {\n                entity.beatListeners.forEach(listener => listener(timeStamp, this.beatCounter, entity.props));\n                this.previousBeat = this.currentBeat;\n            }\n            if (this.currentTick !== this.previousTick) {\n                entity.tickListeners.forEach(listener => listener(timeStamp, this.tickCounter, entity.props));\n                this.previousTick = this.currentTick;\n            }\n            if (this.currentBar !== this.previousBar) {\n                entity.barListeners.forEach(listener => listener(timeStamp, this.currentBar, entity.props));\n                this.previousBar = this.currentBar;\n            }\n        });\n        // Apply post-processing effects\n        if (this.targetCtx) {\n            this.postProcessors.forEach(processor => processor(this.targetCtx, this));\n        }\n        this.sceneTransitionInListeners.forEach(({ scene, startTime, duration, listener }) => {\n            if (scene === this.currentScene) {\n                const sceneElapsedTime = this.currentTime - scene.startTimeinMs;\n                if (sceneElapsedTime >= startTime && sceneElapsedTime <= startTime + duration) {\n                    const transitionProgress = (sceneElapsedTime - startTime) / duration; // Calculate progress based on duration\n                    listener(this.targetCtx, scene, transitionProgress);\n                }\n            }\n        });\n        this.sceneTransitionOutListeners.forEach(({ scene, startTime, duration, listener }) => {\n            if (scene === this.currentScene) {\n                const sceneElapsedTime = this.currentTime - scene.startTimeinMs;\n                if (sceneElapsedTime >= startTime && sceneElapsedTime <= startTime + duration) {\n                    const transitionProgress = (sceneElapsedTime - startTime) / duration; // Calculate progress based on duration\n                    listener(this.targetCtx, scene, transitionProgress);\n                }\n            }\n        });\n        this.handleBeatAndTickEvents(timeStamp); // Handle beat and tick events\n        // Trigger frame listeners\n        this.frameListeners.forEach(listener => listener(this.currentSceneIndex, timeStamp));\n    }\n    /**\n     * Handles beat and tick events based on the current timestamp.\n     * @param timeStamp - The adjusted timestamp for the current frame.\n     */\n    handleBeatAndTickEvents(timeStamp) {\n        const beatIntervalMs = 60000 / this.bpm;\n        const tickIntervalMs = beatIntervalMs / this.ticksPerBeat;\n        if (timeStamp - this.lastBeatTime >= beatIntervalMs) {\n            this.lastBeatTime = timeStamp;\n            this.beatListeners.forEach(listener => listener(this.currentSceneIndex, timeStamp, this.beatCounter));\n            this.currentTick = 0;\n            this.currentBeat++;\n            this.beatCounter++;\n            if (this.currentBeat > this.beatsPerBar) {\n                this.currentBar++;\n                this.currentBeat = 1;\n                this.barListeners.forEach(listener => listener(this.currentBar));\n            }\n        }\n        if (timeStamp - this.lastBeatTime >= this.currentTick * tickIntervalMs) {\n            this.tickListeners.forEach(listener => listener(this.currentSceneIndex, timeStamp, this.tickCounter));\n            this.currentTick++;\n            this.tickCounter++;\n        }\n    }\n}\nexports.Sequence = Sequence;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/Sequence.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGL/GLSLShaderRenderer.js":
/*!**********************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGL/GLSLShaderRenderer.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GLSLShaderRenderer = exports.RenderTarget = void 0;\nclass RenderTarget {\n    constructor(gl, textures, customUniforms) {\n        this.textures = new Array();\n        this.locations = new Map();\n        this.framebuffer = gl.createFramebuffer();\n        this.renderbuffer = gl.createRenderbuffer();\n        this.texture = gl.createTexture();\n        this.textures = textures;\n        this.uniforms = customUniforms;\n    }\n}\nexports.RenderTarget = RenderTarget;\nclass GLSLShaderRenderer {\n    /**\n     * Create a Shader\n     *\n     * @param {WebGLProgram} program\n     * @param {number} type\n     * @param {string} source\n     * @memberof DR\n     */\n    createShader(program, type, source) {\n        let gl = this.gl;\n        let shader = gl.createShader(type);\n        gl.shaderSource(shader, source);\n        gl.compileShader(shader);\n        gl.attachShader(program, shader);\n        if (!gl.getShaderParameter(shader, 35713)) { // this.gl.COMPILE_STATUS\n            // gl.getShaderInfoLog(shader).trim().split(\"\\n\").forEach((l: string) =>\n            //         console.error(\"[shader] \" + l))\n            throw new Error(\"Error while compiling vertex/fragment\" + source);\n        }\n        ;\n    }\n    /**\n     * Create and a WebGLProgram\n     *\n     * @param {string} name\n     * @returns {WebGLProgram}\n     * @memberof DR\n     */\n    addProgram(name) {\n        let p = this.gl.createProgram();\n        this.programs.set(name, { program: p, state: true });\n        return p;\n    }\n    /**\n     *  Create a new WEBGLTexture\n     *\n     * @param {*} data  image or UInt8Array\n     * @returns WebGLTexture\n     * @memberof DR\n     */\n    createTexture(data, d) {\n        let gl = this.gl;\n        let texture = gl.createTexture();\n        gl.activeTexture(33985 + d);\n        gl.bindTexture(3553, texture);\n        if (data instanceof Image) {\n            gl.texImage2D(3553, 0, 6408, 6408, 5121, data);\n        }\n        else {\n            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, 1, 1, 0, gl.RGBA, gl.UNSIGNED_BYTE, data);\n        }\n        gl.generateMipmap(3553);\n        return texture;\n    }\n    /**\n     * Create a texture cube map\n     *\n     * @param {Array<any>} sources\n     * @param {number} d\n     * @returns {WebGLTexture}\n     * @memberof DR\n     */\n    createTextureCube(sources, d) {\n        let gl = this.gl;\n        let texture = gl.createTexture();\n        gl.activeTexture(33985 + d);\n        gl.bindTexture(gl.TEXTURE_CUBE_MAP, texture);\n        const fetchAll = (src, key) => {\n            return new Promise(async (resolve, reject) => {\n                const response = await fetch(src);\n                const blob = await response.blob();\n                let image = new Image();\n                image.dataset.key = key;\n                image.onerror = reject;\n                image.onload = () => {\n                    resolve(image);\n                };\n                image.src = src;\n            });\n        };\n        Promise.all(sources.map(i => {\n            return fetchAll(i.d, i.t);\n        })).then(data => {\n            data.forEach(image => {\n                const target = image.dataset.key;\n                const level = 0;\n                const internalFormat = gl.RGBA;\n                const width = 512;\n                const height = 512;\n                const format = gl.RGBA;\n                const type = gl.UNSIGNED_BYTE;\n                gl.texImage2D(target, level, internalFormat, width, height, 0, format, type, null);\n                gl.bindTexture(gl.TEXTURE_CUBE_MAP, texture);\n                gl.texImage2D(target, level, internalFormat, format, type, image);\n                gl.generateMipmap(gl.TEXTURE_CUBE_MAP);\n            });\n        });\n        gl.generateMipmap(gl.TEXTURE_CUBE_MAP);\n        gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MIN_FILTER, gl.LINEAR_MIPMAP_LINEAR);\n        return texture;\n    }\n    /**\n     * add assets ( textures )\n     *\n     * @param {*} assets\n     * @param {()=>void} cb\n     * @returns {this}\n     * @memberof DR\n     */\n    addAssets(assets, cb) {\n        const cache = (k, v, f) => {\n            this.textureCache.set(k, { src: v, fn: f });\n        };\n        const p = (key, texture, unit) => {\n            return new Promise((resolve) => {\n                if (!texture.src) {\n                    cache(key, this.createTexture(new Uint8Array(1024), unit), texture.fn);\n                    resolve(key);\n                }\n                else {\n                    if (!Array.isArray(texture.src)) {\n                        const i = new Image();\n                        i.onload = (e) => {\n                            cache(key, this.createTexture(i, unit), null);\n                            resolve(key);\n                        };\n                        i.src = texture.src;\n                    }\n                    else {\n                        cache(key, this.createTextureCube(texture.src, unit), texture.fn);\n                        resolve(key);\n                    }\n                }\n            });\n        };\n        Promise.all(Object.keys(assets).map((key, index) => {\n            return p(key, assets[key], index);\n        })).then((result) => {\n            cb(result);\n        }).catch((err) => {\n            console.error(err);\n        });\n        return this;\n    }\n    /**\n     * add a new buffer / shader program\n     *\n     * @param {string} name\n     * @param {string} vertex\n     * @param {string} fragment\n     * @param {Array<string>} [textures]\n     * @param {*} [customUniforms]\n     * @returns {this}\n     * @memberof DR\n     */\n    addBuffer(name, vertex, fragment, textures, customUniforms) {\n        let gl = this.gl;\n        let tA = this.createTarget(this.canvas.width, this.canvas.height, textures ? textures : [], customUniforms ? customUniforms : {});\n        let tB = this.createTarget(this.canvas.width, this.canvas.height, textures ? textures : [], customUniforms ? customUniforms : {});\n        this.targets.set(name, tA);\n        this.targets.set(`_${name}`, tB);\n        let program = this.addProgram(name);\n        this.createShader(program, 35633, this.header + vertex);\n        this.createShader(program, 35632, this.header + fragment);\n        gl.linkProgram(program);\n        gl.validateProgram(program);\n        if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {\n            var info = gl.getProgramInfoLog(program);\n            throw `Could not compile ${name} program. \\n\\n${info}`;\n        }\n        gl.useProgram(program);\n        if (textures) {\n            textures.forEach((tk) => {\n                gl.bindTexture(3553, this.textureCache.get(tk).src);\n            });\n        }\n        this.vertexPosition = gl.getAttribLocation(program, \"pos\");\n        gl.enableVertexAttribArray(this.vertexPosition);\n        for (let i = 0; i < gl.getProgramParameter(program, gl.ACTIVE_UNIFORMS); ++i) {\n            const u = gl.getActiveUniform(program, i);\n            tA.locations.set(u.name, gl.getUniformLocation(program, u.name));\n        }\n        return this;\n    }\n    /**\n     * Set program state ( enable / or disable)\n     *\n     * @param {string} key\n     * @param {boolean} state\n     * @memberof DR\n     */\n    setProgramState(key, state) {\n        this.programs.get(key).state = state;\n    }\n    /**\n     * Render\n     *\n     * @param {number} time\n     * @memberof DR\n     */\n    update(time) {\n        let gl = this.gl;\n        let main = this.mainProgram;\n        let tc = 0;\n        this.programs.forEach((l, key) => {\n            if (!l.state)\n                return; // do not render \n            const current = l.program;\n            let fT = this.targets.get(key);\n            let bT = this.targets.get(`_${key}`);\n            gl.useProgram(current);\n            // resolution, time\n            gl.uniform2f(fT.locations.get(\"resolution\"), this.canvas.width, this.canvas.height);\n            gl.uniform1f(fT.locations.get(\"time\"), time);\n            gl.uniform1f(fT.locations.get(\"deltaTime\"), this.frameCount);\n            gl.uniform1f(fT.locations.get(\"frame\"), this.frameCount);\n            let customUniforms = fT.uniforms;\n            customUniforms && Object.keys(customUniforms).forEach((v) => {\n                customUniforms[v](fT.locations.get(v), gl, current, time);\n            });\n            let bl = gl.getUniformLocation(current, key); // todo: get this from cache?\n            gl.uniform1i(bl, 0);\n            gl.activeTexture(gl.TEXTURE0);\n            gl.bindTexture(gl.TEXTURE_2D, bT.texture);\n            fT.textures.forEach((tk, index) => {\n                let ct = this.textureCache.get(tk);\n                gl.activeTexture(33985 + index);\n                gl.bindTexture(gl.TEXTURE_2D, ct.src);\n                if (ct.fn)\n                    ct.fn(!current, gl, ct.src);\n                let loc = gl.getUniformLocation(!current, tk); // todo: get this from cache?  \n                gl.uniform1i(loc, index + 1);\n                tc++;\n            });\n            gl.bindBuffer(34962, this.surfaceBuffer);\n            gl.vertexAttribPointer(0, 2, 5126, false, 0, 0);\n            gl.bindBuffer(34962, this.buffer);\n            gl.vertexAttribPointer(0, 2, 5126, false, 0, 0);\n            gl.bindFramebuffer(36160, fT.framebuffer);\n            gl.clear(16384 | 256);\n            gl.drawArrays(4, 0, 6);\n            bT = fT;\n            fT = bT;\n        });\n        gl.useProgram(main);\n        gl.uniform2f(this.mainUniforms.get(\"resolution\"), this.canvas.width, this.canvas.height);\n        gl.uniform1f(this.mainUniforms.get(\"time\"), time);\n        // todo:  set up a cache for custom uniforms\n        Object.keys(this.cU).forEach((v) => {\n            this.cU[v](gl.getUniformLocation(main, v), gl, main, time); // todo: use cached locations\n        });\n        gl.bindBuffer(34962, this.buffer);\n        gl.vertexAttribPointer(0, 2, 5126, false, 0, 0);\n        this.targets.forEach((target, key) => {\n            gl.uniform1i(gl.getUniformLocation(main, key), tc); // todo: use cached locations\n            gl.activeTexture(33984 + tc);\n            gl.bindTexture(3553, target.texture);\n            tc++;\n        });\n        gl.bindFramebuffer(36160, null);\n        gl.clear(16384 | 256);\n        gl.drawArrays(4, 0, 6);\n        this.frameCount++;\n        this.deltaTime = -(this.deltaTime - time);\n    }\n    /**\n     * Create render target\n     *\n     * @param {number} width\n     * @param {number} height\n     * @param {Array<string>} textures\n     * @returns {*}\n     * @memberof DR\n     */\n    createTarget(width, height, textures, customUniforms) {\n        let gl = this.gl;\n        let target = new RenderTarget(gl, textures, customUniforms);\n        gl.bindTexture(3553, target.texture);\n        gl.texImage2D(3553, 0, 6408, width, height, 0, 6408, 5121, null);\n        gl.texParameteri(3553, 10242, 33071);\n        gl.texParameteri(3553, 10243, 33071);\n        gl.texParameteri(3553, 10240, 9728);\n        gl.texParameteri(3553, 10241, 9728);\n        gl.bindFramebuffer(36160, target.framebuffer);\n        gl.framebufferTexture2D(36160, 36064, 3553, target.texture, 0);\n        gl.bindRenderbuffer(36161, target.renderbuffer);\n        gl.renderbufferStorage(36161, 33189, width, height);\n        gl.framebufferRenderbuffer(36160, 36096, 36161, target.renderbuffer);\n        gl.bindTexture(3553, null);\n        gl.bindRenderbuffer(36161, null);\n        gl.bindFramebuffer(36160, null);\n        return target;\n    }\n    /**\n     * Render loop\n     *\n     * @param {number} t\n     * @param {number} fps\n     * @returns {this}\n     * @memberof DR\n     */\n    run(t, fps) {\n        let pt = performance.now();\n        let interval = 1000 / fps;\n        let dt = 0;\n        const a = (t) => {\n            requestAnimationFrame(a);\n            dt = t - pt;\n            if (dt > interval) {\n                pt = t - (dt % interval);\n                this.update(pt / 1000);\n            }\n        };\n        a(t | 0);\n        return this;\n    }\n    constructor(canvas, v, f, cU = {}) {\n        this.canvas = canvas;\n        this.cU = cU;\n        this.vertexPosition = 0;\n        this.frameCount = 0;\n        this.deltaTime = 0;\n        this.header = `#version 300 es\r\n#ifdef GL_ES\r\nprecision highp float;\r\nprecision highp int;\r\nprecision mediump sampler3D;\r\n#endif\r\n`;\n        this.targets = new Map();\n        this.mainUniforms = new Map();\n        this.programs = new Map();\n        this.textureCache = new Map();\n        let gl = canvas.getContext(\"webgl2\", { preserveDrawingBuffer: true });\n        this.gl = gl;\n        let mp = gl.createProgram();\n        this.mainProgram = mp;\n        gl.viewport(0, 0, canvas.width, canvas.height);\n        this.buffer = gl.createBuffer();\n        this.surfaceBuffer = gl.createBuffer();\n        this.createShader(mp, 35633, this.header + v);\n        this.createShader(mp, 35632, this.header + f);\n        gl.linkProgram(mp);\n        gl.validateProgram(mp);\n        if (!gl.getProgramParameter(mp, gl.LINK_STATUS)) {\n            var info = gl.getProgramInfoLog(mp);\n            throw 'Could not compile main program. \\n\\n' + info;\n        }\n        gl.useProgram(mp);\n        for (let i = 0; i < gl.getProgramParameter(mp, gl.ACTIVE_UNIFORMS); ++i) {\n            const u = gl.getActiveUniform(mp, i);\n            const loc = gl.getUniformLocation(mp, u.name);\n            this.mainUniforms.set(u.name, loc);\n        }\n        this.screenVertexPosition = gl.getAttribLocation(mp, \"pos\");\n        gl.enableVertexAttribArray(this.screenVertexPosition);\n        gl.bindBuffer(34962, this.buffer);\n        gl.bufferData(34962, new Float32Array([-1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0]), 35044);\n    }\n    /**\n     *  Generate a texture and return a canvas element\n     *\n     * @static\n     * @param {string} mainVertex\n     * @param {string} mainFrag\n     * @param {string} textureVertex\n     * @param {*} textureFrag\n     * @param {number} w\n     * @param {number} h\n     * @returns {HTMLCanvasElement}\n     * @memberof DR\n     */\n    static generateTexture(mainVertex, mainFrag, textureVertex, textureFrag, w, h) {\n        let canvas = document.createElement(\"canvas\");\n        canvas.width = w;\n        canvas.height = h;\n        let dr = new GLSLShaderRenderer(canvas, mainVertex, mainFrag);\n        dr.addBuffer(\"A\", textureVertex, textureFrag);\n        // do a few frames due to back buffer.\n        for (var i = 0; i < 2; i++) {\n            dr.update(i);\n        }\n        return canvas;\n    }\n}\nexports.GLSLShaderRenderer = GLSLShaderRenderer;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGL/GLSLShaderRenderer.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGPU/DefaultMainShader.js":
/*!**********************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGPU/DefaultMainShader.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.defaultMainShader = void 0;\nexports.defaultMainShader = {\n    vertex: /* wgsl */ `\r\n    \r\n    struct VertexOutput {\r\n      @builtin(position) Position  : vec4<f32>,\r\n      @location(0) TexCoord  : vec2<f32>,\r\n  }\r\n  \r\n  @vertex\r\n  fn main_vertex(@builtin(vertex_index) VertexIndex : u32) -> VertexOutput {\r\n  \r\n      var positions = array<vec2<f32>, 6>(\r\n          vec2<f32>( 1.0,  1.0),\r\n          vec2<f32>( 1.0, -1.0),\r\n          vec2<f32>(-1.0, -1.0),\r\n          vec2<f32>( 1.0,  1.0),\r\n          vec2<f32>(-1.0, -1.0),\r\n          vec2<f32>(-1.0,  1.0)\r\n      );\r\n  \r\n      var texCoords = array<vec2<f32>, 6>(\r\n          vec2<f32>(1.0, 0.0),\r\n          vec2<f32>(1.0, 1.0),\r\n          vec2<f32>(0.0, 1.0),\r\n          vec2<f32>(1.0, 0.0),\r\n          vec2<f32>(0.0, 1.0),\r\n          vec2<f32>(0.0, 0.0)\r\n      );\r\n  \r\n      var output : VertexOutput;\r\n      output.Position = vec4<f32>(positions[VertexIndex], 0.0, 1.0);\r\n      output.TexCoord = texCoords[VertexIndex];\r\n      return output;\r\n  }\r\n    \r\n    `,\n    fragment: /* wgsl */ `\r\n    \r\n    struct Uniforms {\r\n      resolution: vec3<f32>,\r\n      time: f32\r\n    };  \r\n    @group(0) @binding(0) var screen_sampler : sampler;    \r\n    @group(0) @binding(1) var<uniform> uniforms: Uniforms;  \r\n    @group(0) @binding(2) var buffer1: texture_2d<f32>;   \r\n\r\n    struct VertexOutput {\r\n      @builtin(position) Position: vec4<f32>,\r\n      @location(0) TexCoord: vec2<f32>\r\n    };  \r\n  \r\n    @fragment\r\n    fn main_fragment(@location(0) TexCoord : vec2<f32>,@builtin(position) Position: vec4<f32> ) -> @location(0) vec4<f32> {\r\n      return  textureSample(buffer1, screen_sampler, -TexCoord);  \r\n  \r\n    }`,\n    // vertexEntryPoint:\"main_vertex\",\n    // fragmentEntryPoint:\"main_fragment\"\n};\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGPU/DefaultMainShader.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGPU/Geometry.js":
/*!*************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGPU/Geometry.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.rectGeometry = exports.Geometry = exports.DefaultIndicies = exports.VERTEXType = void 0;\nvar VERTEXType;\n(function (VERTEXType) {\n    VERTEXType[VERTEXType[\"xyz\"] = 3] = \"xyz\";\n    VERTEXType[VERTEXType[\"xyzw\"] = 4] = \"xyzw\";\n    VERTEXType[VERTEXType[\"xyzrgba\"] = 7] = \"xyzrgba\";\n    VERTEXType[VERTEXType[\"xyzwrgba\"] = 8] = \"xyzwrgba\";\n})(VERTEXType || (exports.VERTEXType = VERTEXType = {}));\nexports.DefaultIndicies = new Uint16Array([0, 1, 2, 3, 4, 5]);\nclass Geometry {\n    /**\n     * Creates a new Geometry object.\n     * @param device - The GPUDevice to use for creating buffers.\n     * @param model - The geometry data, including vertices, indices, and vertex type.\n     */\n    constructor(device, model) {\n        this.device = device;\n        this.model = model;\n        this.vertexBuffer = this.createBuffer(model.vertices, GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST, model.verticesType);\n        this.indexBuffer = this.createBuffer(model.indicies, GPUBufferUsage.INDEX, 3);\n        this.numOfVerticles = model.vertices.length / model.verticesType;\n    }\n    /**\n     * Creates a GPUBuffer with the given data and usage flags.\n     * @param arr - The data to store in the buffer.\n     * @param usage - The usage flags for the buffer.\n     * @param vertexSize - The size of each vertex in bytes.\n     * @returns The created GPUBuffer.\n     */\n    createBuffer(arr, usage, vertexSize) {\n        const desc = {\n            size: (arr.byteLength + vertexSize) & ~vertexSize,\n            usage,\n            mappedAtCreation: true\n        };\n        const buffer = this.device.createBuffer(desc);\n        const writeArray = arr instanceof Uint16Array\n            ? new Uint16Array(buffer.getMappedRange())\n            : new Float32Array(buffer.getMappedRange());\n        writeArray.set(arr);\n        buffer.unmap();\n        return buffer;\n    }\n    /**\n     * Creates a vertex buffer layout for the geometry.\n     * @param shaderLocation - The location of the vertex attribute in the shader.\n     * @returns The GPUVertexBufferLayout object.\n     */\n    vertexBufferLayout(shaderLocation) {\n        return {\n            attributes: [{\n                    shaderLocation: shaderLocation,\n                    offset: 0,\n                    format: 'float32x2' // This might need to be adjusted based on your shader\n                }],\n            arrayStride: 4 * this.model.verticesType,\n            stepMode: 'vertex'\n        };\n    }\n}\nexports.Geometry = Geometry;\n// Default rectangle geometry\nexports.rectGeometry = {\n    verticesType: VERTEXType.xyz,\n    vertices: new Float32Array([\n        -1, 1, 0,\n        -1, -1, 0,\n        1, -1, 0,\n        1, 1, 0,\n        -1, 1, 0,\n        1, -1, 0,\n    ]),\n    indicies: exports.DefaultIndicies, // Use the DefaultIndicies constant\n};\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGPU/Geometry.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGPU/Material.js":
/*!*************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGPU/Material.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Material = exports.defaultWglslVertex = void 0;\n/**\n * Default vertex shader code for rendering a rectangle.\n */\nexports.defaultWglslVertex = ` \r\n  struct VertexInput {\r\n    @location(0) pos: vec2<f32>,\r\n    @builtin(vertex_index) index : u32\r\n  };\r\n\r\n  struct VertexOutput {\r\n    @builtin(position) pos: vec4<f32>,\r\n    @location(0) uv: vec2<f32>,\r\n    @location(1) fragCoord: vec2<f32>\r\n  };\r\n\r\n  @vertex\r\n  fn main_vertex(input: VertexInput) -> VertexOutput {\r\n    var output: VertexOutput;\r\n    var pos: vec2<f32> = input.pos * 2.0 - 1.0;\r\n    output.pos = vec4<f32>(pos, 0.0, 1.0);\r\n    output.uv = pos;\r\n    output.fragCoord = vec2<f32>((pos.x + 1.0) / 2.0, (1.0 - pos.y) / 2.0); \r\n    return output;\r\n  }\r\n`;\n/**\n * Represents a material with vertex and fragment shaders.\n */\nclass Material {\n    /**\n     * Creates a new Material.\n     * @param device - The GPUDevice to use for creating shader modules.\n     * @param shader - The IMaterialShader object containing the shader code.\n     */\n    constructor(device, shader) {\n        this.device = device;\n        this.shader = shader;\n        this.vertexShaderModule = this.device.createShaderModule({\n            code: shader.vertex\n        });\n        this.fragmentShaderModule = this.device.createShaderModule({\n            code: shader.fragment\n        });\n    }\n    /**\n     * Creates an IMaterialShader object from the provided shader code and entry points.\n     * @param vertex - The vertex shader code as a Uint32Array.\n     * @param fragment - The fragment shader code as a Uint32Array.\n     * @param vertexEntryPoint - The entry point function name for the vertex shader.\n     * @param fragmentEntryPoint - The entry point function name for the fragment shader.\n     * @returns The created IMaterialShader object.\n     */\n    static createMaterialShader(vertex, fragment, vertexEntryPoint, fragmentEntryPoint) {\n        return {\n            fragment: fragment,\n            fragmentEntryPoint: fragmentEntryPoint,\n            vertex: vertex,\n            vertexEntryPoint: vertexEntryPoint\n        };\n    }\n}\nexports.Material = Material;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGPU/Material.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGPU/RenderPassBuilder.js":
/*!**********************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGPU/RenderPassBuilder.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RenderPassBuilder = exports.RenderPass = void 0;\nclass RenderPass {\n    constructor(type, label, pipleline, uniforms, bindGroup, buffer, bufferView) {\n        this.type = type;\n        this.label = label;\n        this.pipleline = pipleline;\n        this.uniforms = uniforms;\n        this.bindGroup = bindGroup;\n        this.buffer = buffer;\n        this.bufferView = bufferView;\n    }\n}\nexports.RenderPass = RenderPass;\n/**\n * A builder class for creating render passes in WebGPU.\n */\nclass RenderPassBuilder {\n    /**\n  * Creates a new RenderPassBuilder.\n  * @param device - The GPUDevice to use for creating resources.\n  * @param canvas - The HTMLCanvasElement to render to.\n  */\n    constructor(device, canvas) {\n        this.canvas = canvas;\n        this.device = device;\n    }\n    /**\n   * Creates a bind group layout and entries for a render pipeline.\n   * @param uniformBuffer - The uniform buffer for the pipeline.\n   * @param sampler - An optional GPUSampler to use. If not provided, a default sampler is created.\n   * @returns An array of GPUBindGroupEntry objects.\n   */\n    getRenderPiplelineBindingGroupLayout(uniformBuffer, sampler) {\n        const bindingGroupEntrys = [];\n        bindingGroupEntrys.push({\n            binding: 0,\n            resource: {\n                buffer: uniformBuffer\n            }\n        });\n        const defaultSampler = this.device.createSampler({\n            addressModeU: 'repeat',\n            addressModeV: 'repeat',\n            magFilter: 'linear',\n            minFilter: 'nearest'\n        });\n        bindingGroupEntrys.push({\n            binding: 1,\n            resource: sampler || defaultSampler\n        });\n        return bindingGroupEntrys;\n    }\n    /**\n  * Creates a render pipeline.\n  * @param material - The material to use for the pipeline.\n  * @param geometry - The geometry to use for the pipeline.\n  * @param textures - An array of textures to use in the pipeline.\n  * @param priorRenderPasses - An array of prior render passes to include as textures.\n  * @returns The created GPURenderPipeline.\n  */\n    createRenderPipeline(material, geometry, textures, priorRenderPasses) {\n        const bindGroupLayoutEntries = new Array();\n        // add uniforms\n        bindGroupLayoutEntries.push({\n            binding: 0,\n            visibility: GPUShaderStage.COMPUTE | GPUShaderStage.FRAGMENT,\n            buffer: {\n                type: \"uniform\"\n            }\n        });\n        // add sampler\n        bindGroupLayoutEntries.push({\n            binding: 1,\n            visibility: GPUShaderStage.COMPUTE | GPUShaderStage.FRAGMENT,\n            sampler: {\n                type: \"filtering\"\n            }\n        });\n        let offset = bindGroupLayoutEntries.length;\n        // add prior render passes\n        priorRenderPasses.forEach((p, index) => {\n            bindGroupLayoutEntries.push({\n                binding: offset + index,\n                visibility: GPUShaderStage.FRAGMENT,\n                texture: {}\n            });\n        });\n        offset = bindGroupLayoutEntries.length;\n        if (textures.length > 0) {\n            for (let i = 0; i < textures.length; i++) { //  1-n texture bindings\n                if (textures[i].type === 0) {\n                    bindGroupLayoutEntries.push({\n                        binding: 2 + i,\n                        visibility: GPUShaderStage.FRAGMENT,\n                        texture: {\n                            sampleType: \"float\"\n                        }\n                    });\n                }\n                else {\n                    bindGroupLayoutEntries.push({\n                        binding: 2 + i,\n                        visibility: GPUShaderStage.FRAGMENT,\n                        externalTexture: {}\n                    });\n                }\n            }\n        }\n        const bindGroupLayout = this.device.createBindGroupLayout({\n            entries: bindGroupLayoutEntries\n        });\n        const pipeline = this.device.createRenderPipeline({\n            layout: this.device.createPipelineLayout({\n                bindGroupLayouts: [bindGroupLayout],\n            }),\n            vertex: {\n                module: material.vertexShaderModule,\n                entryPoint: \"main_vertex\",\n                buffers: [geometry.vertexBufferLayout(0)]\n            },\n            fragment: {\n                module: material.fragmentShaderModule,\n                entryPoint: \"main_fragment\",\n                targets: [\n                    {\n                        format: 'bgra8unorm'\n                    }\n                ]\n            }\n        });\n        return pipeline;\n    }\n    /**\n     * Creates a compute pipeline.\n     * @param computeShader - The compute shader module.\n     * @param textures - An array of textures to use in the pipeline.\n     * @returns The created GPUComputePipeline.\n     */\n    createComputePipeline(computeShader, textures) {\n        const bindGroupLayoutEntries = new Array();\n        bindGroupLayoutEntries.push({\n            binding: 0,\n            visibility: GPUShaderStage.COMPUTE,\n            storageTexture: {\n                access: \"write-only\",\n                format: \"bgra8unorm\",\n                viewDimension: \"2d\"\n            },\n        }, {\n            binding: 1, visibility: GPUShaderStage.COMPUTE,\n            buffer: {\n                type: \"uniform\"\n            }\n        });\n        if (textures.length > 0) {\n            for (let i = 0; i < textures.length; i++) { //  1-n texture bindings\n                if (textures[i].type === 0) {\n                    bindGroupLayoutEntries.push({\n                        binding: 3 + i,\n                        visibility: window.GPUShaderStage.COMPUTE,\n                        texture: {\n                            sampleType: \"float\"\n                        }\n                    });\n                }\n                else {\n                    bindGroupLayoutEntries.push({\n                        binding: 3 + i,\n                        visibility: window.GPUShaderStage.COMPUTE,\n                        externalTexture: {}\n                    });\n                }\n            }\n        }\n        const bindGroupLayout = this.device.createBindGroupLayout({\n            entries: bindGroupLayoutEntries\n        });\n        const pipeline = this.device.createComputePipeline({\n            layout: this.device.createPipelineLayout({\n                bindGroupLayouts: [bindGroupLayout],\n            }),\n            compute: {\n                module: computeShader,\n                entryPoint: 'main',\n            },\n        });\n        return pipeline;\n    }\n}\nexports.RenderPassBuilder = RenderPassBuilder;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGPU/RenderPassBuilder.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGPU/TextureLoader.js":
/*!******************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGPU/TextureLoader.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WGSLTextureLoader = exports.WGSLTextureType = void 0;\nvar WGSLTextureType;\n(function (WGSLTextureType) {\n    WGSLTextureType[WGSLTextureType[\"IMAGE\"] = 0] = \"IMAGE\";\n    WGSLTextureType[WGSLTextureType[\"VIDEO\"] = 1] = \"VIDEO\";\n    WGSLTextureType[WGSLTextureType[\"CANVAS\"] = 2] = \"CANVAS\";\n    WGSLTextureType[WGSLTextureType[\"MEDIASTREAM\"] = 3] = \"MEDIASTREAM\";\n})(WGSLTextureType || (exports.WGSLTextureType = WGSLTextureType = {}));\n/**\n * A helper class for loading and creating textures for WebGPU.\n */\nclass WGSLTextureLoader {\n    /**\n     * Loads an array of textures and returns an array of ITextureData.\n     * @param device - The GPUDevice to use for creating textures.\n     * @param textures - An array of ITexture objects.\n     * @returns A Promise that resolves to an array of ITextureData.\n     */\n    static async loadAll(device, ...textures) {\n        return Promise.all(textures.map(async (texture) => {\n            if (texture.type === 0) {\n                return { type: 0, data: await this.createImageTexture(device, texture) };\n            }\n            else {\n                return { type: 1, data: await this.createVideoTexture(device, texture) };\n            }\n        }));\n    }\n    /**\n     * Creates a GPUTexture from an image.\n     * @param device - The GPUDevice to use for creating the texture.\n     * @param texture - The ITexture object containing the image source.\n     * @returns A Promise that resolves to the created GPUTexture.\n     */\n    static async createImageTexture(device, texture) {\n        const image = new Image();\n        image.src = texture.source;\n        await image.decode();\n        const imageBitmap = await createImageBitmap(image);\n        const textureSize = { width: image.width, height: image.height };\n        const gpuTexture = device.createTexture({\n            label: texture.key,\n            size: textureSize,\n            dimension: '2d',\n            format: 'rgba8unorm',\n            usage: GPUTextureUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING\n        });\n        device.queue.copyExternalImageToTexture({ source: imageBitmap }, { texture: gpuTexture, mipLevel: 0 }, textureSize);\n        return gpuTexture;\n    }\n    /**\n     * Creates a HTMLVideoElement for video textures.\n     * @param device - The GPUDevice.\n     * @param texture - The ITexture object containing the video source.\n     * @returns A Promise that resolves to the HTMLVideoElement.\n     */\n    static async createVideoTexture(device, texture) {\n        const video = document.createElement(\"video\");\n        video.loop = true;\n        video.autoplay = true;\n        video.muted = true;\n        if (texture.source instanceof MediaStream) {\n            video.srcObject = texture.source;\n        }\n        else {\n            video.src = texture.source;\n        }\n        await video.play();\n        return video;\n    }\n}\nexports.WGSLTextureLoader = WGSLTextureLoader;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGPU/TextureLoader.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGPU/Uniforms.js":
/*!*************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGPU/Uniforms.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Uniforms = void 0;\n/**\n * Manages uniform data for shaders in WebGPU.\n */\nclass Uniforms {\n    /**\n     * Initializes a Float32Array with default values for uniforms.\n     * @param w - The width of the canvas.\n     * @param h - The height of the canvas.\n     * @returns A new Float32Array with initialized values.\n     */\n    static initialize(w, h) {\n        return new Float32Array([w, h, 0, 1, 0, 0, 0, 0, 0, 0]);\n    }\n    /**\n     * Creates a new Uniforms instance.\n     * @param device - The GPUDevice to use for creating the uniform buffer.\n     * @param canvas - The HTMLCanvasElement to get dimensions from.\n     */\n    constructor(device, canvas) {\n        this.device = device;\n        this.uniformBuffer = this.device.createBuffer({\n            size: 60,\n            usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT,\n        });\n        this.uniformBufferArray = Uniforms.initialize(canvas.width, canvas.height); // Use the initialize method\n    }\n    /**\n     * Sets uniform values in the uniform buffer array.\n     * @param values - An array of values to set.\n     * @param offset - The offset in the array where the values should be written.\n     */\n    setUniforms(values, offset) {\n        this.uniformBufferArray.set(values, offset);\n    }\n    /**\n     * Updates the uniform buffer on the GPU with the data from the uniform buffer array.\n     */\n    updateUniformBuffer() {\n        this.device.queue.writeBuffer(this.uniformBuffer, 0, this.uniformBufferArray.buffer, this.uniformBufferArray.byteOffset, this.uniformBufferArray.byteLength);\n    }\n}\nexports.Uniforms = Uniforms;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGPU/Uniforms.js?");

/***/ }),

/***/ "./build/src/Engine/ShaderRenderers/WebGPU/WGSLShaderRenderer.js":
/*!***********************************************************************!*\
  !*** ./build/src/Engine/ShaderRenderers/WebGPU/WGSLShaderRenderer.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WGSLShaderRenderer = exports.initWebGPU = void 0;\nconst Geometry_1 = __webpack_require__(/*! ./Geometry */ \"./build/src/Engine/ShaderRenderers/WebGPU/Geometry.js\");\nconst Material_1 = __webpack_require__(/*! ./Material */ \"./build/src/Engine/ShaderRenderers/WebGPU/Material.js\");\nconst RenderPassBuilder_1 = __webpack_require__(/*! ./RenderPassBuilder */ \"./build/src/Engine/ShaderRenderers/WebGPU/RenderPassBuilder.js\");\nconst TextureLoader_1 = __webpack_require__(/*! ./TextureLoader */ \"./build/src/Engine/ShaderRenderers/WebGPU/TextureLoader.js\");\nconst Uniforms_1 = __webpack_require__(/*! ./Uniforms */ \"./build/src/Engine/ShaderRenderers/WebGPU/Uniforms.js\");\nconst initWebGPU = async (canvas, options) => {\n    var _a;\n    const adapter = await ((_a = navigator.gpu) === null || _a === void 0 ? void 0 : _a.requestAdapter(options));\n    const hasBGRA8unormStorage = adapter.features.has('bgra8unorm-storage');\n    const device = await (adapter === null || adapter === void 0 ? void 0 : adapter.requestDevice({\n        requiredFeatures: hasBGRA8unormStorage\n            ? ['bgra8unorm-storage']\n            : [],\n    }));\n    if (!device)\n        throw \"need a browser that supports WebGPU\";\n    const context = canvas.getContext(\"webgpu\");\n    context === null || context === void 0 ? void 0 : context.configure({\n        device,\n        format: hasBGRA8unormStorage\n            ? navigator.gpu.getPreferredCanvasFormat()\n            : 'rgba8unorm',\n        usage: GPUTextureUsage.TEXTURE_BINDING |\n            GPUTextureUsage.STORAGE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT,\n    });\n    return { device, context };\n};\nexports.initWebGPU = initWebGPU;\n/**\n * The Renderer class is responsible for managing the WebGPU rendering context,\n * creating and executing render passes, and handling resources like buffers and textures.\n */\nclass WGSLShaderRenderer {\n    constructor(canvas, device, context, geometry) {\n        this.canvas = canvas;\n        this.device = device;\n        this.context = context;\n        this.frameCount = 0;\n        this.frame = 0;\n        this.renderPassBacklog = new Map();\n        this.textures = new Array();\n        this.renderPassBuilder = new RenderPassBuilder_1.RenderPassBuilder(device, this.canvas);\n        this.geometry = new Geometry_1.Geometry(device, geometry || Geometry_1.rectGeometry);\n        this.uniforms = new Uniforms_1.Uniforms(this.device, this.canvas);\n    }\n    /**\n  * Gets the WebGPU device.\n  * @returns The GPUDevice.\n  * @throws Error if the device is not initialized.\n  */\n    getDevice() {\n        if (!this.device)\n            throw \"Cannot get the GPUDevice\";\n        return this.device;\n    }\n    /**\n   * Creates a render pipeline for a given material.\n   * @param uniformBuffer - The uniform buffer for the pipeline.\n   * @param material - The material to use for the pipeline.\n   * @returns The created GPURenderPipeline.\n   */\n    creatRenderPipeline(uniformBuffer, material) {\n        const bindingGroupEntrys = [];\n        const sampler = this.getDevice().createSampler({\n            addressModeU: 'repeat',\n            addressModeV: 'repeat',\n            magFilter: 'linear',\n            minFilter: 'nearest'\n        });\n        bindingGroupEntrys.push({\n            binding: 0,\n            resource: sampler\n        }, {\n            binding: 1,\n            resource: {\n                buffer: uniformBuffer\n            }\n        });\n        const layout = new Array();\n        layout.push({\n            binding: 0,\n            visibility: GPUShaderStage.FRAGMENT,\n            sampler: {}\n        }, {\n            binding: 1,\n            visibility: GPUShaderStage.FRAGMENT,\n            buffer: {\n                type: \"uniform\"\n            }\n        });\n        const pipleline_group_layout = this.getDevice().createBindGroupLayout({\n            entries: layout\n        });\n        const pipeline_layout = this.getDevice().createPipelineLayout({\n            bindGroupLayouts: [pipleline_group_layout]\n        });\n        const pipelineDescriptor = {\n            vertex: {\n                module: material.vertexShaderModule,\n                entryPoint: material.shader.vertexEntryPoint || 'main_vertex',\n                buffers: [this.geometry.vertexBufferLayout(0)]\n            },\n            fragment: {\n                module: material.fragmentShaderModule,\n                entryPoint: material.shader.fragmentEntryPoint || 'main_fragment',\n                targets: [{\n                        format: 'bgra8unorm'\n                    }]\n            },\n            primitive: {\n                topology: 'triangle-list',\n            },\n            layout: pipeline_layout\n        };\n        return this.getDevice().createRenderPipeline(pipelineDescriptor);\n    }\n    /**\n   * Creates a main render pipeline for a given material.\n   * @param uniformBuffer - The uniform buffer for the pipeline.\n   * @param material - The material to use for the pipeline.\n   * @returns The created GPURenderPipeline.\n   */\n    createMainRenderPipeline(uniformBuffer, material) {\n        const bindingGroupEntrys = [];\n        const sampler = this.getDevice().createSampler({\n            addressModeU: 'repeat',\n            addressModeV: 'repeat',\n            magFilter: 'linear',\n            minFilter: 'nearest'\n        });\n        bindingGroupEntrys.push({\n            binding: 0,\n            resource: sampler\n        }, {\n            binding: 1,\n            resource: {\n                buffer: uniformBuffer\n            }\n        });\n        const layout = new Array();\n        layout.push({\n            binding: 0,\n            visibility: GPUShaderStage.FRAGMENT,\n            sampler: {}\n        }, {\n            binding: 1,\n            visibility: GPUShaderStage.FRAGMENT,\n            buffer: {\n                type: \"uniform\"\n            }\n        });\n        const renderPasses = Array.from(this.renderPassBacklog.values());\n        renderPasses.forEach((pass, i) => {\n            bindingGroupEntrys.push({\n                binding: 2 + i,\n                resource: pass.bufferView\n            });\n            layout.push({\n                binding: 2 + i,\n                visibility: GPUShaderStage.FRAGMENT,\n                texture: {}\n            });\n        });\n        const screen_bind_group_layout = this.getDevice().createBindGroupLayout({\n            entries: layout\n        });\n        this.screen_bind_group = this.getDevice().createBindGroup({\n            layout: screen_bind_group_layout,\n            entries: bindingGroupEntrys\n        });\n        const screen_pipeline_layout = this.getDevice().createPipelineLayout({\n            bindGroupLayouts: [screen_bind_group_layout]\n        });\n        const pipelineDescriptor = {\n            vertex: {\n                module: material.vertexShaderModule,\n                entryPoint: material.shader.vertexEntryPoint || 'main_vertex',\n                buffers: [this.geometry.vertexBufferLayout(0)]\n            },\n            fragment: {\n                module: material.fragmentShaderModule,\n                entryPoint: material.shader.fragmentEntryPoint || 'main_fragment',\n                targets: [{\n                        format: 'bgra8unorm'\n                    }]\n            },\n            primitive: {\n                topology: 'triangle-list',\n            },\n            layout: screen_pipeline_layout\n        };\n        return this.getDevice().createRenderPipeline(pipelineDescriptor);\n    }\n    /**\n   * Creates render targets for the pipeline.\n   * @returns An object containing the texture and texture view for the render target.\n   */\n    createAssets() {\n        const buffer = this.getDevice().createTexture({\n            size: {\n                width: this.canvas.width,\n                height: this.canvas.height,\n            },\n            format: \"bgra8unorm\",\n            usage: GPUTextureUsage.COPY_DST | GPUTextureUsage.STORAGE_BINDING | GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT\n        });\n        return { buffer, bufferView: buffer.createView() };\n    }\n    /**\n     * Creates a buffer on the GPU.\n     * @param arr - The data to store in the buffer.\n     * @param usage - The usage flags for the buffer.\n     * @param vertexSize - The size of each vertex in bytes.\n     * @returns The created GPUBuffer.\n     */\n    createBuffer(arr, usage, vertexSize) {\n        let bufferDescriptor = {\n            size: (arr.byteLength + vertexSize) & ~vertexSize,\n            usage,\n            mappedAtCreation: true\n        };\n        let buffer = this.getDevice().createBuffer(bufferDescriptor);\n        const writeArray = arr instanceof Uint16Array\n            ? new Uint16Array(buffer.getMappedRange())\n            : new Float32Array(buffer.getMappedRange());\n        writeArray.set(arr);\n        buffer.unmap();\n        return buffer;\n    }\n    /**\n   * Adds a main render pass to the backlog.\n   * @param material - The material to use for the render pass.\n   */\n    addMainRenderPass(shader) {\n        const material = new Material_1.Material(this.device, shader);\n        this.renderPipleline = this.createMainRenderPipeline(this.uniforms.uniformBuffer, material);\n    }\n    /**\n   * Adds a render pass to the backlog.\n   * @param label - The label for the render pass.\n   * @param material - The material to use for the render pass.\n   * @param geometry - The geometry to use for the render pass.\n   * @param textures - An optional array of textures to use in the render pass.\n   */\n    addRenderPass(label, material, geometry, textures) {\n        textures === null || textures === void 0 ? void 0 : textures.forEach(texture => {\n            this.textures.push(texture);\n        });\n        const priorRenderPasses = Array.from(this.renderPassBacklog.values());\n        const uniforms = this.uniforms;\n        const renderPipeline = this.renderPassBuilder.createRenderPipeline(material, geometry, this.textures, priorRenderPasses);\n        const assets = this.createAssets();\n        const bindingGroupEntrys = [];\n        const sampler = this.getDevice().createSampler({\n            addressModeU: 'repeat',\n            addressModeV: 'repeat',\n            magFilter: 'linear',\n            minFilter: 'nearest'\n        });\n        bindingGroupEntrys.push({\n            binding: 0,\n            resource: {\n                buffer: uniforms.uniformBuffer\n            }\n        }, {\n            binding: 1,\n            resource: sampler\n        });\n        let offset = bindingGroupEntrys.length;\n        // Pass the previos renderpasses to current\n        priorRenderPasses.forEach((pass, i) => {\n            bindingGroupEntrys.push({\n                binding: offset + i,\n                resource: pass.bufferView,\n            });\n        });\n        // Add the bindings for the textures  \n        offset = bindingGroupEntrys.length;\n        this.textures.forEach((t, i) => {\n            let entry;\n            if (t.type === 0) {\n                entry = {\n                    binding: i + offset,\n                    resource: t.data.createView()\n                };\n            }\n            else {\n                entry = {\n                    binding: i + 2,\n                    resource: this.getDevice().importExternalTexture({ source: t.data }),\n                };\n            }\n            bindingGroupEntrys.push(entry);\n        });\n        const bindGroup = this.getDevice().createBindGroup({\n            layout: renderPipeline.getBindGroupLayout(0),\n            entries: bindingGroupEntrys,\n            label: `${label} renderpass`\n        });\n        const renderPass = new RenderPassBuilder_1.RenderPass(1, label, renderPipeline, uniforms, bindGroup, assets.buffer, assets.bufferView);\n        this.renderPassBacklog.set(label, renderPass); // send it the the renderpass backlog\n        return renderPass;\n    }\n    /**\n   * Adds a compute render pass to the backlog.\n   * @param label - The label for the compute pass.\n   * @param computeShaderCode - The WGSL code for the compute shader.\n   * @param textures - An optional array of textures to use in the compute pass.\n   */\n    async addComputeRenderPass(label, computeShaderCode, textures, samplers) {\n        if (samplers)\n            throw \"Samplers not yet implememted, using default binding 2\";\n        const shaderModule = this.getDevice().createShaderModule({ code: computeShaderCode });\n        const uniforms = this.uniforms; //new Uniforms(this.device, this.canvas);\n        if (textures) {\n            for (let i = 0; i < textures.length; i++) {\n                const texture = textures[i];\n                if (texture.type == 0) {\n                    this.textures.push({ type: 0, data: await TextureLoader_1.WGSLTextureLoader.createImageTexture(this.getDevice(), texture) });\n                }\n                else\n                    this.textures.push({ type: 1, data: await TextureLoader_1.WGSLTextureLoader.createVideoTexture(this.getDevice(), texture) });\n            }\n        }\n        const computePipeline = this.renderPassBuilder.createComputePipeline(shaderModule, this.textures);\n        const assets = this.createAssets();\n        const bindingGroupEntrys = [];\n        const sampler = this.getDevice().createSampler({\n            addressModeU: 'repeat',\n            addressModeV: 'repeat',\n            magFilter: 'linear',\n            minFilter: 'nearest'\n        });\n        bindingGroupEntrys.push({\n            binding: 0,\n            resource: assets.bufferView\n        }, {\n            binding: 1,\n            resource: {\n                buffer: uniforms.uniformBuffer\n            }\n        });\n        const offset = bindingGroupEntrys.length;\n        this.textures.forEach((t, i) => {\n            let entry;\n            if (t.type === 0) {\n                entry = {\n                    binding: i + offset,\n                    resource: t.data.createView()\n                };\n            }\n            else {\n                entry = {\n                    binding: i + 2,\n                    resource: this.getDevice().importExternalTexture({ source: t.data }),\n                };\n            }\n            bindingGroupEntrys.push(entry);\n        });\n        const bindGroup = this.getDevice().createBindGroup({\n            layout: computePipeline.getBindGroupLayout(0),\n            entries: bindingGroupEntrys,\n            label: `${label} computepass`\n        });\n        const renderPass = new RenderPassBuilder_1.RenderPass(0, label, computePipeline, uniforms, bindGroup, assets.buffer, assets.bufferView);\n        this.renderPassBacklog.set(label, renderPass);\n    }\n    /**\n   * Updates the renderer and executes all render passes in the backlog.\n   * @param time - The current time in seconds.\n   */\n    update(ts) {\n        const encoder = this.getDevice().createCommandEncoder();\n        const arrRenderPasses = Array.from(this.renderPassBacklog.values());\n        // get the compute shaders from the back log\n        arrRenderPasses.filter((pre) => {\n            return pre.type == 0;\n        }).forEach(pass => {\n            const computePass = encoder.beginComputePass();\n            computePass.setPipeline(pass.pipleline);\n            computePass.setBindGroup(0, pass.bindGroup);\n            computePass.dispatchWorkgroups(Math.floor((this.canvas.width + 7) / 8), Math.floor((this.canvas.height + 7) / 8), 1);\n            computePass.end();\n        });\n        arrRenderPasses.filter(pre => {\n            return pre.type == 1;\n        }).forEach(pass => {\n            const renderPassDescriptor = {\n                colorAttachments: [{\n                        loadOp: 'clear',\n                        storeOp: 'store',\n                        view: pass.bufferView,\n                        clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },\n                    }]\n            };\n            const renderPass = encoder.beginRenderPass(renderPassDescriptor);\n            renderPass.setPipeline(pass.pipleline);\n            renderPass.setBindGroup(0, pass.bindGroup);\n            renderPass.setVertexBuffer(0, this.geometry.vertexBuffer);\n            renderPass.setIndexBuffer(this.geometry.indexBuffer, 'uint16');\n            renderPass.drawIndexed(this.geometry.numOfVerticles, 1);\n            renderPass.end();\n        });\n        const mainRenderer = encoder.beginRenderPass({\n            colorAttachments: [{\n                    view: this.context.getCurrentTexture().createView(),\n                    clearValue: { r: 0.0, g: 0, b: 0.0, a: 1 },\n                    loadOp: \"clear\",\n                    storeOp: \"store\"\n                }]\n        });\n        this.uniforms.setUniforms([this.frame], 8);\n        this.uniforms.setUniforms([ts], 3);\n        this.uniforms.updateUniformBuffer();\n        mainRenderer.setPipeline(this.renderPipleline);\n        mainRenderer.setVertexBuffer(0, this.geometry.vertexBuffer);\n        mainRenderer.setBindGroup(0, this.screen_bind_group);\n        mainRenderer.draw(6, 1, 0, 0);\n        mainRenderer.end();\n        this.getDevice().queue.submit([encoder.finish()]);\n    }\n    /**\n   * Starts the rendering loop.\n   * @param t - The initial time.\n   * @param maxFps - The maximum frames per second.\n   * @param onFrame - An optional callback function to be called on each frame.\n   */\n    start(t, maxFps = 200, onFrame) {\n        let startTime = null;\n        let frame = -1;\n        const renderLoop = (ts) => {\n            if (!startTime)\n                startTime = ts;\n            let segment = Math.floor((ts - startTime) / (1000 / maxFps));\n            if (segment > frame) {\n                frame = segment;\n                this.frame = segment;\n                this.frameCount = frame;\n                if (!this.isPaused) {\n                    this.update(ts / 1000);\n                    if (onFrame)\n                        onFrame(frame);\n                }\n            }\n            requestAnimationFrame(renderLoop);\n        };\n        renderLoop(t);\n    }\n    pause() {\n        this.isPaused = !this.isPaused;\n    }\n    clear() {\n        this.renderPassBacklog.clear();\n    }\n}\nexports.WGSLShaderRenderer = WGSLShaderRenderer;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/ShaderRenderers/WebGPU/WGSLShaderRenderer.js?");

/***/ }),

/***/ "./build/src/Engine/WGSLShaderEntity.js":
/*!**********************************************!*\
  !*** ./build/src/Engine/WGSLShaderEntity.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WGSLShaderEntity = void 0;\nconst WGSLShaderRenderer_1 = __webpack_require__(/*! ./ShaderRenderers/WebGPU/WGSLShaderRenderer */ \"./build/src/Engine/ShaderRenderers/WebGPU/WGSLShaderRenderer.js\");\nclass WGSLShaderEntity {\n    constructor(name, props, action, w, h, startTimeinMs, durationInMs) {\n        var _a, _b;\n        this.name = name;\n        this.props = props;\n        this.action = action;\n        this.w = w;\n        this.h = h;\n        this.startTimeinMs = startTimeinMs;\n        this.durationInMs = durationInMs;\n        this.beatListeners = [];\n        this.tickListeners = [];\n        this.barListeners = [];\n        this.canvas = props === null || props === void 0 ? void 0 : props.canvas;\n        if (props === null || props === void 0 ? void 0 : props.shader) {\n            this.shaderRenderer = new WGSLShaderRenderer_1.WGSLShaderRenderer(this.canvas, (_a = this.props) === null || _a === void 0 ? void 0 : _a.device, (_b = this.props) === null || _b === void 0 ? void 0 : _b.context);\n            props.renderBuffers.forEach((buffer, index) => {\n                this.shaderRenderer.addRenderPass(buffer.name, buffer.shader, buffer.geometry, buffer.textures);\n            });\n            this.shaderRenderer.addMainRenderPass(props.shader);\n        }\n        else {\n            throw new Error(\"Cannot create WGSLShaderEntity: Missing main shader code.\");\n        }\n    }\n    bindToScene(scene) {\n        this.scene = scene;\n    }\n    /**\n * Adds an event listener for when a beat occurs.\n * @param listener - The function to call when a beat occurs.\n * @returns The Entity instance for chaining.\n */\n    onBeat(listener) {\n        this.beatListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds an event listener for when a tick occurs.\n     * @param listener - The function to call when a tick occurs.\n     * @returns The Entity instance for chaining.\n     */\n    onTick(listener) {\n        this.tickListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds an event listener for when a bar is complete.\n     * @param listener - The function to call when a bar is complete.\n     * @returns The Entity instance for chaining.\n     */\n    onBar(listener) {\n        this.barListeners.push(listener);\n        return this;\n    }\n    /**\n     * Updates the ShaderEntity by calling the action function (if provided)\n     * and then updating the ShaderRenderer.\n     * @param timeStamp - The current timestamp in the animation.\n     */\n    update(timeStamp) {\n        if (this.action && this.shaderRenderer && this.props) {\n            // Calculate elapsed time relative to the scene's start time\n            const sceneStartTime = this.scene ? this.scene.startTimeinMs : 0;\n            const elapsed = timeStamp - sceneStartTime - (this.startTimeinMs || 0);\n            if (elapsed >= 0 && elapsed <= (this.durationInMs || Infinity)) {\n                this.action(timeStamp, this.shaderRenderer, this.props);\n                // Calculate shader time relative to the entity's start time (within the scene)\n                const shaderTime = Math.max(0, elapsed);\n                this.shaderRenderer.update(shaderTime / 1000);\n            }\n        }\n    }\n    /**\n     * Copies the entity's canvas to the target canvas.\n     * @param targetCanvas - The target canvas to copy to.\n     */\n    copyToCanvas(targetCanvas, sequence) {\n        const targetCtx = targetCanvas.getContext(\"2d\");\n        if (targetCtx) {\n            // Calculate the elapsed time for the entity\n            const elapsed = sequence.currentTime - (this.startTimeinMs || 0);\n            // Check if the entity should be rendered based on its lifetime\n            if (elapsed >= 0 && elapsed <= (this.durationInMs || Infinity)) {\n                targetCtx.drawImage(this.canvas, 0, 0);\n            }\n        }\n    }\n}\nexports.WGSLShaderEntity = WGSLShaderEntity;\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/Engine/WGSLShaderEntity.js?");

/***/ }),

/***/ "./build/src/index.js":
/*!****************************!*\
  !*** ./build/src/index.js ***!
  \****************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SonantAudioLoader = exports.DefaultAudioLoader = exports.SequenceHelper = exports.SceneBuilder = exports.createInvertPostProcessor = exports.createGrayscalePostProcessor = exports.createBlurPostProcessor = exports.createFadeOutTransition = exports.createFadeInTransition = exports.EntityRenderer = exports.EntityBuilder = exports.DebugHelper = exports.AssetsHelper = exports.Uniforms = exports.WGSLTextureType = exports.WGSLTextureLoader = exports.RenderPassBuilder = exports.Material = exports.defaultWglslVertex = exports.VERTEXType = exports.rectGeometry = exports.Geometry = exports.DefaultIndicies = exports.defaultMainShader = exports.WGSLShaderRenderer = exports.initWebGPU = exports.RenderTarget = exports.GLSLShaderRenderer = exports.Sequence = exports.Scene = exports.GLSLShaderEntity = exports.Entity = exports.EngineLogger = exports.Conductor = exports.WGSLShaderEntity = void 0;\nvar WGSLShaderEntity_1 = __webpack_require__(/*! ./Engine/WGSLShaderEntity */ \"./build/src/Engine/WGSLShaderEntity.js\");\nObject.defineProperty(exports, \"WGSLShaderEntity\", ({ enumerable: true, get: function () { return WGSLShaderEntity_1.WGSLShaderEntity; } }));\nvar Conductor_1 = __webpack_require__(/*! ./Engine/Conductor */ \"./build/src/Engine/Conductor.js\");\nObject.defineProperty(exports, \"Conductor\", ({ enumerable: true, get: function () { return Conductor_1.Conductor; } }));\nvar EngineLogger_1 = __webpack_require__(/*! ./Engine/EngineLogger */ \"./build/src/Engine/EngineLogger.js\");\nObject.defineProperty(exports, \"EngineLogger\", ({ enumerable: true, get: function () { return EngineLogger_1.EngineLogger; } }));\nvar Entity_1 = __webpack_require__(/*! ./Engine/Entity */ \"./build/src/Engine/Entity.js\");\nObject.defineProperty(exports, \"Entity\", ({ enumerable: true, get: function () { return Entity_1.Entity; } }));\nvar GLSLShaderEntity_1 = __webpack_require__(/*! ./Engine/GLSLShaderEntity */ \"./build/src/Engine/GLSLShaderEntity.js\");\nObject.defineProperty(exports, \"GLSLShaderEntity\", ({ enumerable: true, get: function () { return GLSLShaderEntity_1.GLSLShaderEntity; } }));\nvar Scene_1 = __webpack_require__(/*! ./Engine/Scene */ \"./build/src/Engine/Scene.js\");\nObject.defineProperty(exports, \"Scene\", ({ enumerable: true, get: function () { return Scene_1.Scene; } }));\nvar Sequence_1 = __webpack_require__(/*! ./Engine/Sequence */ \"./build/src/Engine/Sequence.js\");\nObject.defineProperty(exports, \"Sequence\", ({ enumerable: true, get: function () { return Sequence_1.Sequence; } }));\nvar GLSLShaderRenderer_1 = __webpack_require__(/*! ./Engine/ShaderRenderers/WebGL/GLSLShaderRenderer */ \"./build/src/Engine/ShaderRenderers/WebGL/GLSLShaderRenderer.js\");\nObject.defineProperty(exports, \"GLSLShaderRenderer\", ({ enumerable: true, get: function () { return GLSLShaderRenderer_1.GLSLShaderRenderer; } }));\nObject.defineProperty(exports, \"RenderTarget\", ({ enumerable: true, get: function () { return GLSLShaderRenderer_1.RenderTarget; } }));\nvar WGSLShaderRenderer_1 = __webpack_require__(/*! ./Engine/ShaderRenderers/WebGPU/WGSLShaderRenderer */ \"./build/src/Engine/ShaderRenderers/WebGPU/WGSLShaderRenderer.js\");\nObject.defineProperty(exports, \"initWebGPU\", ({ enumerable: true, get: function () { return WGSLShaderRenderer_1.initWebGPU; } }));\nObject.defineProperty(exports, \"WGSLShaderRenderer\", ({ enumerable: true, get: function () { return WGSLShaderRenderer_1.WGSLShaderRenderer; } }));\nvar DefaultMainShader_1 = __webpack_require__(/*! ./Engine/ShaderRenderers/WebGPU/DefaultMainShader */ \"./build/src/Engine/ShaderRenderers/WebGPU/DefaultMainShader.js\");\nObject.defineProperty(exports, \"defaultMainShader\", ({ enumerable: true, get: function () { return DefaultMainShader_1.defaultMainShader; } }));\nvar Geometry_1 = __webpack_require__(/*! ./Engine/ShaderRenderers/WebGPU/Geometry */ \"./build/src/Engine/ShaderRenderers/WebGPU/Geometry.js\");\nObject.defineProperty(exports, \"DefaultIndicies\", ({ enumerable: true, get: function () { return Geometry_1.DefaultIndicies; } }));\nObject.defineProperty(exports, \"Geometry\", ({ enumerable: true, get: function () { return Geometry_1.Geometry; } }));\nObject.defineProperty(exports, \"rectGeometry\", ({ enumerable: true, get: function () { return Geometry_1.rectGeometry; } }));\nObject.defineProperty(exports, \"VERTEXType\", ({ enumerable: true, get: function () { return Geometry_1.VERTEXType; } }));\nvar Material_1 = __webpack_require__(/*! ./Engine/ShaderRenderers/WebGPU/Material */ \"./build/src/Engine/ShaderRenderers/WebGPU/Material.js\");\nObject.defineProperty(exports, \"defaultWglslVertex\", ({ enumerable: true, get: function () { return Material_1.defaultWglslVertex; } }));\nObject.defineProperty(exports, \"Material\", ({ enumerable: true, get: function () { return Material_1.Material; } }));\nvar RenderPassBuilder_1 = __webpack_require__(/*! ./Engine/ShaderRenderers/WebGPU/RenderPassBuilder */ \"./build/src/Engine/ShaderRenderers/WebGPU/RenderPassBuilder.js\");\nObject.defineProperty(exports, \"RenderPassBuilder\", ({ enumerable: true, get: function () { return RenderPassBuilder_1.RenderPassBuilder; } }));\nvar TextureLoader_1 = __webpack_require__(/*! ./Engine/ShaderRenderers/WebGPU/TextureLoader */ \"./build/src/Engine/ShaderRenderers/WebGPU/TextureLoader.js\");\nObject.defineProperty(exports, \"WGSLTextureLoader\", ({ enumerable: true, get: function () { return TextureLoader_1.WGSLTextureLoader; } }));\nObject.defineProperty(exports, \"WGSLTextureType\", ({ enumerable: true, get: function () { return TextureLoader_1.WGSLTextureType; } }));\nvar Uniforms_1 = __webpack_require__(/*! ./Engine/ShaderRenderers/WebGPU/Uniforms */ \"./build/src/Engine/ShaderRenderers/WebGPU/Uniforms.js\");\nObject.defineProperty(exports, \"Uniforms\", ({ enumerable: true, get: function () { return Uniforms_1.Uniforms; } }));\nvar AssetsHelper_1 = __webpack_require__(/*! ./Engine/Helpers/AssetsHelper */ \"./build/src/Engine/Helpers/AssetsHelper.js\");\nObject.defineProperty(exports, \"AssetsHelper\", ({ enumerable: true, get: function () { return AssetsHelper_1.AssetsHelper; } }));\nvar DebugHelper_1 = __webpack_require__(/*! ./Engine/Helpers/DebugHelper */ \"./build/src/Engine/Helpers/DebugHelper.js\");\nObject.defineProperty(exports, \"DebugHelper\", ({ enumerable: true, get: function () { return DebugHelper_1.DebugHelper; } }));\nvar EntityBuilder_1 = __webpack_require__(/*! ./Engine/Helpers/EntityBuilder */ \"./build/src/Engine/Helpers/EntityBuilder.js\");\nObject.defineProperty(exports, \"EntityBuilder\", ({ enumerable: true, get: function () { return EntityBuilder_1.EntityBuilder; } }));\nObject.defineProperty(exports, \"EntityRenderer\", ({ enumerable: true, get: function () { return EntityBuilder_1.EntityRenderer; } }));\nvar EntityTransitions_1 = __webpack_require__(/*! ./Engine/Helpers/EntityTransitions */ \"./build/src/Engine/Helpers/EntityTransitions.js\");\nObject.defineProperty(exports, \"createFadeInTransition\", ({ enumerable: true, get: function () { return EntityTransitions_1.createFadeInTransition; } }));\nObject.defineProperty(exports, \"createFadeOutTransition\", ({ enumerable: true, get: function () { return EntityTransitions_1.createFadeOutTransition; } }));\nvar PostProcessors_1 = __webpack_require__(/*! ./Engine/Helpers/PostProcessors */ \"./build/src/Engine/Helpers/PostProcessors.js\");\nObject.defineProperty(exports, \"createBlurPostProcessor\", ({ enumerable: true, get: function () { return PostProcessors_1.createBlurPostProcessor; } }));\nObject.defineProperty(exports, \"createGrayscalePostProcessor\", ({ enumerable: true, get: function () { return PostProcessors_1.createGrayscalePostProcessor; } }));\nObject.defineProperty(exports, \"createInvertPostProcessor\", ({ enumerable: true, get: function () { return PostProcessors_1.createInvertPostProcessor; } }));\nvar SceneBuilder_1 = __webpack_require__(/*! ./Engine/Helpers/SceneBuilder */ \"./build/src/Engine/Helpers/SceneBuilder.js\");\nObject.defineProperty(exports, \"SceneBuilder\", ({ enumerable: true, get: function () { return SceneBuilder_1.SceneBuilder; } }));\nvar SequenceHelper_1 = __webpack_require__(/*! ./Engine/Helpers/SequenceHelper */ \"./build/src/Engine/Helpers/SequenceHelper.js\");\nObject.defineProperty(exports, \"SequenceHelper\", ({ enumerable: true, get: function () { return SequenceHelper_1.SequenceHelper; } }));\nvar AudioLoader_1 = __webpack_require__(/*! ./Engine/Audio/AudioLoader */ \"./build/src/Engine/Audio/AudioLoader.js\");\nObject.defineProperty(exports, \"DefaultAudioLoader\", ({ enumerable: true, get: function () { return AudioLoader_1.DefaultAudioLoader; } }));\nObject.defineProperty(exports, \"SonantAudioLoader\", ({ enumerable: true, get: function () { return AudioLoader_1.SonantAudioLoader; } }));\n\n\n//# sourceURL=webpack://demolished-rail/./build/src/index.js?");

/***/ }),

/***/ "./build/wwwroot/assets/shaders/wglsl/wgslFlamesShader.js":
/*!****************************************************************!*\
  !*** ./build/wwwroot/assets/shaders/wglsl/wgslFlamesShader.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// This is a shader originally written by Inigo Quilez and published on:\n// https://www.shadertoy.com/view/MsXGRf\n//\n// It has been converted to WGSL by Magnus Thor.\n//\n// The original GLSL code is copyrighted by Inigo Quilez:\n// Copyright Inigo Quilez, 2013 - https://iquilezles.org/\n//\n// The converted WGSL code is shared here under the following conditions:\n//\n// This WGSL shader code is shared for educational purposes only. \n// You are free to use it for learning and experimentation.\n//\n// You are NOT allowed to:\n// - Host, display, distribute, or share this WGSL code as it is or altered.\n// - Use this WGSL code in any commercial or non-commercial product, website, or project.\n// - Sell this WGSL code.\n// - Mint NFTs of this WGSL code.\n// - Train a neural network with this WGSL code.\n//\n// If you wish to use this code outside of educational purposes, \n// please contact Inigo Quilez for permission.\n//\n// You can find the original GLSL shader and contact Inigo Quilez here:\n// https://www.shadertoy.com/view/MsXGRf\n// https://iquilezles.org/\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.wgslFlamesShader = void 0;\nconst Material_1 = __webpack_require__(/*! ../../../../src/Engine/ShaderRenderers/WebGPU/Material */ \"./build/src/Engine/ShaderRenderers/WebGPU/Material.js\");\nexports.wgslFlamesShader = {\n    vertex: Material_1.defaultWglslVertex,\n    fragment: /* glsl */ `\r\n\r\n\tstruct VertexOutput {\r\n\t\t@builtin(position) pos: vec4<f32>,\r\n\t\t@location(0) uv: vec2<f32>\r\n\t  };    \r\n   \r\n\tstruct Uniforms {\r\n\t\tresolution: vec3<f32>,\r\n\t\ttime: f32,\r\n\t\tmouse: vec4<f32>,\r\n\t\tframe: f32\r\n\t  };\r\n\t\r\n    @group(0) @binding(0) var<uniform> uniforms: Uniforms;\r\n    @group(0) @binding(1) var linearSampler: sampler;\r\n    @group(0) @binding(2) var NOISE: texture_2d<f32>; \t\t\r\n\t\r\n\tfn sample_texture(tex:texture_2d<f32>,uv:vec2<f32>) -> vec4<f32>{\r\n\t\tlet result:vec4<f32> = textureSample(tex, linearSampler, -uv);\r\n\t\treturn result;\r\n\t}   \r\n\t\r\n\tfn noise(x: vec3<f32>) -> f32 {\r\n\t\tlet p: vec3<f32> = floor(x);\r\n\t\tvar f: vec3<f32> = fract(x);\r\n\t\tf = f * f * (3. - 2. * f);\r\n\t\tlet uv: vec2<f32> = p.xy + vec2<f32>(37., 17.) * p.z + f.xy;\r\n\t\tlet rg: vec2<f32> = textureSampleLevel(NOISE, linearSampler, (uv + 0.5) / 256., f32(0.)).yx;\r\n\t\treturn mix(rg.x, rg.y, f.z);\r\n\t} \r\n\r\n\tfn map(p: vec3<f32>) -> vec4<f32> {\r\n\r\n\t\tvar tm = uniforms.time;\r\n\r\n\t\tvar p_var = p;\r\n\t\tlet r: vec3<f32> = p_var;\r\n\t\tp_var.y = p_var.y + (0.6);\r\n\t\tp_var = -4. * p_var / dot(p_var, p_var);\r\n\t\tlet an: f32 = -1. * sin(0.1 * tm + length(p_var.xz) + p_var.y);\r\n\t\tlet co: f32 = cos(an);\r\n\t\tlet si: f32 = sin(an);\r\n\t\tvar pxz = p_var.xz;\r\n\t\tpxz = mat2x2<f32>(co, -si, si, co) * p_var.xz;\r\n\t\tp_var.x = pxz.x;\r\n\t\tp_var.z = pxz.y;\r\n\r\n\t\tpxz = p_var.xz + (-1. + 2. * noise(p_var * 1.1));\r\n\t\tp_var.x = pxz.x;\r\n\t\tp_var.z = pxz.y;\r\n\t\tvar f: f32;\r\n\t\tvar q: vec3<f32> = p_var * 0.85 - vec3<f32>(0., 1., 0.) * tm * 0.12;\r\n\t\tf = 0.5 * noise(q);\r\n\t\tq = q * 2.02 - vec3<f32>(0., 1., 0.) * tm * 0.12;\r\n\t\tf = f + (0.25 * noise(q));\r\n\t\tq = q * 2.03 - vec3<f32>(0., 1., 0.) * tm * 0.12;\r\n\t\tf = f + (0.125 * noise(q));\r\n\t\tq = q * 2.01 - vec3<f32>(0., 1., 0.) * tm * 0.12;\r\n\t\tf = f + (0.0625 * noise(q));\r\n\t\tq = q * 2.02 - vec3<f32>(0., 1., 0.) * tm * 0.12;\r\n\t\tf = f + (0.04 * noise(q));\r\n\t\tq = q * 2. - vec3<f32>(0., 1., 0.) * tm * 0.12;\r\n\t\tlet den: f32 = clamp((-r.y - 0.6 + 4. * f) * 1.2, 0., 1.);\r\n\r\n\t\tvar col: vec3<f32> = 1.2 * mix(vec3<f32>(1., 0.8, 0.6), 0.9 * vec3<f32>(0.3, 0.2, 0.35), den);\r\n\t\tcol = col + (0.05 * sin(0.05 * q));\r\n\t\tcol = col * (1. - 0.8 * smoothstep(0.6, 1., sin(0.7 * q.x) * sin(0.7 * q.y) * sin(0.7 * q.z)) * vec3<f32>(0.6, 1., 0.8));\r\n\t\tcol = col * (1. + 1. * smoothstep(0.5, 1., 1. - length((fract(q.xz * 0.12) - 0.5) / 0.5)) * vec3<f32>(1., 0.9, 0.8));\r\n\t\t\r\n\t\treturn vec4<f32>(col, den);\r\n\t} \r\n\t\r\n\tfn debugImage(invocation_id: vec2<f32>) -> vec4<f32> {\r\n\t\t\treturn vec4<f32>(1.0,0.,0.,0.5);\r\n\t}\r\n\r\n\tfn mainImage(invocation_id: vec2<f32>) -> vec4<f32> {\r\n\r\n\t\tlet mouse: vec4<f32> = uniforms.mouse;\r\n\t\r\n\t\tlet R: vec2<f32> = uniforms.resolution.xy;\r\n\t\tlet y_inverted_location = vec2<i32>(i32(invocation_id.x), i32(R.y) - i32(invocation_id.y));\r\n\t\tlet location = vec2<i32>(i32(invocation_id.x), i32(invocation_id.y));\r\n\t\t\r\n\t\tvar fragColor: vec4<f32>;\r\n\t\tvar fragCoord = vec2<f32>(f32(location.x), f32(location.y) );\r\n\t\r\n\t\tlet q: vec2<f32> = fragCoord.xy / uniforms.resolution.xy;\r\n\t\tlet p: vec2<f32> = (-1. + 2. * q) * vec2<f32>(uniforms.resolution.x / uniforms.resolution.y, 1.);\r\n\t\tvar mo: vec2<f32> = mouse.xy / uniforms.resolution.xy;\r\n\t\t\r\n\t\tlet an: f32 = -0.07 * uniforms.time + 3. * mo.x;\r\n\t\tvar ro: vec3<f32> = 4.5 * normalize(vec3<f32>(cos(an), 0.5, sin(an)));\r\n\t\tro.y = ro.y + (1.);\r\n\t\tlet ta: vec3<f32> = vec3<f32>(0., 0.5, 0.);\r\n\t\tlet cr: f32 = -0.4 * cos(0.02 * uniforms.time);\r\n\t\tlet ww: vec3<f32> = normalize(ta - ro);\r\n\t\tlet uu: vec3<f32> = normalize(cross(vec3<f32>(sin(cr), cos(cr), 0.), ww));\r\n\t\tlet vv: vec3<f32> = normalize(cross(ww, uu));\r\n\t\tlet rd: vec3<f32> = normalize(p.x * uu + p.y * vv + 2.5 * ww);\r\n\t\tvar sum: vec4<f32> = vec4<f32>(0.);\r\n\t\tlet bg: vec3<f32> = vec3<f32>(0.4, 0.5, 0.5) * 1.3;\r\n\t\tvar t: f32 = 0.05 * fract(10.5421 * dot(vec2<f32>(0.0149451, 0.038921), fragCoord));\r\n\t\r\n\t\tfor (var i: i32 = 0; i < 128; i = i + 1) {\r\n\t\t\tif (sum.a > 0.99) {\t\r\n\t\t\t\t\tbreak;\r\n\t\t \t}\r\n\r\n\t\t\tlet pos: vec3<f32> = ro + t * rd;\r\n\t\tvar col: vec4<f32> = map(pos);\r\n\t\tcol.a = col.a * (0.5);\r\n\t\tvar colrgb = col.rgb;\r\n\t\tcolrgb = mix(bg, col.rgb, exp(-0.002 * t * t * t)) * col.a;\r\n\t\tcol.r = colrgb.x;\r\n\t\tcol.g = colrgb.y;\r\n\t\tcol.b = colrgb.z;\r\n\t\t\tsum = sum + col * (1. - sum.a);\r\n\t\t\tt = t + (0.05);\r\n\t\t}\r\n\t\r\n\t\tvar mixedValue: vec3<f32> = mix(bg, sum.xyz / (0.001 + sum.w), sum.w);\r\n\r\n\t\tvar col: vec3<f32> = clamp(mixedValue, vec3<f32>(0.0), vec3<f32>(1.0));\r\n\r\n\t\tcol = col * col * (3. - 2. * col) * 1.4 - 0.4;\r\n\t\tcol = col * (0.25 + 0.75 * pow(16. * q.x * q.y * (1. - q.x) * (1. - q.y), 0.1));\r\n\t\treturn vec4<f32>(col, 1.);\r\n\t} \r\n\t\t\r\n\t@fragment\r\n\tfn main_fragment(vert: VertexOutput) -> @location(0) vec4<f32> {    \r\n\t\t\r\n\t\treturn mainImage(vert.pos.xy);\r\n\t}\r\n\r\n`\n};\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/assets/shaders/wglsl/wgslFlamesShader.js?");

/***/ }),

/***/ "./build/wwwroot/src/runsWgslShaderOnly.js":
/*!*************************************************!*\
  !*** ./build/wwwroot/src/runsWgslShaderOnly.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RunWGSLShader = void 0;\nconst src_1 = __webpack_require__(/*! ../../src */ \"./build/src/index.js\");\nconst wgslFlamesShader_1 = __webpack_require__(/*! ../assets/shaders/wglsl/wgslFlamesShader */ \"./build/wwwroot/assets/shaders/wglsl/wgslFlamesShader.js\");\n/**\n   * A class to demonstrate the usage of WGSL shaders in the demolished-rail framework.\n   */\nclass RunWGSLShader {\n    /**\n     * Creates a new RunShader instance.\n     * @param target - The canvas element to render to.\n     */\n    constructor(target) {\n        this.screenCanvas = target;\n    }\n    /**\n     * Runs the WGSL shader demo.\n     * @returns A Promise that resolves to the created WGSLShaderEntity.\n     */\n    async run() {\n        const wsglShaderCanvas = document.createElement(\"canvas\");\n        wsglShaderCanvas.width = this.screenCanvas.width;\n        wsglShaderCanvas.height = this.screenCanvas.height;\n        const webgpu = await (0, src_1.initWebGPU)(wsglShaderCanvas, { powerPreference: 'high-performance' });\n        const wsglTextures = await src_1.WGSLTextureLoader.loadAll(webgpu.device, {\n            key: \"NOISE-TEXTURE\",\n            source: \"assets/images/noise.png\",\n            type: src_1.WGSLTextureType.IMAGE,\n        });\n        const wgslMainShader = src_1.defaultMainShader;\n        const wgslShaderProps = {\n            canvas: wsglShaderCanvas,\n            device: webgpu.device,\n            context: webgpu.context,\n            shader: wgslMainShader,\n            renderBuffers: [\n                {\n                    name: \"buffer-01\",\n                    shader: new src_1.Material(webgpu.device, wgslFlamesShader_1.wgslFlamesShader),\n                    geometry: new src_1.Geometry(webgpu.device, src_1.rectGeometry),\n                    textures: wsglTextures\n                }\n            ]\n        };\n        const wgslShaderEntity = new src_1.WGSLShaderEntity(\"wgsl-shader\", wgslShaderProps, (ts, wgslRenderer, props) => {\n            // Perform operations, like modifying uniforms, per frame\n        });\n        const entityRenderer = new src_1.EntityRenderer(this.screenCanvas);\n        entityRenderer.addEntity(wgslShaderEntity);\n        entityRenderer.start();\n        return wgslShaderEntity;\n    }\n}\nexports.RunWGSLShader = RunWGSLShader;\ndocument.addEventListener(\"DOMContentLoaded\", async () => {\n    const canvas = document.querySelector(\"canvas#main-canvas\");\n    const runner = new RunWGSLShader(canvas);\n    const running = await runner.run();\n    console.log(`Running ${running.name}`);\n});\n\n\n//# sourceURL=webpack://demolished-rail/./build/wwwroot/src/runsWgslShaderOnly.js?");

/***/ }),

/***/ "./node_modules/sonantx/dist/sonantx.bundle.js":
/*!*****************************************************!*\
  !*** ./node_modules/sonantx/dist/sonantx.bundle.js ***!
  \*****************************************************/
/***/ ((module) => {

eval("(function webpackUniversalModuleDefinition(root, factory) {\n\tif(true)\n\t\tmodule.exports = factory();\n\telse {}\n})(window, function() {\nreturn /******/ (function(modules) { // webpackBootstrap\n/******/ \t// The module cache\n/******/ \tvar installedModules = {};\n/******/\n/******/ \t// The require function\n/******/ \tfunction __nested_webpack_require_539__(moduleId) {\n/******/\n/******/ \t\t// Check if module is in cache\n/******/ \t\tif(installedModules[moduleId]) {\n/******/ \t\t\treturn installedModules[moduleId].exports;\n/******/ \t\t}\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = installedModules[moduleId] = {\n/******/ \t\t\ti: moduleId,\n/******/ \t\t\tl: false,\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/\n/******/ \t\t// Execute the module function\n/******/ \t\tmodules[moduleId].call(module.exports, module, module.exports, __nested_webpack_require_539__);\n/******/\n/******/ \t\t// Flag the module as loaded\n/******/ \t\tmodule.l = true;\n/******/\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/\n/******/\n/******/ \t// expose the modules object (__webpack_modules__)\n/******/ \t__nested_webpack_require_539__.m = modules;\n/******/\n/******/ \t// expose the module cache\n/******/ \t__nested_webpack_require_539__.c = installedModules;\n/******/\n/******/ \t// define getter function for harmony exports\n/******/ \t__nested_webpack_require_539__.d = function(exports, name, getter) {\n/******/ \t\tif(!__nested_webpack_require_539__.o(exports, name)) {\n/******/ \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n/******/ \t\t}\n/******/ \t};\n/******/\n/******/ \t// define __esModule on exports\n/******/ \t__nested_webpack_require_539__.r = function(exports) {\n/******/ \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n/******/ \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n/******/ \t\t}\n/******/ \t\tObject.defineProperty(exports, '__esModule', { value: true });\n/******/ \t};\n/******/\n/******/ \t// create a fake namespace object\n/******/ \t// mode & 1: value is a module id, require it\n/******/ \t// mode & 2: merge all properties of value into the ns\n/******/ \t// mode & 4: return value when already ns object\n/******/ \t// mode & 8|1: behave like require\n/******/ \t__nested_webpack_require_539__.t = function(value, mode) {\n/******/ \t\tif(mode & 1) value = __nested_webpack_require_539__(value);\n/******/ \t\tif(mode & 8) return value;\n/******/ \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n/******/ \t\tvar ns = Object.create(null);\n/******/ \t\t__nested_webpack_require_539__.r(ns);\n/******/ \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n/******/ \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __nested_webpack_require_539__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n/******/ \t\treturn ns;\n/******/ \t};\n/******/\n/******/ \t// getDefaultExport function for compatibility with non-harmony modules\n/******/ \t__nested_webpack_require_539__.n = function(module) {\n/******/ \t\tvar getter = module && module.__esModule ?\n/******/ \t\t\tfunction getDefault() { return module['default']; } :\n/******/ \t\t\tfunction getModuleExports() { return module; };\n/******/ \t\t__nested_webpack_require_539__.d(getter, 'a', getter);\n/******/ \t\treturn getter;\n/******/ \t};\n/******/\n/******/ \t// Object.prototype.hasOwnProperty.call\n/******/ \t__nested_webpack_require_539__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n/******/\n/******/ \t// __webpack_public_path__\n/******/ \t__nested_webpack_require_539__.p = \"\";\n/******/\n/******/\n/******/ \t// Load entry module and return exports\n/******/ \treturn __nested_webpack_require_539__(__nested_webpack_require_539__.s = \"./sonantx.js\");\n/******/ })\n/************************************************************************/\n/******/ ({\n\n/***/ \"./sonantx.js\":\n/*!********************!*\\\n  !*** ./sonantx.js ***!\n  \\********************/\n/*! exports provided: generateSound, generateSong */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\neval(\"__webpack_require__.r(__webpack_exports__);\\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \\\"generateSound\\\", function() { return generateSound; });\\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \\\"generateSong\\\", function() { return generateSong; });\\n// Oscillators\\nfunction osc_sin(value) {\\n  return Math.sin(value * Math.PI * 2);\\n}\\n\\nfunction osc_square(value) {\\n  if (osc_sin(value) < 0) {\\n    return -1;\\n  }\\n\\n  return 1;\\n}\\n\\nfunction osc_saw(value) {\\n  return value % 1 - 0.5;\\n}\\n\\nfunction osc_tri(value) {\\n  const v2 = value % 1 * 4;\\n\\n  if (v2 < 2) {\\n    return v2 - 1;\\n  }\\n\\n  return 3 - v2;\\n} // Array of oscillator functions\\n\\n\\nconst oscillators = [osc_sin, osc_square, osc_saw, osc_tri];\\n\\nfunction getnotefreq44100(n) {\\n  const val = 0.00390625 * Math.pow(1.059463094, n - 128);\\n  return val;\\n}\\n\\nfunction getnotefreq(audioCtx, n) {\\n  const x = getnotefreq44100(n);\\n  const val = x / audioCtx.sampleRate * 44100;\\n  return val;\\n}\\n\\nfunction effectiveRowLen(audioCtx, bpm) {\\n  return Math.round(60 * audioCtx.sampleRate / 4 / bpm);\\n}\\n\\nclass SoundWriter {\\n  constructor(audioCtx, instr, n, bpm) {\\n    this.audioCtx = audioCtx;\\n    this.instr = instr;\\n    this.n = n;\\n    this.bpm = bpm;\\n    this.c1 = 0;\\n    this.c2 = 0;\\n    this.low = 0;\\n    this.band = 0;\\n    this.j = 0;\\n  }\\n\\n  write(lchan, rchan, from) {\\n    const instr = this.instr;\\n    const n = this.n;\\n    let c = from;\\n    const osc_lfo = oscillators[instr.lfo_waveform];\\n    const osc1 = oscillators[instr.osc1_waveform];\\n    const osc2 = oscillators[instr.osc2_waveform];\\n    const panFreq = Math.pow(2, instr.fx_pan_freq - 8) / effectiveRowLen(this.audioCtx, this.bpm);\\n    const lfoFreq = Math.pow(2, instr.lfo_freq - 8) / effectiveRowLen(this.audioCtx, this.bpm);\\n    const attackTime = instr.env_attack / 44100;\\n    const releaseTime = instr.env_release / 44100;\\n    const sustainTime = instr.env_sustain / 44100;\\n    const env_attack = attackTime * this.audioCtx.sampleRate;\\n    const env_release = releaseTime * this.audioCtx.sampleRate;\\n    const env_sustain = sustainTime * this.audioCtx.sampleRate; // Precalculate frequencues\\n\\n    const o1t = getnotefreq(this.audioCtx, n + (instr.osc1_oct - 8) * 12 + instr.osc1_det) * (1 + 0.0008 * instr.osc1_detune);\\n    const o2t = getnotefreq(this.audioCtx, n + (instr.osc2_oct - 8) * 12 + instr.osc2_det) * (1 + 0.0008 * instr.osc2_detune); // State variable init\\n\\n    const q = instr.fx_resonance / 255;\\n\\n    while (this.j < env_attack + env_sustain + env_release && c < lchan.length) {\\n      // LFO\\n      const lfor = osc_lfo(this.j * lfoFreq) * instr.lfo_amt / 512 + 0.5; // Envelope\\n\\n      let e = 1;\\n\\n      if (this.j < env_attack) {\\n        e = this.j / env_attack;\\n      } else if (this.j >= env_attack + env_sustain) {\\n        e -= (this.j - env_attack - env_sustain) / env_release;\\n      } // Oscillator 1\\n\\n\\n      let t = o1t;\\n\\n      if (instr.lfo_osc1_freq) {\\n        t += lfor;\\n      }\\n\\n      if (instr.osc1_xenv) {\\n        t *= e * e;\\n      }\\n\\n      this.c1 += t;\\n      let rsample = osc1(this.c1) * instr.osc1_vol; // Oscillator 2\\n\\n      t = o2t;\\n\\n      if (instr.osc2_xenv) {\\n        t *= e * e;\\n      }\\n\\n      this.c2 += t;\\n      rsample += osc2(this.c2) * instr.osc2_vol; // Noise oscillator\\n\\n      if (instr.noise_fader) {\\n        rsample += (2 * Math.random() - 1) * instr.noise_fader * e;\\n      }\\n\\n      rsample *= e / 255; // State variable filter\\n\\n      let f = instr.fx_freq;\\n\\n      if (instr.lfo_fx_freq) {\\n        f *= lfor;\\n      }\\n\\n      f = 1.5 * Math.sin(f * Math.PI / this.audioCtx.sampleRate);\\n      this.low += f * this.band;\\n      const high = q * (rsample - this.band) - this.low;\\n      this.band += f * high;\\n\\n      switch (instr.fx_filter) {\\n        case 1:\\n          // Hipass\\n          rsample = high;\\n          break;\\n\\n        case 2:\\n          // Lopass\\n          rsample = this.low;\\n          break;\\n\\n        case 3:\\n          // Bandpass\\n          rsample = this.band;\\n          break;\\n\\n        case 4:\\n          // Notch\\n          rsample = this.low + high;\\n          break;\\n\\n        default:\\n      } // Panning & master volume\\n\\n\\n      t = osc_sin(this.j * panFreq) * instr.fx_pan_amt / 512 + 0.5;\\n      rsample *= 39 * instr.env_master;\\n      let x = 32768 + rsample * (1 - t);\\n      let x1 = x & 255;\\n      let x2 = x >> 8 & 255;\\n      let y = 4 * (x1 + (x2 << 8) - 32768);\\n      y = y < -32768 ? -32768 : y > 32767 ? 32767 : y;\\n      lchan[c] = lchan[c] + y / 32768;\\n      x = 32768 + rsample * t;\\n      x1 = x & 255;\\n      x2 = x >> 8 & 255;\\n      y = 4 * (x1 + (x2 << 8) - 32768);\\n      y = y < -32768 ? -32768 : y > 32767 ? 32767 : y;\\n      rchan[c] = rchan[c] + y / 32768;\\n      this.j++;\\n      c++;\\n    } // returns true if the sound finished\\n\\n\\n    if (c < lchan.length) {\\n      return true;\\n    }\\n\\n    return false;\\n  }\\n\\n}\\n\\nclass TrackGenerator {\\n  constructor(audioCtx, instr, bpm, endPattern) {\\n    bpm = bpm || 118;\\n    endPattern = endPattern || instr.p.length - 1;\\n    this.audioCtx = audioCtx;\\n    this.instr = instr;\\n    this.bpm = bpm;\\n    this.endPattern = endPattern;\\n    const source = this.audioCtx.createOscillator();\\n    const nullGain = this.audioCtx.createGain();\\n    nullGain.gain.value = 0;\\n    source.connect(nullGain);\\n    const scriptNode = this.audioCtx.createScriptProcessor(512, 2, 2);\\n    nullGain.connect(scriptNode);\\n    let currentSample = 0;\\n    let nextNote = 0;\\n    let sounds = [];\\n\\n    scriptNode.onaudioprocess = audioProcessingEvent => {\\n      const inputData = audioProcessingEvent.inputBuffer;\\n      const outputData = audioProcessingEvent.outputBuffer;\\n      const lchan = outputData.getChannelData(0);\\n      const rchan = outputData.getChannelData(1);\\n      lchan.set(inputData.getChannelData(0));\\n      rchan.set(inputData.getChannelData(1));\\n      sounds.slice().forEach(el => {\\n        const finished = el.write(lchan, rchan, 0);\\n\\n        if (finished) {\\n          sounds = sounds.filter(el2 => {\\n            return el2 !== el;\\n          });\\n        }\\n      });\\n      let nextNoteSample = nextNote * effectiveRowLen(this.audioCtx, this.bpm);\\n\\n      while (nextNoteSample >= currentSample && nextNoteSample < currentSample + inputData.length) {\\n        const pattern = instr.p[Math.floor(nextNote / 32) % (this.endPattern + 1)] || 0;\\n        const note = pattern === 0 ? 0 : (instr.c[pattern - 1] || {\\n          n: []\\n        }).n[nextNote % 32] || 0;\\n\\n        if (note !== 0) {\\n          const sw = new SoundWriter(this.audioCtx, instr, note, this.bpm);\\n          sw.write(lchan, rchan, nextNoteSample - currentSample);\\n          sounds.push(sw);\\n        }\\n\\n        nextNote += 1;\\n        nextNoteSample = nextNote * effectiveRowLen(this.audioCtx, this.bpm);\\n      }\\n\\n      currentSample += inputData.length;\\n    };\\n\\n    const delayTime = instr.fx_delay_time * (1 / (this.bpm / 60) / 8);\\n    const delayAmount = instr.fx_delay_amt / 255;\\n    const delayGain = this.audioCtx.createGain();\\n    delayGain.gain.value = delayAmount;\\n    scriptNode.connect(delayGain);\\n    const delay = this.audioCtx.createDelay();\\n    delay.delayTime.value = delayTime;\\n    delayGain.connect(delay);\\n    delay.connect(delayGain);\\n    const mixer = this.audioCtx.createGain();\\n    mixer.gain.value = 1;\\n    scriptNode.connect(mixer);\\n    delay.connect(mixer);\\n    this.chain = [source, nullGain, scriptNode, delayGain, delay, mixer];\\n  }\\n\\n  start(when) {\\n    this.chain[0].start(when);\\n  }\\n\\n  stop(when) {\\n    this.chain[0].stop(when);\\n    this.chain[this.chain.length - 1].disconnect();\\n  }\\n\\n  connect(target) {\\n    this.chain[this.chain.length - 1].connect(target);\\n  }\\n\\n}\\n\\nclass MusicGenerator {\\n  constructor(audioCtx, song) {\\n    this.audioCtx = audioCtx;\\n    this.song = song;\\n    const mixer = this.audioCtx.createGain();\\n    mixer.gain.value = 1;\\n    this.tracks = [];\\n    this.song.songData.forEach(el => {\\n      const track = new TrackGenerator(this.audioCtx, el, this.bpm, this.song.endPattern);\\n      track.connect(mixer);\\n      this.tracks.push(track);\\n    });\\n    this.chain = [this.tracks, mixer];\\n  }\\n\\n  get bpm() {\\n    // rowLen is a number of samples when using 44100hz\\n    return Math.round(60 * 44100 / 4 / this.song.rowLen);\\n  }\\n\\n  start(when) {\\n    when = when || this.audioCtx.currentTime;\\n    this.tracks.forEach(t => t.start(when));\\n  }\\n\\n  stop(when) {\\n    when = when || this.audioCtx.currentTime;\\n    this.tracks.forEach(t => t.stop(when));\\n    this.chain[this.chain.length - 1].disconnect();\\n  }\\n\\n  connect(target) {\\n    this.chain[this.chain.length - 1].connect(target);\\n  }\\n\\n}\\n/**\\n * Generates a single note from an instrument.\\n *\\n * @param {*} instr The instrument descriptor\\n * @param {*} n The note as a midi note\\n * @param {*} sampleRate The sample rate\\n * @param {*} bpm The bpm of the song\\n * @returns {AudioBuffer} The generated audio buffer\\n */\\n\\n\\nasync function generateSound(instr, n, sampleRate, bpm = 120) {\\n  const attackTime = instr.env_attack / 44100;\\n  const releaseTime = instr.env_release / 44100;\\n  const sustainTime = instr.env_sustain / 44100;\\n  const soundLenSeconds = attackTime + releaseTime + sustainTime + 8 * (1 / (bpm / 60));\\n  const nInstr = Object.assign({}, instr);\\n  nInstr.p = [1, 0, 0, 0];\\n  nInstr.c = [{\\n    n: new Array(32).map(() => 0)\\n  }];\\n  nInstr.c[0].n[0] = n + 75;\\n  const audioCtx = new OfflineAudioContext(2, soundLenSeconds * sampleRate, sampleRate);\\n  const soundGen = new TrackGenerator(audioCtx, nInstr, bpm, 0);\\n  soundGen.connect(audioCtx.destination);\\n  soundGen.start();\\n  const buf = await audioCtx.startRendering();\\n  return buf;\\n}\\n/**\\n * Generates a complete song from a song description.\\n *\\n * @param {*} song The song description\\n * @param {*} options `sampleRate`: the sample rate\\n * @returns {AudioBuffer} The generated audio buffer\\n */\\n\\nasync function generateSong(song, sampleRate) {\\n  const songLenSeconds = song.songLen;\\n  const audioCtx = new OfflineAudioContext(2, songLenSeconds * sampleRate, sampleRate);\\n  const soundGen = new MusicGenerator(audioCtx, song);\\n  soundGen.connect(audioCtx.destination);\\n  soundGen.start();\\n  const buf = await audioCtx.startRendering();\\n  return buf;\\n}\\n\\n//# sourceURL=webpack://sonantx/./sonantx.js?\");\n\n/***/ })\n\n/******/ });\n});\n\n//# sourceURL=webpack://demolished-rail/./node_modules/sonantx/dist/sonantx.bundle.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./build/wwwroot/src/runsWgslShaderOnly.js");
/******/ 	
/******/ })()
;